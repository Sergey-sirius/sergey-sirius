<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Последние посты &#8211; Sirius Blog</title>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130427752-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130427752-1');
</script>

</head>
<meta name="description" content="Describtion ..">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/abstract-1.jpg">

<meta name="twitter:title" content="Последние посты">
<meta name="twitter:description" content="Describtion ..">
<meta name="twitter:creator" content="@2hotab2">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Последние посты">
<meta property="og:description" content="Describtion ..">
<meta property="og:url" content="http://localhost:4000/page22/">
<meta property="og:site_name" content="Sirius Blog">





<link rel="canonical" href="http://localhost:4000/page22/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Sirius Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.jpg">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.jpg">
<!-- 114x72 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x72" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.jpg">
<!-- 144x72 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x72" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.jpg">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Sergey Khatsiola photo" class="author-photo">
					<h4>Sergey Khatsiola</h4>
					<p>Кратко обо мне ...</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:2hotab2@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/2hotab2"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				<li>
					<a href="https://facebook.com/sergej.ha1"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/Sergey-sirius"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	    
	    <li><a href="http://localhost:4000/handbook/" >HandBook</a></li>
	  
	    
	    <li><a href="https://github.com/Sergey-sirius" target="_blank">Main Link</a></li>
	  
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/abstract-1.jpg" alt="Последние посты">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Sirius Blog</h1>
      <h2>Последние посты</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-016/" title="Глава 16. Установка из исходного кода"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 16. Установка из исходного кода"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-016/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~43 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-016/" rel="bookmark" title="Глава 16. Установка из исходного кода" itemprop="url">Глава 16. Установка из исходного кода</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Часть III. Администрирование сервера</p>

<p>В этой части документации освещаются темы, представляющие интерес для администратора баз
данных PostgreSQL. В частности, здесь рассматривается установка программного обеспечения,
установка и настройка сервера, управление пользователями и базами данных, а также задачи об-
служивания. С этими темами следует ознакомиться всем, кто эксплуатирует сервер PostgreSQL (да-
же для личных целей, а тем более в производственной среде).
Материал этой части даётся примерно в том порядке, в каком его следует читать начинающему
пользователю. При этом её главы самодостаточны и при желании могут быть прочитаны по отдель-
ности. Информация в этой части книги представлена в повествовательном стиле и разделена по те-
мам. Если же вас интересует формальное и полное описание определённой команды, см. Часть VI.
Первые несколько глав написаны так, чтобы их можно было понять без предварительных знаний, так
что начинающие пользователи, которым нужно установить свой собственный сервер, могут начать
свой путь с них. Остальные главы части посвящены настройке сервера и управлению им; в этом
материале подразумевается, что читатель знаком с основными принципами использования СУБД
PostgreSQL. За дополнительной информацией мы рекомендуем читателям обратиться к Части I и
Части II.</p>

<p>Глава 16. Установка из исходного кода</p>

<p>В этой главе описывается установка PostgreSQL из дистрибутивного пакета исходного кода. (Если
вы устанавливаете собранный двоичный пакет, например RPM или Debian, вам нужно прочитать
инструкции по установке пакета, а не эту главу.)
16.1. Краткий вариант
./configure
make
su
make install
adduser postgres
mkdir /usr/local/pgsql/data
chown postgres /usr/local/pgsql/data
su - postgres
/usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data
/usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data &gt;logfile 2&gt;&amp;1 &amp;
/usr/local/pgsql/bin/createdb test
/usr/local/pgsql/bin/psql test
Развёрнутый вариант представлен в продолжении этой главы.
16.2. Требования
В принципе, запустить PostgreSQL должно быть возможно на любой современной Unix-совмести-
мой платформе. Платформы, прошедшие специальную проверку на совместимость к моменту вы-
пуска версии, перечислены далее в Разделе 16.6. В подкаталоге doc дистрибутива PostgreSQL вы
можете найти несколько документов FAQ по разным платформам, к которым следует обратиться
в случае затруднений.
Для сборки PostgreSQL требуются следующие программные пакеты:
• Требуется GNU make версии 3.80 или новее; другие программы make или ранние версии GNU
make работать не будут. (Иногда GNU make устанавливается под именем gmake.) Чтобы прове-
рить наличие и версию GNU make, введите:
make –version
• Вам потребуется компилятор C, соответствующий ISO/ANSI (как минимум, совместимый с
C89). Рекомендуется использовать последние версии GCC, но известно, что PostgreSQL соби-
рается самыми разными компиляторами и других производителей.
• Для распаковки пакета исходного кода необходим tar, а также gzip или bzip2.
• По умолчанию при сборке используется библиотека GNU Readline. Она позволяет запоминать
все вводимые команды в psql (SQL-интерпретатор командной строки для PostgreSQL) и затем,
пользуясь клавишами-стрелками, возвращаться к ним и редактировать их. Это очень удоб-
но и мы настоятельно рекомендуем пользоваться этим. Если вы не желаете использовать эту
возможность, вы должны добавить указание –without-readline для configure. В качестве
альтернативы часто можно использовать библиотеку libedit с лицензией BSD, изначально
разработанную для NetBSD. Библиотека libedit совместима с GNU Readline и подключает-
ся, если libreadline не найдена, или когда configure передаётся указание –with-libedit-
preferred. Если вы используете систему на базе Linux с пакетами, учтите, что вам потребуют-
ся два пакета: readline и readline-devel, если в вашем дистрибутиве они разделены.
• По умолчанию для сжатия данных используется библиотека zlib. Если вы не хотите её исполь-
зовать, вы должны передать configure указание –without-zlib. Это указание отключает
поддержку сжатых архивов в pg_dump и pg_restore.
Следующие пакеты не являются обязательными. Они не требуются в стандартной конфигурации,
но они необходимы для определённых вариантов сборки, описанных ниже:
450Установка из исходного кода
• Чтобы собрать поддержку языка программирования PL/Perl, вам потребуется полная инстал-
ляция Perl, включая библиотеку libperl и заголовочные файлы. Версия Perl должна быть не
старее 5.8.3. Так как PL/Perl будет разделяемой библиотекой, библиотека libperl тоже долж-
на быть разделяемой для большинства платформ. В последних версиях Perl это вариант по
умолчанию, но в ранних версиях это было не так, и в любом случае это выбирает тот, кто уста-
навливает Perl в вашей системе. Скрипт configure выдаст ошибку, если не сможет найти раз-
деляемую libperl, когда выбрана сборка PL/Perl. В этом случае, чтобы собрать PL/Perl, вам
придётся пересобрать и переустановить Perl. В процессе конфигурирования Perl выберите
сборку разделяемой библиотеки.
Если вы планируете отвести PL/Perl не второстепенную роль, следует убедиться в том, что ин-
сталляция Perl была собрана с флагом usemultiplicity (так ли это, может показать команда
perl -V).
• Чтобы собрать сервер с поддержкой языка программирования PL/Python, вам потребуется ин-
сталляция Python с заголовочными файлами и модулем distutils. Версия Python должна быть
не меньше 2.4. Python 3 поддерживается, начиная с версии 3.1; но используя Python 3, следуй-
те написанному в Раздел 46.1.
Так как PL/Python будет разделяемой библиотекой, библиотека libpython тоже должна быть
разделяемой для большинства платформ. По умолчанию при сборке инсталляции Python из
пакета исходного кода это не так, но во многих дистрибутивах имеется нужная разделяемая
библиотека. Скрипт configure выдаст ошибку, если не сможет найти разделяемую libpython,
когда выбрана сборка PL/Python. Это может означать, что вам нужно либо установить допол-
нительные пакеты, либо пересобрать (частично) вашу инсталляцию Python, чтобы получить
эту библиотеку. При сборке Python из исходного кода выполните configure с флагом –enable-
shared.
• Чтобы собрать поддержку процедурного языка PL/Tcl, вам конечно потребуется инсталляция
Tcl. Версия Tcl должна быть не старее 8.4.
• Чтобы включить поддержку национальных языков (NLS, Native Language Support), то есть воз-
можность выводить сообщения программы не только на английском языке, вам потребуется
реализация API Gettext. В некоторых системах эта реализация встроена (например, в Linux,
NetBSD, Solaris), а для других вы можете получить дополнительный пакет по адресу http://
www.gnu.org/software/gettext/. Если вы используете реализацию Gettext в библиотеке GNU,
вам понадобится ещё пакет GNU Gettext для некоторых утилит. Для любых других реализаций
он не требуется.
• Если вам нужна поддержка зашифрованных клиентских соединений, вам потребуется
OpenSSL, версии не ниже 0.9.8.
• Вам могут понадобиться пакеты Kerberos, OpenLDAP и/или PAM, если вам нужна поддержка
аутентификации, которую они обеспечивают.
• Для сборки документации PostgreSQL предъявляется отдельный набор требований; см. Раз-
дел J.2.
Если вы хотите скомпилировать код из дерева Git, а не из специального пакета исходного кода,
либо вы хотите работать с этим кодом, вам также понадобятся следующие пакеты:
• Flex и Bison потребуются для сборки из содержимого Git или если вы меняете собственно фай-
лы определений анализа и разбора. Если они вам понадобятся, то версия Flex должна быть не
меньше 2.5.31, а Bison — не меньше 1.875. Другие программы lex и yacc работать не будут.
• Perl 5.8.3 или новее потребуется для сборки из содержимого Git, либо если вы меняете ис-
ходные файлы этапов сборки, построенных на скриптах Perl. Если вы выполняете сборку в
Windows, вам потребуется Perl в любом случае. Perl также требуется для выполнения некото-
рых комплектов тестов.
Если вам понадобится какой-либо пакет GNU, вы можете найти его на вашем локальном зеркале
GNU (список зеркал: https://www.gnu.org/prep/ftp) или на сайте ftp://ftp.gnu.org/gnu/.
451Установка из исходного кода
Также проверьте, достаточно ли места на диске. Вам потребуется около 100 Мб для исходного
кода в процессе компиляции и около 20 Мб для каталога инсталляции. Пустой кластер баз данных
занимает около 35 Мб; базы данных занимают примерно в пять раз больше места, чем те же дан-
ные в обычном текстовом файле. Если вы планируете запускать регрессионные тесты, вам может
временно понадобиться ещё около 150 Мб. Проверить наличие свободного места можно с помо-
щью команды df.
16.3. Получение исходного кода
Исходные коды PostgreSQL 11.1 можно загрузить из соответствующего раздела нашего сай-
та: https://www.postgresql.org/download/. Вам следует выбрать файл postgresql-11.1.tar.gz или
postgresql-11.1.tar.bz2. Получив этот файл, распакуйте его:
gunzip postgresql-11.1.tar.gz
tar xf postgresql-11.1.tar
(Если вы выбрали файл .bz2, используйте bunzip2 вместо gunzip.) При этом в текущем каталоге
будет создан подкаталог postgresql-11.1 с исходными кодами PostgreSQL. Перейдите в этот под-
каталог для продолжения процедуры установки.
Вы также можете получить исходный код непосредственно из репозитория системы управления
версиями (см. Приложение I).
16.4. Процедура установки
1.
Конфигурирование
На первом шаге установки требуется сконфигурировать дерево установки для вашей системы
и выбрать желаемые параметры сборки. Для этого нужно запустить скрипт configure. Чтобы
выполнить стандартную сборку, просто введите:
./configure
Этот скрипт проведёт несколько проверок с целью определить значения для различных пе-
ременных, зависящих от системы, и выявить любые странности вашей ОС, а затем создаст
несколько файлов в дереве сборки, в которых отразит полученные результаты. Вы также мо-
жете выполнить configure вне дерева исходного кода, если хотите сохранить каталог сборки
отдельно. Эта процедура также называется сборкой с VPATH. Выполняется она так:
mkdir build_dir
cd build_dir
/путь/к/каталогу/исходного/кода/configure [параметры]
make
В стандартной конфигурации собираются сервер и утилиты, а также клиентские приложения
и интерфейсы, которым требуется только компилятор C. Все файлы по умолчанию устанавли-
ваются в /usr/local/pgsql.
Вы можете настроить процесс сборки и установки, передав configure один или несколько сле-
дующих параметров командной строки:
–prefix=ПРЕФИКС
Разместить все файлы внутри каталога ПРЕФИКС, а не в /usr/local/pgsql. Собственно фай-
лы будут установлены в различные подкаталоги этого каталога; в самом каталоге ПРЕФИКС
никакие файлы не размещаются.
Если у вас есть особые требования, вы также можете изменить отдельные подкаталоги,
определив следующие параметры. Однако, если вы оставите для них значения по умолча-
нию, инсталляция будет перемещаемой, то есть вы сможете переместить каталог после
установки. (Это не распространяется на каталоги man и doc.)
452Установка из исходного кода
Для перемещаемых инсталляций можно передать configure указание –disable-rpath.
Кроме того, вы должны будете сказать операционной системе, как найти разделяемые биб-
лиотеки.
–exec-prefix=ИСП-ПРЕФИКС
Вы можете установить архитектурно-зависимые файлы в размещение с другим префиксом,
ИСП-ПРЕФИКС, отличным от ПРЕФИКС. Это бывает полезно для совместного использования та-
ких файлов несколькими системами. По умолчанию ИСП-ПРЕФИКС считается равным ПРЕФИКС
и все файлы, архитектурно-зависимые и независимые, устанавливаются в одно дерево ка-
талогов, что вам скорее всего и нужно.
–bindir=КАТАЛОГ
Задаёт каталог для исполняемых двоичных программ. По умолчанию это ИСП-ПРЕФИКС/bin,
что обычно означает /usr/local/pgsql/bin.
–sysconfdir=КАТАЛОГ
Задаёт каталог для различных файлов конфигурации, ПРЕФИКС/etc по умолчанию.
–libdir=КАТАЛОГ
Задаёт каталог для установки библиотек и динамически загружаемых модулей. Значение
по умолчанию — ИСП-ПРЕФИКС/lib.
–includedir=КАТАЛОГ
Задаёт каталог для установки заголовочных файлов C и C++. Значение по умолчанию —
ПРЕФИКС/include.
–datarootdir=КАТАЛОГ
Задаёт корневой каталог для разного рода статических файлов. Этот параметр определяет
только базу для некоторых из следующих параметров. Значение по умолчанию — ПРЕФИКС/
share.
–datadir=КАТАЛОГ
Задаёт каталог для статических файлов данных, используемых установленными програм-
мами. Значение по умолчанию — DATAROOTDIR. Заметьте, что это совсем не тот каталог, в
котором будут размещены файлы базы данных.
–localedir=КАТАЛОГ
Задаёт каталог для установки данных локализации, в частности, каталогов перевода сооб-
щений. Значение по умолчанию — DATAROOTDIR/locale.
–mandir=КАТАЛОГ
Страницы man, поставляемые в составе PostgreSQL, будут установлены в этот каталог, в
соответствующие подкаталоги manx. Значение по умолчанию — DATAROOTDIR/man.
–docdir=КАТАЛОГ
Задаёт корневой каталог для установки файлов документации, кроме страниц «man». Этот
параметр только определяет базу для следующих параметров. Значение по умолчанию —
DATAROOTDIR/doc/postgresql.
–htmldir=КАТАЛОГ
В этот каталог будет помещена документация PostgreSQL в формате HTML. Значение по
умолчанию — DATAROOTDIR.
453Установка из исходного кода
Примечание
Чтобы PostgreSQL можно было установить в стандартные системные размещения
(например, в /usr/local/include), не затрагивая пространство имён остальной си-
стемы, приняты определённые меры. Во-первых, к путям datadir, sysconfdir и
docdir автоматически добавляется строка «/postgresql», если только полный раз-
вёрнутый путь каталога уже не содержит строку «postgres» или «pgsql». Так, ес-
ли вы выберете в качестве префикса /usr/local, документация будет установлена
в /usr/local/doc/postgresql, но с префиксом /opt/postgres она будет помещена
в /opt/postgres/doc. Внешние заголовочные файлы C для клиентских интерфей-
сов устанавливаются в includedir, не загрязняя пространство имён. Внутренние
и серверные заголовочные файлы устанавливаются в частные подкаталоги внутри
includedir. Чтобы узнать, как обращаться к заголовочным файлам того или иного
интерфейса, обратитесь к документации этого интерфейса. Наконец, для динами-
чески загружаемых модулей, если требуется, будет также создан частный подка-
талог внутри libdir.
–with-extra-version=СТРОКА
Заданная СТРОКА добавляется к номеру версии PostgreSQL. Это можно использовать, на-
пример, чтобы двоичные файлы, собранные из промежуточных снимков Git или кода с до-
полнительными правками, отличались от стандартных дополнительной строкой в версии,
например, содержащей идентификатор git describe или номер выпуска дистрибутивного
пакета.
–with-includes=КАТАЛОГИ
Значение КАТАЛОГИ представляет список каталогов через двоеточие, которые будут про-
смотрены компилятором при поиске заголовочных файлов. Если дополнительные пакеты
(например, GNU Readline) установлены у вас в нестандартное расположение, вам придётся
использовать этот параметр и, возможно, также добавить соответствующий параметр –
with-libraries.
Пример: –with-includes=/opt/gnu/include:/usr/sup/include.
–with-libraries=КАТАЛОГИ
Значение КАТАЛОГИ представляет список каталогов через двоеточие, в котором следует ис-
кать библиотеки. Возможно, вам потребуется использовать этот параметр (и соответству-
ющий –with-includes), если какие-то пакеты установлены у вас в нестандартное разме-
щение.
Пример: –with-libraries=/opt/gnu/lib:/usr/sup/lib.
–enable-nls[=ЯЗЫКИ]
Включает поддержку национальных языков (NLS, Native Language Support), то есть воз-
можность выводить сообщения программы не только на английском языке. Значение ЯЗЫКИ
представляет необязательный список кодов языков через пробел, поддержка которых вам
нужна, например: –enable-nls=’de fr ru’. (Пересечение заданного вами списка и мно-
жества действительно доступных переводов будет вычислено автоматически.) Если список
не задаётся, устанавливаются все доступные переводы.
Для использования этой возможности вам потребуется реализация API Gettext; см. выше.
454Установка из исходного кода
–with-pgport=НОМЕР
Задаёт НОМЕР порта по умолчанию для сервера и клиентов. Стандартное значение — 5432.
Этот порт всегда можно изменить позже, но если вы укажете другой номер здесь, и сервер,
и клиенты будут скомпилированы с одним значением, что очень удобно. Обычно менять
это значение имеет смысл, только если вы намерены запускать в одной системе несколько
серверов PostgreSQL.
–with-perl
Включает поддержку языка PL/Perl на стороне сервера.
–with-python
Включает поддержку языка PL/Python на стороне сервера.
–with-tcl
Включает поддержку языка PL/Tcl на стороне сервера.
–with-tclconfig=КАТАЛОГ
Tcl устанавливает файл tclConfig.sh, содержащий конфигурационные данные, необходи-
мые для сборки модулей, взаимодействующих с Tcl. Этот файл обычно находится автома-
тически в известном размещении, но если вы хотите использовать другую версию Tcl, вы
должны указать каталог, где искать этот файл.
–with-gssapi
Включает поддержку аутентификации GSSAPI. На многих платформах подсистема GSSAPI
(обычно входящая в состав Kerberos) устанавливается не в то размещение, которое просмат-
ривается по умолчанию (например, /usr/include, /usr/lib), так что помимо этого парамет-
ра вам придётся задать параметры –with-includes и –with-libraries. Скрипт configure
проверит наличие необходимых заголовочных файлов и библиотек, чтобы убедиться в це-
лостности инсталляции GSSAPI, прежде чем продолжить.
–with-krb-srvnam=ИМЯ
Задаёт имя по умолчанию для субъекта-службы Kerberos, используемое GSSAPI (по умолча-
нию это postgres). Обычно менять его имеет смысл только в среде Windows, где оно должно
быть задано в верхнем регистре (POSTGRES).
–with-llvm
Включает поддержку JIT-компиляции (см. Главу 32) на базе LLVM. Для этого должна быть
установлена библиотека LLVM. В настоящее время требуется версия LLVM не ниже 3.9.
Программа llvm-configбудет использоваться для выяснения требуемых параметров ком-
пиляции. Поиск её будет выполняться в путях PATH по имени llvm-config, а затем llvm-
config-$major-$minor для всех поддерживаемых версий. Если нужный экземпляр програм-
мы найти таким образом не удастся, воспользуйтесь переменной LLVM_CONFIG и укажите
путь к корректному llvm-config. Например:
./configure … –with-llvm LLVM_CONFIG=’/path/to/llvm/bin/llvm-config’
Для поддержки LLVM требуется совместимый компилятор clang (указываемый, если это
требуется, в переменной окружения CLANG) и работающий компилятор C++ (указываемый,
если требуется, в переменной окружения CXX).
–with-icu
Включает поддержку библиотеки ICU. Для этого должен быть установлен пакет ICU4C. В
настоящее время требуется ICU4C версии не ниже 4.2.
455Установка из исходного кода
По умолчанию для определения нужных параметров компиляции будет использоваться
pkg-config. Этот вариант работает для ICU4C версии 4.6 и новее. Для более старых версий
или в отсутствие pkg-config соответствующие параметры для configure можно задать в пе-
ременных ICU_CFLAGS и ICU_LIBS, как в этом примере:
./configure … –with-icu ICU_CFLAGS=’-I/путь/include’ ICU_LIBS=’-L/путь/lib -
licui18n -licuuc -licudata’
(Даже если ICU4C находится в пути поиска, который использует компилятор, тем не ме-
нее нужно задать непустое значение, чтобы избежать обращения к pkg-config, например,
ICU_CFLAGS=’ ‘.)
–with-openssl
Включает поддержку соединений SSL (зашифрованных). Для этого необходимо установить
пакет OpenSSL. Скрипт configure проверит наличие необходимых заголовочных файлов и
библиотек, чтобы убедиться в целостности инсталляции OpenSSL, прежде чем продолжить.
–with-pam
Включает поддержку PAM(Pluggable Authentication Modules, подключаемых модулей аутен-
тификации).
–with-bsd-auth
Включает поддержку аутентификации BSD. (Инфраструктура аутентификации BSD в насто-
ящее время доступна только в OpenBSD.)
–with-ldap
Включает поддержку LDAPдля проверки подлинности и получения параметров соединения
(за дополнительными сведениями обратитесь к Разделу 34.17 и Разделу 20.10). В Unix для
этого нужно установить пакет OpenLDAP. В Windows используется стандартная библиотека
WinLDAP. Скрипт configure проверит наличие необходимых заголовочных файлов и биб-
лиотек, чтобы убедиться в целостности инсталляции OpenLDAP, прежде чем продолжить.
–with-systemd
Включает поддержку служебных уведомлений для systemd. Это улучшает интеграцию с си-
стемой, когда процесс сервера запускается под управлением systemd, и не оказывает ни-
какого влияния в противном случае; за дополнительными сведениями обратитесь к Разде-
лу 18.3. Для использования этой поддержки в системе должна быть установлена libsystemd
с сопутствующими заголовочными файлами.
–without-readline
Запрещает использование библиотеки Readline (а также libedit). При этом отключается ре-
дактирование командной строки и история в psql, так что этот вариант не рекомендуется.
–with-libedit-preferred
Отдаёт предпочтение библиотеке libedit с лицензией BSD, а не Readline (GPL). Этот пара-
метр имеет значение, только если установлены обе библиотеки; по умолчанию в этом слу-
чае используется Readline.
–with-bonjour
Включает поддержку Bonjour. Для этого Bonjour должен поддерживаться самой операци-
онной системой. Рекомендуется для macOS.
456Установка из исходного кода
–with-uuid=БИБЛИОТЕКА
Собрать модуль uuid-ossp (предоставляющий функции для генерирования UUID), используя
заданную библиотеку UUID.БИБЛИОТЕКА может быть следующей:
• bsd, чтобы использовались функции получения UUID, имеющиеся во FreeBSD, NetBSD
и некоторых других системах на базе BSD
• e2fs, чтобы использовалась библиотека получения UUID, созданная в рамках проекта
e2fsprogs; эта библиотека присутствует в большинстве систем Linux и macOS, также
её можно найти и для других платформ.
• ossp, чтобы использовалась библиотека OSSP UUID
–with-ossp-uuid
Устаревший вариант указания –with-uuid=ossp.
–with-libxml
Собрать с libxml (включает поддержку SQL/XML). Для этого требуется libxml версии 2.6.23
или новее.
В составе libxml устанавливается программа xml2-config, с помощью которой можно полу-
чить требуемые параметры компилятора и компоновщика. PostgreSQL будет использовать
её автоматически, если найдёт. Чтобы указать нестандартное размещение libxml, вы мо-
жете воспользоваться переменной окружения XML2<em>CONFIG и указать в ней путь к програм-
ме xml2-config нужной инсталляции, либо задать параметры –with-includes и –with-
libraries.
–with-libxslt
Использовать libxslt при сборке модуля xml2. Библиотека xml2 задействует её для выпол-
нения XSL-преобразований XML.
–disable-float4-byval
Запрещает передачу типа float4 «по значению», чтобы он передавался «по ссылке». Это
снижает быстродействие, но может быть необходимо для совместимости со старыми поль-
зовательскими функциями на языке C, которые используют соглашение о вызовах «версии
0». В качестве более долгосрочного решения лучше модернизировать такие функции, что-
бы они использовали соглашение «версии 1».
–disable-float8-byval
Запрещает передачу типа float8 «по значению», чтобы он передавался «по ссылке». Это
снижает быстродействие, но может быть необходимо для совместимости со старыми поль-
зовательскими функциями на языке C, которые используют соглашение о вызовах «версии
0». В качестве более долгосрочного решения лучше модернизировать такие функции, что-
бы они использовали соглашение «версии 1». Заметьте, что этот параметр влияет не только
на float8, но и на int8, а также некоторые другие типы, например timestamp. На 32-битных
платформах параметр –disable-float8-byval действует по умолчанию и задать –enable-
float8-byval нельзя.
–with-segsize=РАЗМЕР_СЕГМЕНТА
Задаёт размер сегмента (в гигабайтах). Сервер делит большие таблицы на несколько фай-
лов в файловой системе, ограничивая размер каждого данным размером сегмента. Это поз-
воляет обойти ограничения на размер файлов, существующие на многих платформах. Раз-
мер сегмента по умолчанию, 1 гигабайт, безопасен для всех поддерживаемых платформ. Ес-
ли же ваша операционная система поддерживает «большие файлы» (а сегодня это поддер-
живают почти все), вы можете установить больший размер сегмента. Это позволит умень-
457Установка из исходного кода
шить число файловых дескрипторов, используемых при работе с очень большими таблица-
ми. Но будьте осторожны, чтобы выбранное значение не превысило максимум, поддержи-
ваемый вашей платформой и файловыми системами, которые вы будете применять. Воз-
можно, допустимый размер файла будет ограничиваться и другими утилитами, которые вы
захотите использовать, например tar. Рекомендуется, хотя и не требуется, чтобы это значе-
ние было степенью 2. Заметьте, что при изменении значения требуется выполнить initdb.
–with-blocksize=РАЗМЕР_БЛОКА
Задаёт размер блока (в килобайтах). Эта величина будет единицей хранения и ввода/вывода
данных таблиц. Значение по умолчанию, 8 килобайт, достаточно универсально; но в особых
случаях может быть оправдан другой размер блока. Это значение должно быть степенью
2 от 1 до 32 (в килобайтах). Заметьте, что при изменении значения требуется выполнить
initdb.
–with-wal-blocksize=РАЗМЕР_БЛОКА
Задаёт размер блока WAL (в килобайтах) Эта величина будет единицей хранения и вво-
да/вывода записей WAL. Значение по умолчанию, 8 килобайт, достаточно универсально; но
в особых случаях может быть оправдан другой размер блока. Это значение должно быть
степенью 2 от 1 до 64 (в килобайтах). Заметьте, что при изменении значения требуется
выполнить initdb.
–disable-spinlocks
Позволяет провести сборку, если PostgreSQL не может воспользоваться циклическими бло-
кировками CPU на данной платформе. Отсутствие таких блокировок приводит к снижению
производительности, поэтому использовать этот вариант следует, только если сборка пре-
рывается и выдаётся сообщение, что ваша платформа эти блокировки не поддерживает.
Если вы не можете собрать PostgreSQL на вашей платформе без этого указания, сообщите
о данной проблеме разработчикам PostgreSQL.
–disable-strong-random
Разрешает производить сборку, даже если в PostgreSQL отсутствует поддержка генериро-
вания криптографически стойких случайных ключей на данной платформе. Источник слу-
чайных чисел необходим для некоторых протоколов аутентификации, а также некоторых
функций в модуле pgcrypto. Ключ –disable-strong-random отключает функциональность,
требующую криптографически стойкие случайные числа, и задействует для получения со-
ли и ключей отмены запросов слабый генератор псевдослучайных чисел. Это может сде-
лать аутентификацию менее безопасной.
–disable-thread-safety
Отключает потокобезопасное поведение клиентских библиотек. При этом параллельные
потоки программ на базе libpq и ECPG не будут безопасно контролировать собственные
дескрипторы соединений.
–with-system-tzdata=КАТАЛОГ
В PostgreSQL включена собственная база данных часовых поясов, необходимая для опера-
ций с датой и временем. На самом деле эта база данных совместима с базой часовых поясов
IANA, поставляемой в составе многих операционных систем FreeBSD, Linux, Solaris, поэто-
му устанавливать её дополнительно может быть излишне. С этим параметром вместо базы
данных, включённой в пакет исходного кода PostgreSQL, будет использоваться системная
база данных часовых поясов, находящаяся в заданном КАТАЛОГЕ. КАТАЛОГ должен задавать-
ся абсолютным путём (в ряде операционных систем принят путь /usr/share/zoneinfo). За-
метьте, что процедура установки не будет проверять несоответствия или ошибки в данных
часовых поясов. Поэтому, используя этот параметр, рекомендуется выполнить регрессион-
ные тесты, чтобы убедиться, что выбранная вами база данных часовых поясов работает кор-
ректно с PostgreSQL.
458Установка из исходного кода
Этот параметр в основном предназначен для тех, кто собирает двоичные пакеты для дис-
трибутивов и хорошо знает свою операционную систему. Основной плюс от использова-
ния системных данных в том, что пакет PostgreSQL не придётся обновлять при изменени-
ях местных определений часовых поясов. Ещё один плюс заключается в упрощении кросс-
компиляции, так как при инсталляции не требуется собирать базу данных часовых поясов.
–without-zlib
Запрещает использование библиотеки Zlib. При этом отключается поддержка сжатых ар-
хивов утилитами pg_dump и pg_restore. Этот параметр предназначен только для тех редких
систем, в которых нет этой библиотеки.
–enable-debug
Включает компиляцию всех программ и библиотек с отладочными символами. Это значит,
что вы сможете запускать программы в отладчике для анализа проблем. При такой компи-
ляции размер установленных исполняемых файлов значительно увеличивается, а компи-
ляторы, кроме GCC, обычно отключают оптимизацию, что снижает быстродействие. Одна-
ко, наличие отладочных символов очень полезно при решении возможных проблем любой
сложности. В настоящее время рекомендуется использовать этот параметр для производ-
ственной среды, только если применяется компилятор GCC. Но если вы занимаетесь раз-
работкой или испытываете бета-версию, его следует использовать всегда.
–enable-coverage
При использовании GCC все программы и библиотеки компилируются с инструментарием,
оценивающим покрытие кода тестами. Если его запустить, в каталоге сборки будут сфор-
мированы файлы с метриками покрытия кода. За дополнительными сведениями обратитесь
к Разделу 33.5. Этот параметр предназначен только для GCC и только для использования
в процессе разработки.
–enable-profiling
При использовании GCC все программы и библиотеки компилируются так, чтобы их можно
было профилировать. В результате по завершении серверного процесса будет создаваться
подкаталог с файлом gmon.out для профилирования. Этот параметр предназначен только
для GCC и только для тех, кто занимается разработкой.
–enable-cassert
Включает для сервера проверочные утверждения, проверяющие множество условий, ко-
торые «не должны происходить». Это бесценно в процессе разработке кода, но эти проверки
могут значительно замедлить работу сервера. Кроме того, включение этих проверок не обя-
зательно увеличит стабильность вашего сервера! Проверочные утверждения не категори-
зируются по важности, поэтому относительно безвредная ошибка может привести к пере-
запуску сервера, если утверждение не выполнится. Применять это следует, только если вы
занимаетесь разработкой или испытываете бета-версию, но не в производственной среде.
–enable-depend
Включает автоматическое отслеживание зависимостей. С этим параметром скрипты
Makefile настраиваются так, чтобы при изменении любого заголовочного файла пересоби-
рались все зависимые объектные файлы. Это полезно в процессе разработки, но если вам
нужно только скомпилировать и установить сервер, это будет лишней тратой времени. В
настоящее время это работает только с GCC.
–enable-dtrace
Включает при компиляции PostgreSQL поддержку средства динамической трассировки
DTrace. За дополнительными сведениями обратитесь к Разделу 28.5.
459Установка из исходного кода
Задать расположение программы dtrace можно в переменной окружения DTRACE. Часто
это необходимо, потому что dtrace обычно устанавливается в каталог /usr/sbin, который
может отсутствовать в пути поиска.
Дополнительные параметры командной строки для dtrace можно задать в переменной
окружения DTRACEFLAGS. В Solaris, чтобы включить поддержку DTrace для 64-битной сбор-
ки, необходимо передать configure параметр DTRACEFLAGS=”-64”. Например, с компилято-
ром GCC:
./configure CC=’gcc -m64’ –enable-dtrace DTRACEFLAGS=’-64’ …
С компилятором Sun:
./configure CC=’/opt/SUNWspro/bin/cc -xtarget=native64’ –enable-dtrace
DTRACEFLAGS=’-64’ …
–enable-tap-tests
Включает тесты по технологии Perl TAP. Для этого у вас должен быть установлен Perl и
модуль IPC::Run. За дополнительными сведениями обратитесь к Разделу 33.4.
Если вы предпочитаете компилятор C, отличный от выбираемого скриптом configure, укажи-
те его в переменной CC. По умолчанию configure выбирает gcc (если он находится) или стан-
дартный компилятор платформы (обычно cc). Подобным образом, при необходимости можно
переопределить флаги компилятора по умолчанию с помощью переменной CFLAGS.
Вы можете задать переменные окружения в командной строке configure, например, так:
./configure CC=/opt/bin/gcc CFLAGS=’-O2 -pipe’
Ниже приведён список значимых переменных, которые можно установить таким образом:
BISON
Программа Bison
CC
компилятор C
CFLAGS
параметры, передаваемые компилятору C
CLANG
путь к программе clang, которая будет подготавливать исходный код для встраивания при
компиляции с ключом –with-llvm
CPP
препроцессор C
CPPFLAGS
параметры, передаваемые препроцессору C
CXX
компилятор C++
CXXFLAGS
параметры, передаваемые компилятору C++
460Установка из исходного кода
DTRACE
расположение программы dtrace
DTRACEFLAGS
параметры, передаваемые программе dtrace
FLEX
программа Flex
LDFLAGS
параметры, которые должны использоваться при компоновке исполняемых программ или
разделяемых библиотек
LDFLAGS_EX
дополнительные параметры для компоновки только исполняемых программ
LDFLAGS_SL
дополнительные параметры для компоновки только разделяемых библиотек
LLVM_CONFIG
Программа llvm-config помогает найти инсталляцию LLVM.
MSGFMT
расположение программы msgfmt для поддержки национальных языков
PERL
Полный путь к интерпретатору Perl. Он помогает определить зависимости для сборки PL/
Perl.
PYTHON
Полный путь к интерпретатору Python. Он помогает определить зависимости для сборки
PL/Python. Кроме того, выбранная таким образом (или неявно как-то ещё) версия Python, 2
или 3, определяет вариацию языка PL/Python, которая будет доступна. За дополнительными
сведениями обратитесь к Разделу 46.1.
TCLSH
Полный путь к интерпретатору Tcl. Он помогает определить зависимости для сборки PL/Tcl
и будет подставляться в скрипты Tcl.
XML2_CONFIG
Программа xml2-config помогает найти инсталляцию libxml.
Иногда может быть полезно добавить флаги компилятора к набору флагов, ранее заданному
на этапе configure. В частности, эта потребность объясняется тем, что параметр gcc -Werror
нельзя указать в переменной CFLAGS, передаваемой configure, так как в результате сломаются
многие встроенные тесты configure. Чтобы добавить такие флаги, задайте их в переменной
среды COPT при запуске make. Содержимое COPT будет добавлено в параметры CFLAGS и LDFLAGS,
заданные скриптом configure. Например, вы можете выполнить:
make COPT=’-Werror’
или
export COPT=’-Werror’
461Установка из исходного кода
make
Примечание
Разрабатывая внутренний код сервера, рекомендуется использовать указания
configure –enable-cassert (которое включает множество проверок во время вы-
полнения) и –enable-debug (которое упрощает использование средств отладки).
Используя GCC, лучше выполнять сборку с уровнем оптимизации не ниже -O1, так
как без оптимизации (-O0) отключаются некоторые важные предупреждения ком-
пилятора (например, об использовании неинициализированных переменных). Од-
нако оптимизация ненулевого уровня может затруднить отладку, так как при по-
шаговом выполнении скомпилированный код обычно не соответствует в точности
строкам исходного кода. При возникновении сложностей с отладкой оптимизиро-
ванного кода, перекомпилируйте интересующие вас файлы с ключом -O0. Это мож-
но сделать, просто передав соответствующий параметр make: make PROFILE=-O0
file.o.
На самом деле переменные окружения COPT и PROFILE обрабатываются сборочны-
ми файлами Makefile PostgreSQL одинаково. Поэтому выбор одной из этих перемен-
ных — дело вкуса, но обычно разработчики используют PROFILE для одноразовых
корректив флагов, а содержимое COPT сохраняют постоянным.
2.
Сборка
Чтобы запустить сборку, введите одну из двух команд:
make
make all
(Помните, что нужно использовать GNU make.) Сборка займёт несколько минут, в зависимости
от мощности вашего компьютера. В конце должно появиться сообщение:
All of PostgreSQL successfully made. Ready to install.
(Весь PostgreSQL собран успешно и готов к установке.)
Если вы хотите собрать всё, что может быть собрано, включая документацию (страницы HTML
и man) и дополнительные модули (contrib), введите:
make world
В конце должно появиться сообщение:
PostgreSQL, contrib and documentation successfully made. Ready to install.
(PostgreSQL, contrib и документация собраны успешно и готовы к установке.)
Если вы хотите вызывать сборку из другого сборочного файла, а не вручную, вы должны сбро-
сить переменную MAKELEVEL или присвоить ей 0, например так:
build-postgresql:
$(MAKE) -C postgresql MAKELEVEL=0 all
Если этого не сделать, могут выдаваться странные ошибки, обычно с сообщениями о недоста-
ющих заголовочных файлах.
3.
Регрессионные тесты
Если вы хотите протестировать только что собранный сервер, прежде чем устанавливать его,
на этом этапе вы можете запустить регрессионные тесты. Регрессионные тесты — это комплек-
тов тестов, проверяющих, что PostgreSQL работает на вашем компьютере так, как задумано
разработчиками. Введите:
462Установка из исходного кода
make check
(Это должен выполнять обычный пользователь, не root.) Как интерпретировать результаты про-
верки, подробно описывается в Главе 33. Вы можете повторить эту проверку позже в любой
момент, выполнив ту же команду.
4.
Установка файлов
Примечание
Если вы обновляете существующую систему, обязательно прочитайте инструкции
по обновлению кластера, приведённые в Раздел 18.6.
Чтобы установить PostgreSQL, введите:
make install
При этом файлы будут установлены в каталоги, заданные в Шаг 1. Убедитесь в том, что у вас
есть соответствующие разрешения для записи туда. Обычно это действие нужно выполнять от
имени root. Также возможно заранее создать целевые каталоги и дать требуемый доступ к ним.
Чтобы установить документацию (HTML и страницы man), введите:
make install-docs
Если вы собирали цель world, введите вместо этого:
make install-world
При этом также будет установлена документация.
Вы можете запустить make install-strip вместо make install, чтобы убрать лишнее из уста-
навливаемых исполняемых файлов и библиотек. Это позволит сэкономить немного места. Если
вы выполняете сборку для отладки, при этом фактически вырежется поддержка отладки, по-
этому этот вариант подходит только если отладка больше не планируется. Процедура install-
strip пытается оптимизировать объём разумными способами, но не рассчитывайте, что она
способна удалить каждый ненужный байт из исполняемого файла. Если вы хотите освободить
как можно больше места, вам придётся проделать это вручную.
При стандартной установке в систему устанавливаются все заголовочные файлы для разработ-
ки клиентских приложений, а также программ на стороне сервера, в частности, собственных
функций или типов данных, реализованных на C. (До PostgreSQL 8.0 для этого требовалось вы-
полнить make install-all-headers, но сейчас это включено в стандартную установку.)
Установка только клиентской части:  Если вы хотите установить только клиентские при-
ложения и интерфейсные библиотеки, можно выполнить эти команды:
make
make
make
make
-C
-C
-C
-C
src/bin install
src/include install
src/interfaces install
doc install
В src/bin есть несколько программ, применимых только на сервере, но они очень малы.
Удаление:  Чтобы отменить установку, воспользуйтесь командой make uninstall. Однако со-
зданные каталоги при этом удалены не будут.
Очистка:  После установки вы можете освободить место на диске, удалив файлы сборки из дере-
ва исходного кода, выполнив make clean. При этом файлы, созданные программой configure, бу-
дут сохранены, так что позже вы сможете пересобрать всё заново, выполнив make. Чтобы сбросить
дерево исходного кода к состоянию, в котором оно распространяется, выполните make distclean.
Если вы намерены выполнять сборку одного дерева исходного кода для нескольких платформ, вам
463Установка из исходного кода
придётся делать это и переконфигурировать сборочную среду для каждой. (Также можно исполь-
зовать отдельное дерево сборки для каждой платформы, чтобы дерево исходного кода оставалось
неизменным.)
Если в процессе сборки вы обнаружите, что заданные вами параметры configure оказались оши-
бочными, либо вы изменили что-то, от чего зависит работа configure (например, обновили паке-
ты), стоит выполнить make distclean, прежде чем переконфигурировать и пересобирать всё за-
ново. Если этого не сделать, ваши изменения в конфигурации могут распространиться не везде,
где они важны.
16.5. Действия после установки
16.5.1. Разделяемые библиотеки
В некоторых системах с разделяемыми библиотеками необходимо указать системе, как найти
недавно установленные разделяемые библиотеки. К числу систем, где это не требуется, относятся
FreeBSD, HP-UX, Linux, NetBSD, OpenBSD и Solaris.
Путь поиска разделяемых библиотек на разных платформах может устанавливаться по-разному,
но наиболее распространённый способ — установить переменную окружения LD_LIBRARY_PATH,
например так: в оболочках Bourne (sh, ksh, bash, zsh):
LD_LIBRARY_PATH=/usr/local/pgsql/lib
export LD_LIBRARY_PATH
или в csh, tcsh:
setenv LD_LIBRARY_PATH /usr/local/pgsql/lib
Замените /usr/local/pgsql/lib значением, переданным Шаг 1 в –libdir. Эти команды следу-
ет поместить в стартовый файл оболочки, например, в /etc/profile или ~/.bash_profile. Полез-
ные предостережения об использовании этого метода приведены на странице http://xahlee.info/
UnixResource_dir/</em>/ldpath.html.
В некоторых системах предпочтительнее установить переменную окружения LD_RUN_PATH до сбор-
ки.
В Cygwin добавьте каталог с библиотеками в PATH или переместите файлы .dll в каталог bin.
В случае сомнений обратитесь к страницам руководства по вашей системе (возможно, к справке
по ld.so или rld). Если вы позже получаете сообщение:
psql: error in loading shared libraries
libpq.so.2.1: cannot open shared object file: No such file or directory
(psql: ошибка при загрузке разделяемых библиотек libpq.so.2.1: не удалось открыть разделяемый
объектный файл: Нет такого файла или каталога), значит этот шаг был необходим. Тогда вам про-
сто нужно вернуться к нему.
Если вы используете Linux и имеете права root, вы можете запустить:
/sbin/ldconfig /usr/local/pgsql/lib
(возможно, с другим каталогом) после установки, чтобы механизм связывания во время выполне-
ния мог найти разделяемые библиотеки быстрее. За дополнительными сведениями обратитесь к
странице руководства по ldconfig. Во FreeBSD, NetBSD и OpenBSD команда будет такой:
/sbin/ldconfig -m /usr/local/pgsql/lib
В других системах подобной команды может не быть.
16.5.2. Переменные окружения
Если целевым каталогом был выбран /usr/local/pgsql или какой-то другой, по умолчанию отсут-
ствующий в пути поиска, вам следует добавить /usr/local/pgsql/bin (или другой путь, передан-
464Установка из исходного кода
ный Шаг 1 в указании –bindir) в вашу переменную PATH. Строго говоря, это не обязательно, но
при этом использовать PostgreSQL будет гораздо удобнее.
Для этого добавьте в ваш скрипт запуска оболочки, например ~/.bash_profile (или в /etc/
profile, если это нужно всем пользователям):
PATH=/usr/local/pgsql/bin:$PATH
export PATH
Для оболочек csh или tcsh команда должна быть такой:
set path = ( /usr/local/pgsql/bin $path )
Чтобы ваша система могла найти документацию man, вам нужно добавить в скрипт запуска обо-
лочки примерно следующие строки, если только она не установлена в размещение, просматрива-
емое по умолчанию:
MANPATH=/usr/local/pgsql/share/man:$MANPATH
export MANPATH
Переменные окружения PGHOST и PGPORT задают для клиентских приложений адрес компьютера
и порт сервера базы данных, переопределяя стандартные значения. Если планируется запускать
клиентские приложения удалённо, пользователям, которые будут использовать определённый сер-
вер, будет удобно, если они установят PGHOST. Однако это не обязательно, так как большинство
клиентских программ могут принять эти параметры через аргументы командной строки.
16.6. Поддерживаемые платформы
Платформа (то есть комбинация архитектуры процессора и операционной системы) считается под-
держиваемой сообществом разработчиков PostgreSQL, если код адаптирован для работы на этой
платформе, и он в настоящее время успешно собирается и проходит регрессионные тесты на ней.
В настоящее время тестирование совместимости в основном выполняется автоматически в Ферме
сборки PostgreSQL. Если вы заинтересованы в использовании PostgreSQL на платформе, ещё не
представленной в ферме сборки, но уверены, что код на ней работает или может работать, мы
очень хотели бы, чтобы вы включили в ферму сборки свой компьютер с этой платформой для по-
стоянной гарантии совместимости.
Вообще следует ожидать, что PostgreSQL будет работать на процессорах следующих архитектур:
x86, x86_64, IA64, PowerPC, PowerPC 64, S/390, S/390x, Sparc, Sparc 64, ARM, MIPS, MIPSEL и PA-
RISC. Есть также код для поддержки M68K, M32R и VAX, но неизвестно, проверялась ли его ра-
бота в последнее время. Часто сервер можно собрать для неподдерживаемого типа процессора,
сконфигурировав сборку с указанием –disable-spinlocks, но производительность при этом бу-
дет неудовлетворительной.
Также следует ожидать, что сервер PostgreSQL будет работать в следующих операционных си-
стемах: Linux (все последние дистрибутивы), Windows (Win2000 SP4 и новее), FreeBSD, OpenBSD,
NetBSD, macOS, AIX, HP/UX и Solaris. Возможна также работа в других Unix-подобных системах,
но в настоящее время она не проверяется. При этом в большинстве случаев он будет работать на
процессорах всех архитектур, поддерживаемых данной операционной системой. Перейдите к Раз-
делу 16.7 и проверьте, нет ли там замечаний, относящихся именно к вашей операционной системе,
особенно если вы используете не самую новую систему.
Если вы столкнулись с проблемами установки на платформе, которая считается поддерживаемой
согласно последним результатам сборки в нашей ферме, пожалуйста, сообщите о них по адресу
<a href="mailto:pgsql-bugs@postgresql.org">pgsql-bugs@postgresql.org</a>. Если вы заинтересованы в переносе PostgreSQL на новую платфор-
му, обсудить это можно в рассылке <a href="mailto:pgsql-hackers@postgresql.org">pgsql-hackers@postgresql.org</a>.
16.7. Замечания по отдельным платформам
В этом разделе приведены дополнительные замечания по отдельным платформам, связанные с
установкой и подготовкой к работе PostgreSQL. Обязательно изучите ещё инструкции по установ-
465Установка из исходного кода
ке, в частности Раздел 16.2. Также обратитесь к Главе 33, где рассказывается, как прочитать ре-
зультаты регрессионных тестов.
Если какие-то платформы здесь не упоминаются, значит каких-либо известных особенностей уста-
новки в них нет.
16.7.1. AIX
PostgreSQL работает в AIX, но установить его правильно может быть непростой задачей. Поддер-
живаемыми считаются версии AIX с 4.3.3 до 6.1. Для сборки вы можете применить GCC или соб-
ственный компилятор IBM xlc. Вообще говоря, полезно использовать последние версии AIX и
PostgreSQL. Получить актуальную информацию о версиях AIX, работа в которых проверена на дан-
ный момент, можно на сайте фермы сборки.
Минимальные рекомендуемые уровни исправлений для поддерживаемых версий AIX:
AIX 4.3.3
Эксплуатационный уровень (ML) 11 + пакет исправлений после ML11
AIX 5.1
Эксплуатационный уровень (ML) 9 + пакет исправлений после ML9
AIX 5.2
Технологический уровень (TL) 10, Пакет обновлений (SP) 3
AIX 5.3
Технологический уровень (TL) 7
AIX 6.1
Базовый уровень
Чтобы проверить ваш текущий уровень исправлений, выполните oslevel -r в AIX версии с 4.3.3
по 5.2 ML 7, либо oslevel -s в более поздних версиях.
Если Readline или libz у вас установлены не в /usr/local, передайте configure следующие ключи
в дополнение к вашим: –with-includes=/usr/local/include –with-libraries=/usr/local/lib.
16.7.1.1. Особенности использования GCC
В AIX 5.3 наблюдались проблемы с компиляцией и запуском PostgreSQL с использованием GCC.
Для успешной сборки вам потребуется GCC версии новее 3.3.2, особенно, если вы используете
версию из системного пакета. Мы добивались успеха с 4.0.1. Проблемы с предыдущими версиями,
судя по всему, были связаны больше с тем, как IBM упаковала GCC, а не собственно с GCC, поэтому
если вы скомпилируете GCC самостоятельно, положительный исход возможен и с ранней версией
GCC.
16.7.1.2. Неработающие Unix-сокеты
В AIX 5.3 была проблема с размером структуры sockaddr_storage. В версии 5.3 IBM увеличила
размер sockaddr_un, структуры адреса для Unix-сокетов, но не увеличила соответственно размер
sockaddr_storage. В итоге при попытке PostgreSQL использовать Unix-сокеты происходило пере-
полнение этой структуры в libpq. Подключение через TCP/IP устанавливается корректно, а через
Unix-сокеты — нет, и в результате регрессионные тесты не проходят.
Об этой проблеме было сообщено IBM, она зафиксирована в отчёте об ошибке PMR29657. Если вы
обновите систему до эксплуатационного уровня 5300-03 или новее, она получит соответствующее
исправление. В качестве временного решения можно присвоить _SS_MAXSIZE значение 1025 в /
usr/include/sys/socket.h. В любом случае, после исправления этого заголовочного файла пере-
компилируйте PostgreSQL.
466Установка из исходного кода
16.7.1.3. Проблемы с сетевыми адресами
PostgreSQL пользуется системной функцией getaddrinfo для разбора IP-адресов, указанных в па-
раметре listen_addresses, файле pg_hba.conf и т. д. В старых версиях AIX эта функция работала
некорректно. Если вы столкнулись с проблемами в этой области, обновление до уровня исправле-
ний AIX, обозначенного выше, должно решить их.
Один пользователь сообщает:
Используя PostgreSQL версии 8.1 в AIX 5.3, мы периодически сталкивались с тем, что сборщик
статистики «загадочным образом» не запускается. Кажется, это результат незапланированного
поведения реализации IPv6. Похоже, что PostgreSQL и IPv6 не дружат в AIX 5.3.
Для «решения» проблемы можно выполнить одно из следующих действий.
• Удалите адрес IPv6 для localhost:
(от имени root)</p>
<h1 id="ifconfig-lo0-inet6-10-delete">ifconfig lo0 inet6 ::1/0 delete</h1>
<p>• Удалите IPv6 из сетевых сервисов. Файл /etc/netsvc.conf в AIX примерно соответствует фай-
лу /etc/nsswitch.conf в Solaris/Linux. По умолчанию в AIX он выглядит так:
hosts=local,bind
Чтобы отключить поиск адресов IPv6, замените его содержимое следующим:
hosts=local4,bind4
Предупреждение
К этим временным решениям приходилось прибегать из-за проблем, связанных с сырой
реализацией IPv6, которая заметно улучшилась в последующих выпусках AIX 5.3. Эти
решения работали в AIX версии 5.3, но они конечно далеки от идеальных. Кроме того,
сообщалось, что они не только не требуются, но и приводят к другим проблемам в AIX
6.1, где поддержка IPv6 стала более зрелой.
16.7.1.4. Управление памятью
Иногда управление памятью в AIX может работать несколько странно. В системе может быть сво-
бодно несколько гигабайт ОЗУ, но при запуске приложений всё равно возможны ошибки, связан-
ные с адресным пространством или нехваткой памяти. В частности, необычные ошибки могут воз-
никать при загрузке расширений. Например, при выполнении от имени владельца инсталляции
PostgreSQL:
=# CREATE EXTENSION plperl;
ERROR: could not load library “/opt/dbs/pgsql/lib/plperl.so”: A memory address is not
in the address space for the process.
(ОШИБКА: не удалось загрузить библиотеку “/opt/dbs/pgsql/lib/plperl.so”: Адрес памяти находит-
ся не в адресном пространстве процесса.) При выполнении от имени не владельца, а члена груп-
пы-владельца инсталляции PostgreSQL:
=# CREATE EXTENSION plperl;
ERROR: could not load library “/opt/dbs/pgsql/lib/plperl.so”: Bad address
(ОШИБКА: не удалось загрузить библиотеку “/opt/dbs/pgsql/lib/plperl.so”: Неверный адрес) Также
сообщения о нехватке могут появляться в журнале PostgreSQL при попытке выделить блок памяти
размером около 256 МиБ или больше.
Общая причина всех этих проблем связана с битностью и моделью памяти серверного процесса.
По умолчанию все исполняемые файлы для AIX собираются как 32-битные, вне зависимости от
того, какой тип оборудования или ядра используется. Такие 32-битные процессы ограничиваются
467Установка из исходного кода
общим пространством в 4 ГиБ, разделённым на сегменты по 256 МиБ, по одной из нескольких
моделей. По умолчанию в куче можно выделить меньше 256 МиБ, так как она разделяет один
сегмент со стеком.
В ситуации с показанным выше примером plperl проверьте umask и разрешения, назначенные
для двоичных файлов в вашей инсталляции PostgreSQL. Задействованные в данном примере дво-
ичные файлы были 32-битными и установились с режимом 750 вместо 755. Из-за таких разреше-
ний только владелец или член группы-владельца могли загрузить требуемую библиотеку. Так как
она недоступна для чтения всем, загрузчик помещал этот объект в область кучи процесса, а не в
сегменты разделяемых библиотек, где он должен находиться.
В «идеале» эту проблему можно решить, если использовать 64-битную сборку PostgreSQL, но это не
всегда практично, так как с 32-битным процессором нельзя будет запустить 64-битный код (можно
только собрать).
При желании использовать 32-битную версию сервера установите в LDR_CNTRL значение
MAXDATA=0xn0000000, где 1 &lt;= n &lt;= 8, до запуска PostgreSQL, и попробуйте подобрать подходя-
щее значение и параметры postgresql.conf. Переменная окружения LDR_CNTRL говорит AIX, что
вы хотите, чтобы сервер получил MAXDATA байт для области кучи, в сегментах по 256 МиБ. Подо-
брав рабочее значение, можно воспользоваться ldedit и модифицировать двоичные файлы, чтобы
они использовали такой размер кучи по умолчанию. Тот же эффект можно получить, пересобрав
PostgreSQL с указанием configure LDFLAGS=”-Wl,-bmaxdata:0xn0000000”.
Для 64-битной сборки определите переменную OBJECT_MODE со значением 64 и передайте
configure указания CC=”gcc -maix64” и LDFLAGS=”-Wl,-bbigtoc”. (Для xlc параметры могут быть
другими.) Если нужное значение OBJECT_MODE не будет экспортировано, при сборке могут произой-
ти ошибки на стадии компоновки. Когда переменная OBJECT_MODE установлена, она говорит сбо-
рочным утилитам AIX, таким как ar, as и ld, какие типы объектов обрабатывать по умолчанию.
По умолчанию система может чрезмерно выделять память в пространстве подкачки. Хотя нам не
приходилось с этим сталкиваться, AIX уничтожает процессы при попытке обращения к чрезмерно
выделенной памяти, когда её фактически не хватает. Наиболее близкое, что мы наблюдали, была
ошибка порождения процесса из-за того, что система решала, что для него не хватает памяти. Как
и многие другие компоненты AIX, механизмы распределения пространства подкачки и уничтоже-
ния процессов при нехватке памяти можно настроить на уровне системы или процесса, если воз-
никают подобные проблемы.
Ссылки и ресурсы
«Large Program Support». Документация AIX: Общие концепции программирования: Написание и
отладка программ.
«Program Address Space Overview». Документация AIX: Общие концепции программирования: На-
писание и отладка программ.
«Performance Overview of the Virtual Memory Manager (VMM)». Документация AIX: Руководство по
управлению производительностью.
«Page Space Allocation». Документация AIX: Руководство по управлению производительностью.
«Paging-space thresholds tuning». Документация AIX: Руководство по управлению производитель-
ностью.
Developing and Porting C and C++ Applications on AIX. Красная книга IBM.
16.7.2. Cygwin
PostgreSQL можно собрать с применением Cygwin, Linux-подобной среды для Windows, но сейчас
этому методу предпочитается обычная сборка в Windows (см. Главу 17), и запускать сервер в среде
Cygwin более не рекомендуется.
468Установка из исходного кода
Выполняя сборку, следуйте обычной процедуре установки (т. е., ./configure; make; и т. д.), с
учётом следующих особенностей Cygwin:
• Настройте путь поиска так, чтобы каталог bin в Cygwin стоял перед каталогами утилит
Windows. Это поможет избавиться от проблем при компиляции.
• Команда adduser не поддерживается; воспользуйтесь соответствующим средством управле-
ния пользователями для Windows NT, 2000 или XP. Либо просто пропустите этот шаг.
• Команда su не поддерживается; для эмуляции su в Windows NT, 2000 или XP воспользуйтесь
ssh. Либо пропустите этот шаг.
• OpenSSL не поддерживается.
• Запустите cygserver для поддержки разделяемой памяти. Для этого введите команду /usr/
sbin/cygserver &amp;. Эта программа должна работать всегда при запуске сервера PostgreSQL
или инициализации кластера баз данных (initdb). Возможно, вам придётся настроить конфи-
гурацию cygserver (например, увеличить SEMMNS), чтобы PostgreSQL мог получить требуемые
системные ресурсы.
• Сборка может завершиться ошибкой в некоторых системах, где используется локаль, отлич-
ная от C. Чтобы исправить это, выберите локаль C, выполнив export LANG=C.utf8 до сборки, а
затем восстановите предыдущее значение после установки PostgreSQL.
• Параллельные регрессионные тесты (make check) могут выдавать ложные ошибки тестиро-
вания при переполнении очереди listen(), из-за чего подключения могут не устанавливать-
ся или зависать. Вы можете ограничить число подключений, определив переменную make
MAX_CONNECTIONS так:
make MAX_CONNECTIONS=5 check
(В некоторых системах поддерживается до 10 одновременных подключений).
Сервер PostgreSQL и cygserver можно запустить в виде служб Windows NT. Как это сделать, рас-
сказывается в описании README, включённом в двоичный пакет PostgreSQL для Cygwin. Оно уста-
навливается в каталог /usr/share/doc/Cygwin.
16.7.3. HP-UX
PostgreSQL 7.3+ должен работать на машинах Series 700/800 PA-RISC под управлением HP-UX 10.X
или 11.X, с подходящими уровнями системных исправлений и средствами сборки. Как минимум
один разработчик регулярно тестирует сборку в HP-UX 10.20, и мы получали сообщения об успеш-
ных установках в HP-UX 11.00 и 11.11.
Помимо пакета исходного кода PostgreSQL, вам потребуется GNU make (HP make не подойдёт) и
GCC или полный компилятор ANSI C от HP. Если вы намерены выполнить сборку не из дистрибутив-
ного пакета исходного кода, а из Git, вам также потребуется Flex (GNU lex) и Bison (GNU yacc). Мы
также рекомендуем убедиться, что у вас установлены довольно свежие исправления HP. Для сбор-
ки 64-битного кода в HP-UX 11.11 вам потребуется PHSS_30966 (11.11) или более новое исправле-
ние, без него initdb может зависать. Как правило, для сборки нужно иметь текущие исправления
libc и ld/dld, а также компилятора (если вы используете компилятор HP). Получить эти исправле-
ния бесплатно можно на сайтах поддержки HP (например здесь: ftp://us-ffs.external.hp.com/).
Если вы проводите сборку на машине PA-RISC 2.0 и хотите получить 64-битный исполняемый код,
вы должны использовать 64-битную версию GCC.
Если вы проводите сборку на машине PA-RISC 2.0 и хотите, чтобы скомпилированный код запус-
кался на машинах PA-RISC 1.1, также потребуется указать +DAportable в CFLAGS.
Если вы проводите сборку на машине HP-UX Itanium, вам потребуется последний компилятор ANSI
C от HP с соответствующим исправлением или более новыми:
PHSS_30848 s700_800 HP C Compiler (A.05.57)
469Установка из исходного кода
PHSS_30849 s700_800 u2comp/be/plugin library Patch
Если вы используете компилятор HP C и GCC, может потребоваться явно выбрать предпочитаемый
компилятор при запуске configure:
./configure CC=cc
для использования компилятора C от HP, либо
./configure CC=gcc
для выбора GCC. При отсутствии явного указания configure выберет gcc, если есть такая возмож-
ность.
По умолчанию целевой каталог установки — /usr/local/pgsql, но вы, возможно, захотите его
изменить на другой, внутри /opt. В этом случае передайте его configure с ключом –prefix.
В регрессионных тестах возможны отклонения при геометрических проверках, в наименее знача-
щих цифрах, в зависимости от применяемого компилятора и математической библиотеки. Любые
другие ошибки заслуживают внимания.
16.7.4. macOS
В последних версиях macOS необходимо включать путь «sysroot» во флаги include, позволяющие
найти некоторые системные заголовочные файлы. Как результат, вывод скрипта configure может
меняться в зависимости от того, какая версия SDK использовалась в процессе configure. Это не
должно создавать никаких проблем в простых сценариях, но если вы попытаетесь, например, со-
брать расширение не на той машине, где был собран серверный код, то может потребоваться явно
указать другой путь sysroot. В этом случае установите PG_SYSROOT, например, так:
make PG_SYSROOT=/требуемый/путь all
Чтобы узнать правильный путь на вашей машине, выполните:
xcodebuild -version -sdk macosx Path
Заметьте, что собирать расширения с версией sysroot, отличной от той, с которой собиралось ядро
сервера, не рекомендуется; в худшем случае это приведёт к труднодиагностируемым несогласо-
ванностям ABI.
Также при конфигурировании вы можете задать sysroot, отличный от подразумеваемого по умол-
чанию, передав PG_SYSROOT скрипту configure:
./configure … PG_SYSROOT=/требуемый/путь
Функциональность «Защита целостности системы» (System Integrity Protection, SIP) в macOS нару-
шает работу make check, так как она не позволяет передавать нужное значение DYLD_LIBRARY_PATH
тестируемым исполняемым файлам. Обойти эту проблему можно, выполнив make install перед
make check. Однако большинство разработчиков Postgres просто отключают SIP.
16.7.5. MinGW/Собственная сборка Windows
PostgreSQL для Windows можно собрать с использованием MinGW, Unix-подобной среды сборки для
операционных систем Microsoft, либо используя набор средств разработки Microsoft Visual C++.
При использовании MinGW применяется обычная система сборки, описанная в этой главе; сборка
Visual C++ выполняется по-другому, как описано в Главе 17. Это полностью естественная сборка
для Windows, для которой не требуется дополнительное ПО вроде MinGW. Готовый инсталлятор
для Windows можно найти на сайте PostgreSQL.
PostgreSQL, портированный в Windows, будет работать в 32- или 64-битной версии Windows 2000
или новее. В предыдущих операционных системах нет достаточной инфраструктуры (но там мож-
но использовать Cygwin). MinGW, Unix-подобные средства сборки, и MSYS, набор утилит Unix, тре-
буемых для исполнения скриптов типа configure, можно загрузить с сайта http://www.mingw.org/.
470Установка из исходного кода
Эти дополнительные программы нужны только для сборки, для запуска полученных исполняемых
файлов они не требуются.
Чтобы собрать 64-битную версию с использованием MinGW, установите набор 64-битных утилит с
https://mingw-w64.org/, добавьте путь к его каталогу bin в PATH и запустите configure с параметром
–host=x86_64-w64-mingw32.
Когда вы всё установите, запускать psql предлагается из CMD.EXE, так как в консоли MSYS есть
проблемы с буферизацией.
16.7.5.1. Сбор аварийных дампов в Windows
В случае аварии PostgreSQL в Windows он может сгенерировать минидамп памяти, который по-
могает выяснить причину аварии, подобно дампам памяти в Unix. Проанализировать эти дампы
можно, используя Windows Debugger Tools (Средства отладки Windows) или Visual Studio. Чтобы в
Windows получить дамп в случае аварии, создайте подкаталог crashdumps в каталоге данных кла-
стера. Дампы будут записываться в этот каталог с уникальным именем, составленным из иденти-
фикатора процесса, давшего сбой, и времени сбоя.
16.7.6. Solaris
PostgreSQL хорошо поддерживается в Solaris. Чем новее операционная система, тем меньше за-
труднений будет; подробнее об этом ниже.
16.7.6.1. Требуемые инструменты
Вы можете выполнить сборку с GCC или с набором компиляторов Sun. Для лучшей оптимизации
кода на архитектуре SPARC настоятельно рекомендуется использовать компилятор Sun. Мы слы-
шали о проблемах с GCC 2.95.1, поэтому рекомендуется использовать GCC 2.95.3 или новее. Если
вы решили применить компилятор Sun, не выберите по ошибке /usr/ucb/cc; правильный путь —
/opt/SUNWspro/bin/cc.
Sun Studio вы можете загрузить с сайта https://www.oracle.com/technetwork/server-storage/
solarisstudio/downloads/. Средства GNU по большей части интегрированы в Solaris 10, либо пред-
ставлены на сопутствующем CD. Если вам нужны пакеты для старых версий Solaris, вы можете
найти их на сайте http://www.sunfreeware.com. Если вы предпочитаете исходный код, обратитесь
к https://www.gnu.org/prep/ftp.
16.7.6.2. Процедура configure сообщает о сбое тестовой программы
Если configure сообщает о сбое тестовой программы, это может быть вызвано тем, что при связы-
вании во время выполнения не удаётся найти некоторую библиотеку, вероятно, libz, libreadline или
какую-то другую нестандартную, например, libssl. Чтобы указать правильное размещение библио-
теки, задайте переменную окружения LDFLAGS в командной строке configure, например так:
configure … LDFLAGS=”-R /usr/sfw/lib:/opt/sfw/lib:/usr/local/lib”
За дополнительными сведениями обратитесь к странице man ld.
16.7.6.3. Периодические сбои 64-битной сборки
В Solaris 7 и старее 64-битная версия libc содержала бракованную функцию vsnprintf, которая
могла вызывать непредсказуемые сбои PostgreSQL. Самое простое известное решение — сделать,
чтобы PostgreSQL использовал собственную версию vsnprintf вместо библиотечной версии. Для
этого, выполнив configure, отредактируйте полученный в результате configure файл. В src/
Makefile.global поменяйте строку
LIBOBJS =
на такую
LIBOBJS = snprintf.o
471Установка из исходного кода
(В этой переменной уже также могут быть перечислены и другие файлы.) Затем продолжите сбор-
ку как обычно.
16.7.6.4. Компиляция для максимальной производительности
Для архитектуры SPARC настоятельно рекомендуется проводить компиляцию с использованием
Sun Studio. Добавив флаг -xO5, вы можете получить исполняемый код, который будет работать
значительно быстрее. Но не добавляйте никакие флаги, влияющие на вычисления с плавающей
точкой или обработку errno (например, -fast). С такими флагами PostgreSQL может вести себя
нестандартно, например, выполняя операции с датами/временем.
Если у вас нет причины использовать 64-битные программы в архитектуре SPARC, собирайте 32-
битную версию, так как 64-битные операции, а значит и 64-битные программы, выполняются мед-
леннее 32-битных. С другой стороны, 32-битный код для процессоров семейства AMD64 не явля-
ется «родным», поэтому на таких процессорах значительно медленнее работает 32-битный код.
16.7.6.5. Применение DTrace для трассировки PostgreSQL
Да, вы можете использовать DTrace. За дополнительными сведениями обратитесь к Разделу 28.5.
Если компоновка исполняемого файла postgres прерывается с таким сообщением об ошибке:
Undefined
first referenced
symbol
in file
AbortTransaction
utils/probes.o
CommitTransaction
utils/probes.o
ld: fatal: Symbol referencing errors. No output written to postgres
collect2: ld returned 1 exit status
make: *** [postgres] Error 1
Это означает, что ваша инсталляция DTrace слишком стара и неспособна работать с пробами в
статических функциях. В этом случае вам нужна версия Solaris 10u4 или новее.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-015/" title="Глава 15. Параллельный запрос"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 15. Параллельный запрос"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-015/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~14 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-015/" rel="bookmark" title="Глава 15. Параллельный запрос" itemprop="url">Глава 15. Параллельный запрос</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 15. Параллельный запрос</p>

<p>PostgreSQL может вырабатывать такие планы запросов, которые будут задействовать несколько
CPU, чтобы получить ответ на запросы быстрее. Эта возможность называется распараллеливанием
запросов. Для многих запросов параллельное выполнение не даёт никакого выигрыша, либо из-за
ограничений текущей реализации, либо из-за принципиальной невозможности построить парал-
лельный план, который был бы быстрее последовательного. Однако для запросов, в которых это
может быть полезно, распараллеливание часто даёт очень значительное ускорение. Многие та-
кие запросы могут выполняться в параллельном режиме как минимум двое быстрее, а некоторые
— быстрее в четыре и даже более раз. Обычно наибольший выигрыш можно получить с запроса-
ми, обрабатывающими большой объём данных, но возвращающими пользователю всего несколько
строк. В этой главе достаточно подробно рассказывается, как работают параллельные запросы и в
каких ситуациях их можно использовать, чтобы пользователи, желающие применять их, понима-
ли, чего ожидать.
15.1. Как работают параллельно выполняемые запро-
сы
Когда оптимизатор определяет, что параллельное выполнение будет наилучшей стратегией для
конкретного запроса, он создаёт план запроса, включающий узел Gather (Сбор) или Gather Merge
(Сбор со слиянием). Взгляните на простой пример:
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE ‘%x%’;
QUERY PLAN
————————————————————————————-
Gather (cost=1000.00..217018.43 rows=1 width=97)
Workers Planned: 2
-&gt; Parallel Seq Scan on pgbench_accounts (cost=0.00..216018.33 rows=1 width=97)
Filter: (filler ~~ ‘%x%’::text)
(4 rows)
Во всех случаях узел Gather или Gather Merge будет иметь ровно один дочерний план, представ-
ляющий часть общего плана, выполняемую в параллельном режиме. Если узел Gather или Gather
Merge располагается на самом верху дерева плана, в параллельном режиме будет выполняться весь
запрос. Если он находится где-то в другом месте плана, параллельно будет выполняться только
часть плана ниже него. В приведённом выше примере запрос обращается только к одной таблице,
так что помимо узла Gather есть только ещё один узел плана; и так как этот узел является потом-
ком узла Gather, он будет выполняться в параллельном режиме.
Используя EXPLAIN, вы можете узнать количество исполнителей, выбранное планировщиком
для данного запроса. Когда при выполнении запроса достигается узел Gather, процесс, обслу-
живающий сеанс пользователя, запрашивает фоновые рабочие процессы в этом количестве. Ко-
личество исполнителей, которое может попытаться задействовать планировщик, ограничива-
ется значением max_parallel_workers_per_gather. Общее число фоновых рабочих процессов, ко-
торые могут существовать одновременно, ограничивается параметрами max_worker_processes
и max_parallel_workers. Таким образом, вполне возможно, что параллельный запрос будет
выполняться меньшим числом рабочих процессов, чем планировалось, либо вообще без до-
полнительных рабочих процессов. Оптимальность плана может зависеть от числа доступ-
ных рабочих процессов, так что их нехватка может повлечь значительное снижение произ-
водительности. Если это наблюдается часто, имеет смысл увеличить max_worker_processes и
max_parallel_workers, чтобы одновременно могло работать больше процессов, либо наоборот
уменьшить max_parallel_workers_per_gather, чтобы планировщик запрашивал их в меньшем ко-
личестве.
Каждый фоновый рабочий процесс, успешно запущенный для данного параллельного запроса, бу-
дет выполнять параллельную часть плана. Ведущий процесс также будет выполнять эту часть пла-
на, но он несёт дополнительную ответственность: он должен также прочитать все кортежи, выдан-
ные рабочими процессами. Когда параллельная часть плана выдаёт лишь небольшое количество
443Параллельный запрос
кортежей, ведущий часто ведёт себя просто как один из рабочих процессов, ускоряя выполнение
запроса. И напротив, когда параллельная часть плана выдаёт множество кортежей, ведущий мо-
жет быть почти всё время занят чтением кортежей, выдаваемых другими рабочими процессами, и
выполнять другие шаги обработки, связанные с узлами плана выше узла Gather или Gather Merge.
В таких случаях ведущий процесс может вносить лишь минимальный вклад в выполнение парал-
лельной части плана.
Когда над параллельной частью плана оказывается узел Gather Merge, а не Gather, это означает,
что все процессы, выполняющие части параллельного плана, выдают кортежи в отсортированном
порядке, и что ведущий процесс выполняет слияние с сохранением порядка. Узел же Gather, на-
против, получает кортежи от подчинённых процессов в произвольном удобном ему порядке, нару-
шая порядок сортировки, который мог существовать.
15.2. Когда может применяться распараллеливание за-
просов?
Планировщик запросов может отказаться от построения параллельных планов запросов в любом
случае под влиянием нескольких параметров. Чтобы он строил параллельные планы запросов при
каких-бы то ни было условиях, описанные далее параметры необходимо настроить указанным об-
разом.
• max_parallel_workers_per_gather должен иметь значение, большее нуля. Это особый вариант
более общего ограничения на суммарное число используемых рабочих процессов, задаваемо-
го параметром max_parallel_workers_per_gather.
• dynamic_shared_memory_type должен иметь значение, отличное от none. Для параллельного
выполнения запросов нужна динамическая общая память, через которую будут передаваться
данные между взаимодействующими процессами.
В дополнение к этому, система должна работать не в однопользовательском режиме. Так как в
этом режиме вся СУБД работает в одном процессе, фоновые рабочие процессы в нём недоступны.
Даже если принципиально возможно построить параллельные планы выполнения, планировщик
не будет строить такой план для определённого запроса, если имеет место одно из следующих
обстоятельств:
• Запрос выполняет запись данных или блокирует строки в базе данных. Если запрос содержит
операцию, изменяющую данные либо на верхнем уровне, либо внутри CTE, для такого запроса
не будут строиться параллельные планы. Исключение составляют команды CREATE TABLE …
AS, SELECT INTO и CREATE MATERIALIZED VIEW, которые создают новую таблицу и наполняют
её, и при этом могут использовать параллельный план.
• Запрос может быть приостановлен в процессе выполнения. В ситуациях, когда система реша-
ет, что может иметь место частичное или дополнительное выполнение, план параллельного
выполнения не строится. Например, курсор, созданный предложением DECLARE CURSOR, ни-
когда не будет использовать параллельный план. Подобным образом, цикл PL/pgSQL вида FOR
x IN query LOOP .. END LOOP никогда не будет использовать параллельный план, так как си-
стема параллельных запросов не сможет определить, может ли безопасно выполняться код
внутри цикла во время параллельного выполнения запроса.
• В запросе используются функции, помеченные как PARALLEL UNSAFE. Большинство систем-
ных функций безопасны для параллельного выполнения (PARALLEL SAFE), но пользовательские
функции по умолчанию помечаются как небезопасные (PARALLEL UNSAFE). Эта характеристика
функции рассматривается в Разделе 15.4.
• Запрос работает внутри другого запроса, уже параллельного. Например, если функция, вызы-
ваемая в параллельном запросе, сама выполняет SQL-запрос, последний запрос никогда не
будет выполняться параллельно. Это ограничение текущей реализации, но убирать его вряд
ли следует, так как это может привести к использованию одним запросом чрезмерного коли-
чества процессов.
444Параллельный запрос
• Для транзакции установлен сериализуемый уровень изоляции. Это ограничение текущей реа-
лизации.
Даже когда для определённого запроса построен параллельный план, возможны различные обсто-
ятельства, при которых этот план нельзя будет выполнить в параллельном режиме. В этих случаях
ведущий процесс выполнит часть плана ниже узла Gather полностью самостоятельно, как если бы
узла Gather вовсе не было. Это произойдёт только при выполнении одного из следующих условий:
• Невозможно получить ни одного фонового рабочего процесса из-за ограничения общего чис-
ла этих процессов значением max_worker_processes.
• Невозможно получить ни одного фонового рабочего процесса из-за ограничения общего чис-
ла таких процессов для параллельного выполнения значением max_parallel_workers.
• Клиент передаёт сообщение Execute с ненулевым количеством выбираемых кортежей. За
подробностями обратитесь к описанию протокола расширенных запросов. Так как libpq в
настоящее время не позволяет передавать такие сообщения, это возможно только с кли-
ентом, задействующим не libpq. Если это происходит часто, имеет смысл установить в
max_parallel_workers_per_gather 0 в сеансах, для которых это актуально, чтобы система не пы-
талась строить планы, которые могут быть неэффективны при последовательном выполнении.
• Для транзакции установлен сериализуемый уровень изоляции. Обычно эта ситуация не возни-
кает, так как при таком уровне изоляции не строятся параллельные планы выполнения. Од-
нако она возможна, если уровень изоляции транзакции меняется на сериализуемый после по-
строения плана и до его выполнения.
15.3. Параллельные планы
Так как каждый рабочий процесс выполняет параллельную часть плана до конца, нельзя просто
взять обычный план запроса и запустить его в нескольких исполнителях. В этом случае все испол-
нители выдавали бы полные копии выходного набора результатов, так что запрос выполнится не
быстрее, чем обычно, а его результаты могут быть некорректными. Вместо этого параллельной
частью плана должно быть то, что для оптимизатора представляется как частичный план; то есть
такой план, при выполнении которого в отдельном процессе будет получено только подмножество
выходных строк, а каждая требующаяся строка результата будет гарантированно выдана ровно
одним из сотрудничающих процессов. Вообще говоря, это означает, что сканирование нижележа-
щей таблицы запроса должно проводиться с учётом распараллеливания.
15.3.1. Параллельные сканирования
В настоящее время поддерживаются следующие виды сканирований таблицы, рассчитанные на
параллельное выполнение.
• При параллельном последовательном сканировании блоки таблицы будут разделены меж-
ду взаимодействующими процессами. Блоки выдаются по очереди, так что доступ к таблице
остаётся последовательным.
• При параллельном сканировании кучи по битовой карте один процесс выбирается на роль ве-
дущего. Этот процесс производит сканирование одного или нескольких индексов и строит би-
товую карту, показывающую, какие блоки таблицы нужно посетить. Затем эти блоки разделя-
ются между взаимодействующими процессами как при параллельном последовательном ска-
нировании. Другими словами, сканирование кучи выполняется в параллельном режиме, а ска-
нирование нижележащего индекса — нет.
• При параллельном сканировании по индексу или параллельном сканировании только индек-
са, взаимодействующие процессы читают данные из индекса по очереди. В настоящее время
параллельное сканирование индекса поддерживается только для индексов-B-деревьев. Каж-
дый процесс будет выбирать один блок индекса с тем, чтобы просканировать и вернуть все
кортежи, на которые он ссылается; другой процесс может в то же время возвращать кортежи
для другого блока индекса. Результаты параллельного сканирования B-дерева каждый рабо-
чий процесс возвращает в отсортированном порядке.
445Параллельный запрос
В будущем может появиться поддержка параллельного выполнения и для других вариантов ска-
нирования, например, сканирования индексов, отличных от B-дерева.
15.3.2. Параллельные соединения
Как и в непараллельном плане, целевая таблица может соединяться с одной или несколькими дру-
гими таблицами с использованием вложенных циклов, соединения по хешу или соединения слия-
нием. Внутренней стороной соединения может быть любой вид непараллельного плана, который
в остальном поддерживается планировщиком, при условии, что он безопасен для выполнения в
параллельном исполнителе. Внутренней стороной может быть и параллельный план, в зависимо-
сти от типа соединения.
• В соединении с вложенным циклом внутренняя сторона всегда непараллельная. Хотя она вы-
полняется полностью, это эффективно, если с внутренней стороны производится сканирова-
ние индекса, так как внешние кортежи, а значит и циклы, находящие значения в индексе,
разделяются по параллельным процессам.
• При соединении слиянием с внутренней стороны всегда будет непараллельный план и, та-
ким образом, он будет выполняться полностью. Это может быть неэффективно, особенно если
потребуется произвести сортировку, так как работа и конечные данные будут повторяться в
каждом параллельном процессе.
• При соединении по хешу (непараллельном, без префикса «parallel») внутреннее соединение
выполняется полностью в каждом параллельном процессе, и в результате они строят одинако-
вые копии хеш-таблицы. Это может быть неэффективно при большой хеш-таблице или дорого-
стоящем плане. В параллельном соединении по хешу с внутренней стороны выполняется па-
раллельное хеширование, при котором работа по построению общей хеш-таблицы разделяет-
ся между параллельными процессами.
15.3.3. Параллельное агрегирование
PostgreSQL поддерживает параллельное агрегирование, выполняя агрегирование в два этапа. Сна-
чала каждый процесс, задействованный в параллельной части запроса, выполняет шаг агрегиро-
вания, выдавая частичный результат для каждой известной ему группы. В плане это отражает
узел Partial Aggregate. Затем эти промежуточные результаты передаются ведущему через узел
Gather или Gather Merge. И наконец, ведущий заново агрегирует результаты всех рабочих процес-
сов, чтобы получить окончательный результат. Это отражает в плане узел Finalize Aggregate.
Так как узел Finalize Aggregate выполняется в ведущем процессе, запросы, выдающие достаточ-
но большое количество групп по отношению к числу входных строк, будут расцениваться плани-
ровщиком как менее предпочтительные. Например, в худшем случае количество групп, выявлен-
ных узлом Finalize Aggregate, может равняться числу входных строк, обработанных всеми ра-
бочими процессами на этапе Partial Aggregate. Очевидно, что в такой ситуации использование
параллельного агрегирования не даст никакого выигрыша производительности. Планировщик за-
просов учитывает это в процессе планирования, так что выбор параллельного агрегирования в по-
добных случаях очень маловероятен.
Параллельное агрегирование поддерживается не во всех случаях. Чтобы оно поддерживалось, аг-
регатная функция должна быть безопасной для распараллеливания и должна иметь комбинирую-
щую функцию. Если переходное состояние агрегатной функции имеет тип internal, она должна
также иметь функции сериализации и десериализации. За подробностями обратитесь к CREATE
AGGREGATE. Параллельное агрегирование не поддерживается, если вызов агрегатной функции
содержит предложение DISTINCT или ORDER BY. Также оно не поддерживается для сортирующих аг-
регатов или когда запрос включает предложение GROUPING SETS. Оно может использоваться толь-
ко когда все соединения, задействованные в запросе, также входят в параллельную часть плана.
15.3.4. Параллельное присоединение
Когда требуется объединить строки из различных источников в единый набор результатов, в
PostgreSQL используются узлы плана Append или MergeAppend. Это обычно происходит при реали-
446Параллельный запрос
зации UNION ALL или при сканировании секционированной таблицы. Данные узлы могут приме-
няться как в параллельных, так и в обычных планах. Однако в параллельных планах планировщик
может заменить их на узел Parallel Append.
Если в параллельном плане используется узел Append, все задействованные процессы выполняют
очередной дочерний план совместно, пока он не будет завершён, и лишь затем, примерно в одно
время, переходят к выполнению следующего дочернего плана. Когда же применяется Parallel
Append, исполнитель старается равномерно распределить между задействованными процессами
все дочерние планы, чтобы они выполнялись параллельно. Это позволяет избежать конкуренции и
не тратить ресурсы на запуск дочернего плана для тех процессов, которые не будут его выполнять.
Кроме того, в отличие от обычного узла Append, использование которого внутри параллельного
плана допускается только для частичных дочерних планов, узел Parallel Append может обрабаты-
вать как частичные, так и не частичные дочерние планы. Для сканирования не частичного плана
будет использоваться только один процесс, поскольку его многократное сканирование приведёт
лишь к дублированию результатов. Таким образом, для планов, объединяющих несколько наборов
результатов, можно достичь параллельного выполнения на высоком уровне, даже когда эффектив-
ные частичные планы отсутствуют. Например, рассмотрим запрос к секционированной таблице,
который может быть эффективно реализован только с помощью индекса, не поддерживающего па-
раллельное сканирование. Планировщик может выбрать узел Parallel Append для параллельного
объединения нескольких обычных планов Index Scan; в этом случае каждое сканирование индекса
будет выполняться до полного завершения одним процессом, но при этом разные сканирования
будут осуществляться параллельно.
Отключить данную функциональность можно с помощью enable_parallel_append.
15.3.5. Советы по параллельным планам
Если для запроса ожидается параллельный план, но такой план не строится, можно попытаться
уменьшить parallel_setup_cost или parallel_tuple_cost. Разумеется, этот план может оказаться мед-
леннее последовательного плана, предпочитаемого планировщиком, но не всегда. Если вы не по-
лучаете параллельный план даже с очень маленькими значениями этих параметров (например,
сбросив оба их в ноль), может быть какая-то веская причина тому, что планировщик запросов не
может построить параллельный план для вашего запроса. За информацией о возможных причинах
обратитесь к Разделу 15.2 и Разделу 15.4.
Когда выполняется параллельный план, вы можете применить EXPLAIN (ANALYZE, VERBOSE), чтобы
просмотреть статистику по каждому узлу плана в разрезе рабочих процессов. Это может помочь
определить, равномерно ли распределяется работа между всеми узлами плана, и на более общем
уровне понимать характеристики производительности плана.
15.4. Безопасность распараллеливания
Планировщик классифицирует операции, вовлечённые в выполнение запроса, как либо безопас-
ные для распараллеливания, либо ограниченно распараллеливаемые, либо небезопасные для рас-
параллеливания. Безопасной для распараллеливания операцией считается такая, которая не ме-
шает параллельному выполнению запроса. Ограниченно распараллеливаемой операцией считает-
ся такая, которая не может выполняться в параллельном рабочем процессе, но может выполнять-
ся в ведущем процессе, когда запрос выполняется параллельно. Таким образом, ограниченно па-
раллельные операции никогда не могут оказаться ниже узла Gather или Gather Merge, но могут
встречаться в других местах плана, содержащего такой узел. Небезопасные для распараллелива-
ния операции не могут выполняться в параллельных запросах, даже в ведущем процессе. Когда
запрос содержит что-либо небезопасное для распараллеливания, параллельное выполнение для
такого запроса полностью исключается.
Ограниченно распараллеливаемыми всегда считаются следующие операции.
• Сканирование общих табличных выражений (CTE).
• Сканирование временных таблиц.
447Параллельный запрос
• Сканирование сторонних таблиц, если только обёртка сторонних данных не предоставляет
функцию IsForeignScanParallelSafe, которая допускает распараллеливание.
• Узлы плана, к которым присоединён узел InitPlan.
• Узлы плана, которые ссылаются на связанный SubPlan.
15.4.1. Пометки параллельности для функций и агрегатов
Планировщик не может автоматически определить, является ли пользовательская обычная или
агрегатная функция безопасной для распараллеливания, так как это потребовало бы предсказа-
ния действия каждой операции, которую могла бы выполнять функция. В общем случае это рав-
нозначно решению проблемы остановки, а значит, невозможно. Даже для простых функций, где
это в принципе возможно, мы не пытаемся это делать, так как это будет слишком дорогой и по-
тенциально неточной процедурой. Вместо этого, все определяемые пользователем функции пола-
гаются небезопасными для распараллеливания, если явно не отмечено обратное. Когда исполь-
зуется CREATE FUNCTION или ALTER FUNCTION, функции можно назначить отметку PARALLEL
SAFE, PARALLEL RESTRICTED или PARALLEL UNSAFE, отражающую её характер. В команде CREATE
AGGREGATE для параметра PARALLEL можно задать SAFE, RESTRICTED или UNSAFE в виде соответ-
ствующего значения.
Обычные и агрегатные функции должны помечаться небезопасными для распараллеливания
(PARALLEL UNSAFE), если они пишут в базу данных, обращаются к последовательностям, изменя-
ют состояние транзакции, даже временно (как, например, функция PL/pgSQL, устанавливающая
блок EXCEPTION для перехвата ошибок), либо производят постоянные изменения параметров. По-
добным образом, функции должны помечаться как ограниченно распараллеливаемые (PARALLEL
RESTRICTED), если они обращаются к временным таблицам, состоянию клиентского подключения,
курсорам, подготовленным операторам или разнообразному локальному состоянию обслуживаю-
щего процесса, которое система не может синхронизировать между рабочими процессами. Напри-
мер, по этой причине ограниченно параллельными являются функции setseed и random.
В целом, если функция помечена как безопасная, когда на самом деле она небезопасна или огра-
ниченно безопасна, или если она помечена как ограниченно безопасная, когда на самом деле она
небезопасная, такая функция может выдавать ошибки или возвращать неправильные ответы при
использовании в параллельном запросе. Функции на языке C могут теоретически проявлять пол-
ностью неопределённое появление при некорректной пометке, так как система никаким образом
не может защитить себя от произвольного кода C, но чаще всего результат будет не хуже, чем с
любой другой функцией. В случае сомнений, вероятно, лучше всего будет помечать функции как
небезопасные (UNSAFE).
Если функция, выполняемая в параллельном рабочем процессе, затребует блокировки, которыми
не владеет ведущий, например, обращаясь к таблице, не упомянутой в запросе, эти блокировки
будут освобождены по завершении процесса, а не в конце транзакции. Если вы разрабатываете
функцию с таким поведением, и эта особенность выполнения оказывается критичной, пометьте
такую функцию как PARALLEL RESTRICTED, чтобы она выполнялась только в ведущем процессе.
Заметьте, что планировщик запросов не рассматривает возможность отложенного выполнения
ограниченно распараллеливаемых обычных или агрегатных функций, задействованных в запросе,
для получения лучшего плана. Поэтому, например, если предложение WHERE, применяемое к кон-
кретной таблице, является ограниченно параллельным, планировщик запросов исключит возмож-
ность сканирования этой таблицы в параллельной части плана. В некоторых случаях возможно (и,
вероятно, более эффективно) включить сканирование этой таблицы в параллельную часть запроса
и отложить вычисление предложения WHERE, чтобы оно происходило над узлом Gather, но плани-
ровщик этого не делает.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" title="Глава 14. Оптимизация производительности"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 14. Оптимизация производительности"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~45 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" rel="bookmark" title="Глава 14. Оптимизация производительности" itemprop="url">Глава 14. Оптимизация производительности</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 14. Оптимизация производительности</p>

<p>Быстродействие запросов зависит от многих факторов. На некоторые из них могут воздейство-
вать пользователи, а другие являются фундаментальными особенностями системы. В этой главе
приводятся полезные советы, которые помогут понять их и оптимизировать производительность
PostgreSQL.
14.1. Использование EXPLAIN
Выполняя любой полученный запрос, PostgreSQL разрабатывает для него план запроса. Выбор
правильного плана, соответствующего структуре запроса и характеристикам данным, крайне ва-
жен для хорошей производительности, поэтому в системе работает сложный планировщик, зада-
ча которого — подобрать хороший план. Узнать, какой план был выбран для какого-либо запроса,
можно с помощью команды EXPLAIN. Понимание плана — это искусство, и чтобы овладеть им,
нужен определённый опыт, но этот раздел расскажет о самых простых вещах.
Приведённые ниже примеры показаны на тестовой базе данных, которая создаётся для выявления
регрессий в исходных кодах PostgreSQL текущей версии. Для неё предварительно выполняется
VACUUM ANALYZE. Вы должны получить похожие результаты, если возьмёте ту же базу данных и
проделаете следующие действия, но примерная стоимость и ожидаемое число строк у вас может
немного отличаться из-за того, что статистика команды ANALYZE рассчитывается по случайной
выборке, а оценки стоимости зависят от конкретной платформы.
В этих примерах используется текстовый формат вывода EXPLAIN, принятый по умолчанию, как
более компактный и удобный для восприятия человеком. Если вывод EXPLAIN нужно передать ка-
кой-либо программе для дальнейшего анализа, лучше использовать один из машинно-ориентиро-
ванных форматов (XML, JSON или YAML).
14.1.1. Азы EXPLAIN
Структура плана запроса представляет собой дерево узлов плана. Узлы на нижнем уровне дере-
ва — это узлы сканирования, которые возвращают необработанные данные таблицы. Разным ти-
пам доступа к таблице соответствуют разные узлы: последовательное сканирование, сканирование
индекса и сканирование битовой карты. Источниками строк могут быть не только таблицы, но и
например, предложения VALUES и функции, возвращающие множества во FROM, и они представля-
ются отдельными типами узлов сканирования. Если запрос требует объединения, агрегатных вы-
числений, сортировки или других операций с исходными строками, над узлами сканирования по-
являются узлы, обозначающие эти операции. И так как обычно операции могут выполняться раз-
ными способами, на этом уровне тоже могут быть узлы разных типов. В выводе команды EXPLAIN
для каждого узла в дереве плана отводится одна строка, где показывается базовый тип узла плюс
оценка стоимости выполнения данного узла, которую сделал для него планировщик. Если для уз-
ла выводятся дополнительные свойства, в вывод могут добавляться дополнительные строки, с от-
ступом от основной информации узла. В самой первой строке (основной строке самого верхнего
узла) выводится общая стоимость выполнения для всего плана; именно это значение планировщик
старается минимизировать.
Взгляните на следующий простейший пример, просто иллюстрирующий формат вывода:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Этот запрос не содержит предложения WHERE, поэтому он должен просканировать все строки таб-
лицы, так что планировщик выбрал план простого последовательного сканирования. Числа, пере-
численные в скобках (слева направо), имеют следующий смысл:
422Оптимизация производительности
• Приблизительная стоимость запуска. Это время, которое проходит, прежде чем начнётся этап
вывода данных, например для сортирующего узла это время сортировки.
• Приблизительная общая стоимость. Она вычисляется в предположении, что узел плана вы-
полняется до конца, то есть возвращает все доступные строки. На практике родительский
узел может досрочно прекратить чтение строк дочернего (см. приведённый ниже пример с
LIMIT).
• Ожидаемое число строк, которое должен вывести этот узел плана. При этом так же предпола-
гается, что узел выполняется до конца.
• Ожидаемый средний размер строк, выводимых этим узлом плана (в байтах).
Стоимость может измеряться в произвольных единицах, определяемых параметрами планировщи-
ка (см. Подраздел 19.7.2). Традиционно единицей стоимости считается операция чтения страницы
с диска; то есть seq_page_cost обычно равен 1.0, а другие параметры задаётся относительно него.
Примеры в этом разделе выполняются со стандартными параметрами стоимости.
Важно понимать, что стоимость узла верхнего уровня включает стоимость всех его потомков.
Также важно осознавать, что эта стоимость отражает только те факторы, которые учитывает пла-
нировщик. В частности, она не зависит от времени, необходимого для передачи результирующих
строк клиенту, хотя оно может составлять значительную часть общего времени выполнения за-
проса. Тем не менее планировщик игнорирует эту величину, так как он всё равно не сможет из-
менить её, выбрав другой план. (Мы верим в то, что любой правильный план запроса выдаёт один
и тот же набор строк.)
Значение rows здесь имеет особенность — оно выражает не число строк, обработанных или про-
сканированных узлом плана, а число строк, выданных этим узлом. Часто оно окажется меньше
числа просканированных строк в результате применённой к узлу фильтрации по условиям WHERE.
В идеале, на верхнем уровне это значение будет приблизительно равно числу строк, которое фак-
тически возвращает, изменяет или удаляет запрос.
Возвращаясь к нашему примеру:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Эти числа получаются очень просто. Выполните:
SELECT relpages, reltuples FROM pg_class WHERE relname = ‘tenk1’;
и вы увидите, что tenk1 содержит 358 страниц диска и 10000 строк. Общая стоимость вычисляется
как (число_чтений_диска * seq_page_cost) + (число_просканированных_строк * cpu_tuple_cost). По
умолчанию, seq_page_cost равно 1.0, а cpu_tuple_cost — 0.01, так что приблизительная стоимость
запроса равна (358 * 1.0) + (10000 * 0.01) = 458.
Теперь давайте изменим запрос, добавив в него предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;
QUERY PLAN
————————————————————
Seq Scan on tenk1 (cost=0.00..483.00 rows=7001 width=244)
Filter: (unique1 &lt; 7000)
Заметьте, что в выводе EXPLAIN показано, что условие WHERE применено как «фильтр» к узлу плана
Seq Scan (Последовательное сканирование). Это означает, что узел плана проверяет это условие
для каждого просканированного им узла и выводит только те строки, которые удовлетворяют ему.
Предложение WHERE повлияло на оценку числа выходных строк. Однако при сканировании потре-
423Оптимизация производительности
буется прочитать все 10000 строк, поэтому общая стоимость не уменьшилась. На деле она даже
немного увеличилась (на 10000 * cpu_operator_cost, если быть точными), отражая дополнительное
время, которое потребуется процессору на проверку условия WHERE.
Фактическое число строк результата этого запроса будет равно 7000, но значение rows даёт толь-
ко приблизительное значение. Если вы попытаетесь повторить этот эксперимент, вы можете по-
лучить немного другую оценку; более того, она может меняться после каждой команды ANALYZE,
так как ANALYZE получает статистику по случайной выборке таблицы.
Теперь давайте сделаем ограничение более избирательным:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.01 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
В данном случае планировщик решил использовать план из двух этапов: сначала дочерний узел
плана просматривает индекс и находит в нём адреса строк, соответствующих условию индекса, а
затем верхний узел собственно выбирает эти строки из таблицы. Выбирать строки по отдельности
гораздо дороже, чем просто читать их последовательно, но так как читать придётся не все стра-
ницы таблицы, это всё равно будет дешевле, чем сканировать всю таблицу. (Использование двух
уровней плана объясняется тем, что верхний узел сортирует адреса строк, выбранных из индек-
са, в физическом порядке, прежде чем читать, чтобы снизить стоимость отдельных чтений. Слово
«bitmap» (битовая карта) в имени узла обозначает механизм, выполняющий сортировку.)
Теперь давайте добавим ещё одно условие в предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = ‘xxx’;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.01..229.40 rows=1 width=244)
Recheck Cond: (unique1 &lt; 100)
Filter: (stringu1 = ‘xxx’::name)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
Добавленное условие stringu1 = ‘xxx’ уменьшает оценку числа результирующих строк, но не
стоимость запроса, так как просматриваться будет тот же набор строк, что и раньше. Заметьте, что
условие на stringu1 не добавляется в качестве условия индекса, так как индекс построен только
по столбцу unique1. Вместо этого оно применяется как фильтр к строкам, полученным по индексу.
В результате стоимость даже немного увеличилась, отражая добавление этой проверки.
В некоторых случаях планировщик предпочтёт «простой» план сканирования индекса:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
QUERY PLAN
—————————————————————————
Index Scan using tenk1_unique1 on tenk1 (cost=0.29..8.30 rows=1 width=244)
Index Cond: (unique1 = 42)
В плане такого типа строки таблицы выбираются в порядке индекса, в результате чего чтение их
обходится дороже, но так как их немного, дополнительно сортировать положения строк не стоит.
Вы часто будете встречать этот тип плана в запросах, которые выбирают всего одну строку. Также
424Оптимизация производительности
он часто задействуется там, где условие ORDER BY соответствует порядку индекса, так как в этих
случаях для выполнения ORDER BY не требуется дополнительный шаг сортировки.
Если в таблице есть отдельные индексы по разным столбцам, фигурирующим в WHERE, планировщик
может выбрать сочетание этих индексов (с AND и OR):
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
————————————————————————————-
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
Index Cond: (unique2 &gt; 9000)
Но для этого потребуется обойти оба индекса, так что это не обязательно будет выгоднее, чем
просто просмотреть один индекс, а второе условие обработать как фильтр. Измените диапазон и
вы увидите, как это повлияет на план.
Следующий пример иллюстрирует эффекты LIMIT:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
————————————————————————————-
Limit (cost=0.29..14.48 rows=2 width=244)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..71.27 rows=10 width=244)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Это тот же запрос, что и раньше, но добавили мы в него LIMIT, чтобы возвращались не все стро-
ки, и планировщик решает выполнять запрос по-другому. Заметьте, что общая стоимость и число
строк для узла Index Scan рассчитываются в предположении, что он будет выполняться полностью.
Однако узел Limit должен остановиться, получив только пятую часть всех строк, так что его сто-
имость будет составлять одну пятую от вычисленной ранее, и это и будет итоговой оценкой стои-
мости запроса. С другой стороны, планировщик мог бы просто добавить в предыдущий план узел
Limit, но это не избавило бы от затрат на запуск сканирования битовой карты, а значит, общая
стоимость была бы выше 25 единиц.
Давайте попробуем соединить две таблицы по столбцам, которые мы уже использовали:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
Index Cond: (unique2 = t1.unique2)
В этом плане появляется узел соединения с вложенным циклом, на вход которому поступают дан-
ные от двух его потомков, узлов сканирования. Эту структуру плана отражает отступ основных
425Оптимизация производительности
строк его узлов. Первый, или «внешний», потомок соединения — узел сканирования битовой кар-
ты, похожий на те, что мы видели раньше. Его стоимость и число строк те же, что мы получили
бы для запроса SELECT … WHERE unique1 &lt; 10, так как к этому узлу добавлено предложение
WHERE unique1 &lt; 10. Условие t1.unique2 = t2.unique2 ещё не учитывается, поэтому оно не влияет
на число строк узла внешнего сканирования. Узел соединения с вложенным циклом будет выпол-
нять узел «внутреннего» потомка для каждой строки, полученной из внешнего потомка. Значения
столбцов из текущей внешней строки могут использоваться во внутреннем сканировании (в дан-
ном случае это значение t1.unique2), поэтому мы получаем план и стоимость примерно такие,
как и раньше для простого запроса SELECT … WHERE t2.unique2 = константа. (На самом деле
оценочная стоимость немного меньше, в предположении, что при неоднократном сканировании
индекса по t2 положительную роль сыграет кеширование.) В результате стоимость узла цикла
складывается из стоимости внешнего сканирования, цены внутреннего сканирования, умножен-
ной на число строк (здесь 10 * 7.91), и небольшой наценки за обработку соединения.
В этом примере число выходных строк соединения равно произведению чисел строк двух узлов
сканирования, но это не всегда будет так, потому что в дополнительных условиях WHERE могут
упоминаться обе таблицы, так что применить их можно будет только в точке соединения, а не в
одном из узлов сканирования. Например:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t2.unique2 &lt; 10 AND t1.hundred &lt; t2.hundred;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..49.46 rows=33 width=488)
Join Filter: (t1.hundred &lt; t2.hundred)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Materialize (cost=0.29..8.51 rows=10 width=244)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..8.46 rows=10
width=244)
Index Cond: (unique2 &lt; 10)
Условие t1.hundred &lt; t2.hundred не может быть проверено в индексе tenk2_unique2, поэтому оно
применяется в узле соединения. Это уменьшает оценку числа выходных строк, тогда как число
строк в узлах сканирования не меняется.
Заметьте, что здесь планировщик решил «материализовать» внутреннее отношение соединения,
поместив поверх него узел плана Materialize (Материализовать). Это значит, что сканирование
индекса t2 будет выполняться только единожды, при том, что узлу вложенного цикла соединения
потребуется прочитать данные десять раз, по числу строк во внешнем соединении. Узел Materialize
сохраняет считанные данные в памяти, чтобы затем выдать их из памяти на следующих проходах.
Выполняя внешние соединения, вы можете встретить узлы плана с присоединёнными условиями,
как обычными «Filter», так и «Join Filter» (Фильтр соединения). Условия Join Filter формируются
из предложения ON для внешнего соединения, так что если строка не удовлетворяет условию Join
Filter, она всё же выдаётся как строка, дополненная значениями NULL. Обычное же условие Filter
применяется после правил внешнего соединения и поэтому полностью исключает строки. Во внут-
реннем соединении оба этих фильтра работают одинаково.
Если немного изменить избирательность запроса, мы можем получить совсем другой план соеди-
нения:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
426Оптимизация производительности
QUERY PLAN
——————————————————————————————
Hash Join (cost=230.47..713.98 rows=101 width=488)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0)
Index Cond: (unique1 &lt; 100)
Здесь планировщик выбирает соединение по хешу, при котором строки одной таблицы записыва-
ются в хеш-таблицу в памяти, после чего сканируется другая таблица и для каждой её строки про-
веряется соответствие по хеш-таблице. Обратите внимание, что и здесь отступы отражают струк-
туру плана: результат сканирования битовой карты по tenk1 подаётся на вход узлу Hash, который
конструирует хеш-таблицу. Затем она передаётся узлу Hash Join, который читает строки из узла
внешнего потомка и проверяет их по этой хеш-таблице.
Ещё один возможный тип соединения — соединение слиянием:
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=198.11..268.19 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Sort (cost=197.83..200.33 rows=1000 width=244)
Sort Key: t2.unique2
-&gt; Seq Scan on onek t2 (cost=0.00..148.00 rows=1000 width=244)
Соединение слиянием требует, чтобы входные данные для него были отсортированы по ключам
соединения. В этом плане данные tenk1 сортируются после сканирования индекса, при котором
все строки просматриваются в правильном порядке, но таблицу onek выгоднее оказывается после-
довательно просканировать и отсортировать, так как в этой таблице нужно обработать гораздо
больше строк. (Последовательное сканирование и сортировка часто бывает быстрее сканирования
индекса, когда нужно отсортировать много строк, так как при сканировании по индексу обраще-
ния к диску не упорядочены.)
Один из способов посмотреть различные планы — принудить планировщик не считать выбранную
им стратегию самой выгодной, используя флаги, описанные в Подразделе 19.7.1. (Это полезный,
хотя и грубый инструмент. См. также Раздел 14.3.) Например, если мы убеждены, что последова-
тельное сканирование и сортировка — не лучший способ обработать таблицу onek в предыдущем
примере, мы можем попробовать
SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=0.56..292.65 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
427Оптимизация производительности
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Index Scan using onek_unique2 on onek t2 (cost=0.28..224.79 rows=1000
width=244)
Видно, что планировщик считает сортировку onek со сканированием индекса примерно на 12%
дороже, чем последовательное сканирование и сортировку. Конечно, может возникнуть вопрос —
а правильно ли это? Мы можем ответить на него, используя описанную ниже команду EXPLAIN
ANALYZE.
14.1.2. EXPLAIN ANALYZE
Точность оценок планировщика можно проверить, используя команду EXPLAIN с параметром
ANALYZE. С этим параметром EXPLAIN на самом деле выполняет запрос, а затем выводит фактиче-
ское число строк и время выполнения, накопленное в каждом узле плана, вместе с теми же оцен-
ками, что выдаёт обычная команда EXPLAIN. Например, мы можем получить примерно такой ре-
зультат:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488) (actual time=0.128..0.377 rows=10
loops=1)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244) (actual
time=0.057..0.121 rows=10 loops=1)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
(actual time=0.024..0.024 rows=10 loops=1)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
(actual time=0.021..0.022 rows=1 loops=10)
Index Cond: (unique2 = t1.unique2)
Planning time: 0.181 ms
Execution time: 0.501 ms
Заметьте, что значения «actual time» (фактическое время) приводятся в миллисекундах, тогда как
оценки cost (стоимость) выражаются в произвольных единицах, так что они вряд ли совпадут.
Обычно важнее определить, насколько приблизительная оценка числа строк близка к действи-
тельности. В этом примере они в точности совпали, но на практике так бывает редко.
В некоторых планах запросов некоторый внутренний узел может выполняться неоднократно. На-
пример, внутреннее сканирование индекса будет выполняться для каждой внешней строки во вло-
женном цикле верхнего уровня. В таких случаях значение loops (циклы) показывает, сколько все-
го раз выполнялся этот узел, а фактическое время и число строк вычисляется как среднее по всем
итерациям. Это делается для того, чтобы полученные значения можно было сравнить с выводимы-
ми приблизительными оценками. Чтобы получить общее время, затраченное на выполнение узла,
время одной итерации нужно умножить на значение loops. В показанном выше примере мы по-
тратили в общей сложности 0.220 мс на сканирование индекса в tenk2.
В ряде случаев EXPLAIN ANALYZE выводит дополнительную статистику по выполнению, включаю-
щую не только время выполнения узлов и число строк. Для узлов Sort и Hash, например выводится
следующая информация:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;
428Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Sort (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100
loops=1)
Sort Key: t1.fivethous
Sort Method: quicksort Memory: 77kB
-&gt; Hash Join (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427
rows=100 loops=1)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244) (actual
time=0.007..2.583 rows=10000 loops=1)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659
rows=100 loops=1)
Buckets: 1024 Batches: 1 Memory Usage: 28kB
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
(actual time=0.080..0.526 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0) (actual time=0.049..0.049 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.194 ms
Execution time: 8.008 ms
Для узла Sort показывается использованный метод и место сортировки (в памяти или на диске),
а также задействованный объём памяти. Для узла Hash выводится число групп и пакетов хеша, а
также максимальный объём, который заняла в памяти хеш-таблица. (Если число пакетов больше
одного, часть хеш-таблицы будет выгружаться на диск и занимать какое-то пространство, но его
объём здесь не показывается.)
Другая полезная дополнительная информация — число строк, удалённых условием фильтра:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;
QUERY PLAN
——————————————————————————————–
Seq Scan on tenk1 (cost=0.00..483.00 rows=7000 width=244) (actual time=0.016..5.107
rows=7000 loops=1)
Filter: (ten &lt; 7)
Rows Removed by Filter: 3000
Planning time: 0.083 ms
Execution time: 5.905 ms
Эти значения могут быть особенно ценны для условий фильтра, применённых к узлам соединения.
Строка «Rows Removed» выводится, только когда условие фильтра отбрасывает минимум одну про-
сканированную строку или потенциальную пару соединения, если это узел соединения.
Похожую ситуацию можно наблюдать при сканировании «неточного» индекса. Например, рас-
смотрим этот план поиска многоугольников, содержащих указанную точку:
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Seq Scan on polygon_tbl (cost=0.00..1.05 rows=1 width=32) (actual time=0.044..0.044
rows=0 loops=1)
Filter: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Filter: 4
Planning time: 0.040 ms
Execution time: 0.083 ms
429Оптимизация производительности
Планировщик полагает (и вполне справедливо), что таблица слишком мала для сканирования по
индексу, поэтому он выбирает последовательное сканирование, при котором все строки отбрасы-
ваются условием фильтра. Но если мы принудим его выбрать сканирование по индексу, мы полу-
чим:
SET enable_seqscan TO off;
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Index Scan using gpolygonind on polygon_tbl (cost=0.13..8.15 rows=1 width=32) (actual
time=0.062..0.062 rows=0 loops=1)
Index Cond: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Index Recheck: 1
Planning time: 0.034 ms
Execution time: 0.144 ms
Здесь мы видим, что индекс вернул одну потенциально подходящую строку, но затем она была
отброшена при перепроверке условия индекса. Это объясняется тем, что индекс GiST является
«неточным» для проверок включений многоугольников: фактически он возвращает строки с мно-
гоугольниками, перекрывающими точку по координатам, а затем для этих строк нужно выполнять
точную проверку.
EXPLAIN принимает параметр BUFFERS (который также можно применять с ANALYZE), включающий
ещё более подробную статистику выполнения запроса:
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
——————————————————————————————–
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244) (actual
time=0.323..0.342 rows=10 loops=1)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
Buffers: shared hit=15
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0) (actual time=0.309..0.309 rows=0
loops=1)
Buffers: shared hit=7
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Buffers: shared hit=2
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
(actual time=0.227..0.227 rows=999 loops=1)
Index Cond: (unique2 &gt; 9000)
Buffers: shared hit=5
Planning time: 0.088 ms
Execution time: 0.423 ms
Значения, которые выводятся с параметром BUFFERS, помогают понять, на какие части запроса
приходится большинство операций ввода-вывода.
Не забывайте, что EXPLAIN ANALYZE действительно выполняет запрос, хотя его результаты могут
не показываться, а заменяться выводом команды EXPLAIN. Поэтому при таком анализе возможны
побочные эффекты. Если вы хотите проанализировать запрос, изменяющий данные, но при этом
сохранить прежние данные таблицы, вы можете откатить транзакцию после запроса:
BEGIN;
EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;
430Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Update on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual time=14.628..14.628
rows=0 loops=1)
-&gt; Bitmap Heap Scan on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual
time=0.101..0.439 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.079 ms
Execution time: 14.727 ms
ROLLBACK;
Как показано в этом примере, когда выполняется команда INSERT, UPDATE или DELETE, собственно
изменение данных в таблице происходит в узле верхнего уровня Insert, Update или Delete. Узлы
плана более низких уровней выполняют работу по нахождению старых строк и/или вычислению
новых данных. Поэтому вверху мы видим тот же тип сканирования битовой карты, что и раньше,
только теперь его вывод подаётся узлу Update, который сохраняет изменённые строки. Стоит от-
метить, что узел, изменяющий данные, может выполняться значительное время (в данном случае
это составляет львиную часть всего времени), но планировщик не учитывает эту работу в оценке
общей стоимости. Это связано с тем, что эта работа будет одинаковой при любом правильном пла-
не запроса, и поэтому на выбор плана она не влияет.
Когда команда UPDATE или DELETE имеет дело с иерархией наследования, вывод может быть таким:
EXPLAIN UPDATE parent SET f2 = f2 + 1 WHERE f1 = 101;
QUERY PLAN
———————————————————————————–
Update on parent (cost=0.00..24.53 rows=4 width=14)
Update on parent
Update on child1
Update on child2
Update on child3
-&gt; Seq Scan on parent (cost=0.00..0.00 rows=1 width=14)
Filter: (f1 = 101)
-&gt; Index Scan using child1_f1_key on child1 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child2_f1_key on child2 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child3_f1_key on child3 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
В этом примере узлу Update помимо изначально упомянутой в запросе родительской таблицы нуж-
но обработать ещё три дочерние таблицы. Поэтому формируются четыре плана сканирования, по
одному для каждой таблицы. Ясности ради для узла Update добавляется примечание, показываю-
щее, какие именно таблицы будут изменяться, в том же порядке, в каком они идут в соответствую-
щих внутренних планах. (Эти примечания появились в PostgreSQL 9.5; до этого о целевых таблицах
приходилось догадываться, изучая внутренние планы узла.)
Под заголовком Planning time (Время планирования) команда EXPLAIN ANALYZE выводит время,
затраченное на построение плана запроса из разобранного запроса и его оптимизацию. Время
собственно разбора или перезаписи запроса в него не включается.
Значение Execution time (Время выполнения), выводимое командой EXPLAIN ANALYZE, включает
продолжительность запуска и остановки исполнителя запроса, а также время выполнения всех
сработавших триггеров, но не включает время разбора, перезаписи и планирования запроса. Вре-
мя, потраченное на выполнение триггеров BEFORE (если такие имеются) включается во время соот-
431Оптимизация производительности
ветствующих узлов Insert, Update или Delete node; но время выполнения триггеров AFTER не учиты-
вается, так как триггеры AFTER срабатывают после выполнения всего плана. Общее время, прове-
дённое в каждом триггере (BEFORE или AFTER), также выводится отдельно. Заметьте, что триггеры
отложенных ограничений выполняются только в конце транзакции, так что время их выполнения
EXPLAIN ANALYZE не учитывает.
14.1.3. Ограничения
Время выполнения, измеренное командой EXPLAIN ANALYZE, может значительно отличаться от
времени выполнения того же запроса в обычном режиме. Тому есть две основных причины. Во-
первых, так как при анализе никакие строки результата не передаются клиенту, время ввода/вы-
вода и передачи по сети не учитывается. Во-вторых, может быть существенной дополнительная
нагрузка, связанная с функциями измерений EXPLAIN ANALYZE, особенно в системах, где вызов
gettimeofday() выполняется медленно. Для измерения этой нагрузки вы можете воспользоваться
утилитой pg_test_timing.
Результаты EXPLAIN не следует распространять на ситуации, значительно отличающиеся от тех, в
которых вы проводите тестирование. В частности, не следует полагать, что выводы, полученные
для игрушечной таблицы, будут применимы и для настоящих больших таблиц. Оценки стоимости
нелинейны и планировщик может выбирать разные планы в зависимости от размера таблицы. На-
пример, в крайнем случае вся таблица может уместиться в одну страницу диска, и тогда вы почти
наверняка получите план последовательного сканирования, независимо от того, есть у неё и ин-
дексы или нет. Планировщик понимает, что для обработки таблицы ему в любом случае потребу-
ется прочитать одну страницу, так что нет никакого смысла обращаться к ещё одной странице за
индексом. (Мы наблюдали это в показанном выше примере с polygon_tbl.)
Бывает, что фактическое и приближённо оценённое значения не совпадают, но в этом нет ничего
плохого. Например, это возможно, когда выполнение плана узла прекращается преждевременно
из-за указания LIMIT или подобного эффекта. Например, для запроса с LIMIT, который мы пробо-
вали раньше:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
——————————————————————————————–
Limit (cost=0.29..14.71 rows=2 width=244) (actual time=0.177..0.249 rows=2 loops=1)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..72.42 rows=10 width=244)
(actual time=0.174..0.244 rows=2 loops=1)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Rows Removed by Filter: 287
Planning time: 0.096 ms
Execution time: 0.336 ms
Оценки стоимости и числа строк для узла Index Scan показываются в предположении, что этот узел
будет выполняться до конца. Но в действительности узел Limit прекратил запрашивать строки,
как только получил первые две, так что фактическое число строк равно 2 и время выполнения
запроса будет меньше, чем рассчитал планировщик. Но это не ошибка, а просто следствие того,
что оценённые и фактические значения выводятся по-разному.
Соединения слиянием также имеют свои особенности, которые могут ввести в заблуждение. Со-
единение слиянием прекратит читать один источник данных, если второй будет прочитан до кон-
ца, а следующее значение ключа в первом больше последнего значения во втором. В этом случае
пар строк больше не будет, так что сканировать первый источник дальше нет смысла. В результате
будут прочитаны не все строки одного потомка и вы получите тот же эффект, что и с LIMIT. Кро-
ме того, если внешний (первый) потомок содержит строки с повторяющимися значениями клю-
ча, внутренний (второй) потомок сдвинется назад и повторно выдаст строки для этого значения
ключа. EXPLAIN ANALYZE считает эти повторяющиеся строки, как если бы это действительно были
дополнительные строки внутреннего источника. Когда во внешнем узле много таких повторений
432Оптимизация производительности
ключей, фактическое число строк, подсчитанное для внутреннего узла, может значительно пре-
вышать число строк в соответствующей таблице.
Для узлов BitmapAnd (Логическое произведение битовых карт) и BitmapOr (Логическое сложение
битовых карт) фактическое число строк всегда равно 0 из-за ограничений реализации.
Обычно EXPLAIN выводит подробности для каждого узла плана, сгенерированного планировщиком.
Однако бывают ситуации, когда исполнитель может определить, что некоторые узлы не требуют-
ся, и не выполнять их; в настоящее время это поддерживает только узел Append. Узел этого типа
может отбросить подчинённые узлы, определив, что они не выдадут ни одной записи, нужной для
запроса. Понять, что узлы были удалены таким образом, можно по наличию свойства «Subplans
Removed» (Подпланов удалено) в выводе EXPLAIN.
14.2. Статистика, используемая планировщиком
14.2.1. Статистика по одному столбцу
Как было показано в предыдущем разделе, планировщик запросов должен оценить число строк,
возвращаемых запросов, чтобы сделать правильный выбор в отношении плана запроса. В этом
разделе кратко описывается статистика, которую использует система для этих оценок.
В частности, статистика включает общее число записей в каждой таблице и индексе, а также
число дисковых блоков, которые они занимают. Эта информация содержится в таблице pg_class,
в столбцах reltuples и relpages. Получить её можно, например так:
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE ‘tenk1%’;
relname
| relkind | reltuples | relpages
———————-+———+———–+———-
tenk1
| r
|
10000 |
358
tenk1_hundred
| i
|
10000 |
30
tenk1_thous_tenthous | i
|
10000 |
30
tenk1_unique1
| i
|
10000 |
30
tenk1_unique2
| i
|
10000 |
30
(5 rows)
Здесь мы видим, что tenk1 содержит 10000 строк данных и столько же строк в индексах (что неуди-
вительно), но объём индексов гораздо меньше таблицы.
Для большей эффективности reltuples и relpages не пересчитываются «на лету», так что они
обычно содержат несколько устаревшие значения. Их обновляют команды VACUUM, ANALYZE и
несколько команд DDL, такие как CREATE INDEX. VACUUM и ANALYZE могут не сканировать всю таб-
лицу (и обычно так и делают), а только вычислить приращение reltuples по части таблицы, так
что результат остаётся приблизительным. В любом случае планировщик пересчитывает значения,
полученные из pg_class, в пропорции к текущему физическому размеру таблицы и таким образом
уточняет приближение.
Большинство запросов возвращают не все строки таблицы, а только немногие из них, ограничен-
ные условиями WHERE. Поэтому планировщику нужно оценить избирательность условий WHERE,
то есть определить, какой процент строк будет соответствовать каждому условию в предложении
WHERE. Нужная для этого информация хранится в системном каталоге pg_statistic. Значения в
pg_statistic обновляются командами ANALYZE и VACUUM ANALYZE и никогда не бывают точными,
даже сразу после обновления.
Для исследования статистики лучше обращаться не непосредственно к таблице pg_statistic, а к
представлению pg_stats, предназначенному для облегчения восприятия этой информации. Кроме
того, представление pg_stats доступно для чтения всем, тогда как pg_statistic — только супер-
433Оптимизация производительности
пользователям. (Это сделано для того, чтобы непривилегированные пользователи не могли ничего
узнать о содержимом таблиц других людей из статистики. Представление pg_stats устроено так,
что оно показывает строки только для тех таблиц, которые может читать данный пользователь.)
Например, мы можем выполнить:
SELECT attname, inherited, n_distinct,
array_to_string(most_common_vals, E’\n’) as most_common_vals
FROM pg_stats
WHERE tablename = ‘road’;
attname | inherited | n_distinct |
most_common_vals
———+———–+————+————————————
name
| f
| -0.363388 | I- 580
Ramp+
|
|
| I- 880
Ramp+
|
|
| Sp Railroad
+
|
|
| I- 580
+
|
|
| I- 680
Ramp
name
| t
| -0.284859 | I- 880
Ramp+
|
|
| I- 580
Ramp+
|
|
| I- 680
Ramp+
|
|
| I- 580
+
|
|
| State Hwy 13
Ramp
(2 rows)
Заметьте, что для одного столбца показываются две строки: одна соответствует полной иерархии
наследования, построенной для таблицы road (inherited=t), и другая относится непосредственно
к таблице road (inherited=f).
Объём информации, сохраняемой в pg_statistic командой ANALYZE, в частности максимальное
число записей в массивах most_common_vals (самые популярные значения) и histogram_bounds
(границы гистограмм) для каждого столбца, можно ограничить на уровне столбцов с помо-
щью команды ALTER TABLE SET STATISTICS или глобально, установив параметр конфигурации
default_statistics_target. В настоящее время ограничение по умолчанию равно 100 записям. Уве-
личивая этот предел, можно увеличить точность оценок планировщика, особенно для столбцов
с нерегулярным распределением данных, ценой большего объёма pg_statistic и, возможно, уве-
личения времени расчёта этой статистики. И напротив, для столбцов с простым распределением
данных может быть достаточно меньшего предела.
Подробнее использование статистики планировщиком описывается в Главе 70.
14.2.2. Расширенная статистика
Часто наблюдается картина, когда медленное выполнение запросов объясняется плохим выбором
плана из-за того, что несколько столбцов, фигурирующих в условиях запроса, оказываются свя-
занными. Обычно планировщик полагает, что несколько условий не зависят друг от друга, а это
предположение оказывается неверным, когда значения этих столбцов коррелируют. Обычная ста-
тистика, которая по природе своей строится по отдельным столбцам, не может выявить корреля-
ции между столбцами. Однако PostgreSQL имеет возможность вычислять многовариантную ста-
тистику, которая может собирать необходимую для этого информацию.
Так как число возможных комбинаций столбцов очень велико, автоматически вычислять много-
вариантную статистику непрактично. Вместо этого можно создать объекты расширенной стати-
стики, чаще называемые просто объектами статистики, чтобы сервер собирал статистику по
некоторым наборам столбцов, представляющим интерес.
Объекты статистики создаются командой CREATE STATISTICS (за подробностями обратитесь к
её описанию). При создании такого объекта просто создаётся запись в каталоге, выражающая
востребованность этой статистики. Собственно сбор данных выполняется командой ANALYZE (при
запуске вручную или фоновом автоанализе). Изучить собранные значения можно в каталоге
pg_statistic_ext.
434Оптимизация производительности
Команда ANALYZE вычисляет расширенную статистику по той же выборке строк таблицы, которая
используется и для вычисления обычной статистики по отдельным столбцам. Так как размер вы-
борки увеличивается с увеличением целевого ограничения статистики для таблицы или любых её
столбцов (как описано в предыдущем разделе), при большем целевом ограничении обычно полу-
чается более точная расширенная статистика, но и времени на её вычисление требуется больше.
В следующих подразделах описываются виды расширенной статистики, поддерживаемые в насто-
ящее время.
14.2.2.1. Функциональные зависимости
Простейший вид расширенной статистики отслеживает функциональные зависимости (это поня-
тие используется в определении нормальных форм баз данных). Мы называем столбец b функцио-
нально зависимым от столбца a, если знания значения a достаточно для определения значения b,
то есть не существует двух строк с одинаковыми значениями a, но разными значениями b. В пол-
ностью нормализованной базе данных функциональные зависимости должны существовать только
в первичных ключах и суперключах. Однако на практике многие наборы данных не нормализуют-
ся полностью по разным причинам; например, денормализация часто производится намеренно по
соображениям производительности.
Существование функциональных зависимостей напрямую влияет на точность оценок в определён-
ных запросах. Если запрос содержит условия как по независимым, так и по зависимым столбцам,
условия по зависимым столбцам дополнительно не сокращают размер результата. Однако без зна-
ния о функциональной зависимости планировщик запросов будет полагать, что все условия неза-
висимы, и недооценит размер результата.
Для информирования планировщика о функциональных зависимостях команда ANALYZE может со-
бирать показатели зависимостей между столбцами. Оценить степень зависимости между всеми
наборами столбцов обошлось бы непозволительно дорого, поэтому сбор данных ограничивается
только теми группами столбцов, которые фигурируют вместе в объекте статистики, определённом
со свойством dependencies. Во избежание ненужных издержек при выполнении ANALYZE и после-
дующем планировании запросов статистику с dependencies рекомендуется создавать только для
групп сильно коррелирующих столбцов.
Взгляните на пример сбора статистики функциональной зависимости:
CREATE STATISTICS stts (dependencies) ON zip, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxname, stxkeys, stxdependencies
FROM pg_statistic_ext
WHERE stxname = ‘stts’;
stxname | stxkeys |
stxdependencies
———+———+——————————————
stts
| 1 5
| {“1 =&gt; 5”: 1.000000, “5 =&gt; 1”: 0.423130}
(1 row)
В показанном случае столбец 1 (код zip) полностью определяет столбец 5 (city), так что коэффи-
циент равен 1.0, тогда как город (столбец city) определяет код ZIP только в 42% всех случаев, что
означает, что многие города (58%) представлены несколькими кодами ZIP.
При вычислении избирательности запроса, в котором задействованы функционально зависимые
столбцы, планировщик корректирует оценки избирательности по условиям, используя коэффици-
енты зависимостей, чтобы не допустить недооценки размера результата.
14.2.2.1.1. Ограничения функциональных зависимостей
Функциональные зависимости в настоящее время применяются только при рассмотрении простых
условий с равенствами, сравнивающих значения столбцов с константами. Они не используются для
улучшения оценок при проверке равенства двух столбцов или сравнении столбца с выражением,
а также в условиях с диапазоном, условиях LIKE или любых других видах условий.
435Оптимизация производительности
Рассматривая функциональные зависимости, планировщик предполагает, что условия по задей-
ствованным столбцам совместимы и таким образом избыточны. Если условия несовместимы, пра-
вильной оценкой должен быть ноль строк, но эта возможность не рассматривается. Например, с
таким запросом
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘94105’;
планировщик отбросит условие с city, так как оно не влияет на избирательность, что верно. Од-
нако он сделает то же предположение и в таком случае:
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘90210’;
хотя на самом деле этому запросу будет удовлетворять ноль строк. Но статистика функциональной
зависимости не даёт достаточно информации, чтобы прийти к такому заключению.
Во многих практических ситуациях это предположение обычно удовлетворяется; например, гра-
фический интерфейс приложения для последующего формирования запроса может не допускать
выбор несовместимого сочетания города и кода ZIP. Но когда это не так, статистика функциональ-
ной зависимости может не подойти.
14.2.2.2. Многовариантное число различных значений
Статистика по одному столбцу содержит число различных значений в каждом отдельном столбце.
Оценки числа различных значений в сочетании нескольких столбцов (например, в GROUP BY a,
b) часто оказываются ошибочными, когда планировщик имеет статистические данные только по
отдельным столбцам, что приводит к выбору плохих планов.
Для улучшения таких оценок операция ANALYZE может собирать статистику по различным значе-
ниям для группы столбцов. Как и ранее, это непрактично делать для каждой возможной группы
столбцов, так что данные собираются только по тем группам столбцов, которые указаны в опре-
делении объекта статистики, создаваемого со свойством ndistinct. Данные будут собираться по
всем возможным сочетаниям из двух или нескольких столбцов из перечисленных в определении.
В продолжение предыдущего примера, количества различных значений в таблице ZIP-кодов могут
выглядеть так:
CREATE STATISTICS stts2 (ndistinct) ON zip, state, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxkeys AS k, stxndistinct AS nd
FROM pg_statistic_ext
WHERE stxname = ‘stts2’;
-[ RECORD 1 ]——————————————————–
k | 1 2 5
nd | {“1, 2”: 33178, “1, 5”: 33178, “2, 5”: 27435, “1, 2, 5”: 33178}
(1 row)
Как видно, есть три комбинации столбцов, имеющих 33178 различных значений: код ZIP и штат;
код ZIP и город; код ZIP, город и штат (то, что все эти числа равны, ожидаемый факт, так как сам
по себе код ZIP в этой таблице уникален). С другой стороны, сочетание города и штата даёт только
27435 различных значений.
Объект статистики ndistinct рекомендуется создавать только для тех сочетаний столбцов, кото-
рые действительно используются при группировке, и только когда неправильная оценка числа
групп может привести к выбору плохих планов. В противном случае усилия, потраченные на вы-
полнение ANALYZE, будут напрасными.
14.3. Управление планировщиком с помощью явных
предложений JOIN
436Оптимизация производительности
Поведением планировщика в некоторой степени можно управлять, используя явный синтаксис
JOIN. Понять, когда и почему это бывает нужно, поможет небольшое введение.
В простом запросе с соединением, например таком:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
планировщик может соединять данные таблицы в любом порядке. Например, он может разрабо-
тать план, в котором сначала A соединяется с B по условию WHERE a.id = b.id, а затем C соединя-
ется с получившейся таблицей по другому условию WHERE. Либо он может соединить B с C, а затем
с A результатом соединения. Он также может соединить сначала A с C, а затем результат с B — но
это будет не эффективно, так как ему придётся сформировать полное декартово произведение A
и C из-за отсутствия в предложении WHERE условия, подходящего для оптимизации соединения. (В
PostgreSQL исполнитель запросов может соединять только по две таблицы, поэтому для получения
результата нужно выбрать один из этих способов.) При этом важно понимать, что все эти разные
способы соединения дают одинаковые по смыслу результаты, но стоимость их может различаться
многократно. Поэтому планировщик должен изучить их все и найти самый эффективный способ
выполнения запроса.
Когда запрос включает только две или три таблицы, возможны всего несколько вариантов их со-
единения. Но их число растёт экспоненциально с увеличением числа задействованных таблиц.
Если число таблиц больше десяти, уже практически невозможно выполнить полный перебор всех
вариантов, и даже для шести или семи таблиц планирование может занять недопустимо много
времени. Когда таблиц слишком много, планировщик PostgreSQL переключается с полного поис-
ка на алгоритм генетического вероятностного поиска в ограниченном числе вариантов. (Порог
для этого переключения задаётся параметром выполнения geqo_threshold.) Генетический поиск
выполняется быстрее, но не гарантирует, что найденный план будет наилучшим.
Когда запрос включает внешние соединения, планировщик имеет меньше степеней свободы, чем
с обычными (внутренними) соединениями. Например, рассмотрим запрос:
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Хотя ограничения в этом запросе очень похожи на показанные в предыдущем примере, смысл его
отличается, так как результирующая строка должна выдаваться для каждой строки A, даже если
для неё не находится соответствия в соединении B и C. Таким образом, здесь планировщик не мо-
жет выбирать порядок соединения: он должен соединить B с C, а затем соединить A с результатом.
Соответственно, и план этого запроса построится быстрее, чем предыдущего. В других случаях
планировщик сможет определить, что можно безопасно выбрать один из нескольких способов со-
единения. Например, для запроса:
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
можно соединить A либо с B, либо с C. В настоящее время только FULL JOIN полностью ограничи-
вает порядок соединения. На практике в большинстве запросов с LEFT JOIN и RIGHT JOIN порядком
можно управлять в некоторой степени.
Синтаксис явного внутреннего соединения (INNER JOIN, CROSS JOIN или лаконичный JOIN) по смыс-
лу равнозначен перечислению отношений в предложении FROM, так что он никак не ограничивает
порядок соединений.
Хотя большинство видов JOIN не полностью ограничивают порядок соединения, в PostgreSQL мож-
но принудить планировщик обрабатывать все предложения JOIN как ограничивающие этот поря-
док. Например, следующие три запроса логически равнозначны:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Но если мы укажем планировщику соблюдать порядок JOIN, на планирование второго и третьего
уйдёт меньше времени. Когда речь идёт только о трёх таблицах, выигрыш будет незначительным,
но для множества таблиц это может быть очень эффективно.
437Оптимизация производительности
Чтобы планировщик соблюдал порядок внутреннего соединения, выраженный явно предложения-
ми JOIN, нужно присвоить параметру выполнения join_collapse_limit значение 1. (Другие допусти-
мые значения обсуждаются ниже.)
Чтобы сократить время поиска, необязательно полностью ограничивать порядок соединений, в
JOIN можно соединять элементы как в обычном списке FROM. Например, рассмотрите следующий
запрос:
SELECT * FROM a CROSS JOIN b, c, d, e WHERE …;
Если join_collapse_limit = 1, планировщик будет вынужден соединить A с B раньше, чем резуль-
тат с другими таблицами, но в дальнейшем выборе вариантов он не ограничен. В данном примере
число возможных вариантов соединения уменьшается в 5 раз.
Упрощать для планировщика задачу перебора вариантов таким способом — это полезный приём,
помогающий не только выбрать сократить время планирования, но и подтолкнуть планировщик
к хорошему плану. Если планировщик по умолчанию выбирает неудачный порядок соединения,
вы можете заставить его выбрать лучший, применив синтаксис JOIN, конечно если вы сами его
знаете. Эффект подобной оптимизации рекомендуется подтверждать экспериментально.
На время планирования влияет и другой, тесно связанный фактор — решение о включении подза-
просов в родительский запрос. Пример такого запроса:
SELECT *
FROM x, y,
(SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;
Такая же ситуация может возникнуть с представлением, содержащим соединение; вместо ссылки
на это представление будет вставлено его выражение SELECT и в результате получится запрос, по-
хожий на показанный выше. Обычно планировщик старается включить подзапрос в родительский
запрос и получить таким образом:
SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;
Часто это позволяет построить лучший план, чем при планировании подзапросов по отдельности.
(Например, внешние условия WHERE могут быть таковы, что при соединении сначала X с A будет ис-
ключено множество строк A, а значит формировать логический результат подзапроса полностью
не потребуется.) Но в то же время тем самым мы увеличиваем время планирования; две задачи
соединения трёх элементов мы заменяем одной с пятью элементами. Так как число вариантов уве-
личивается экспоненциально, сложность задачи увеличивается многократно. Планировщик пыта-
ется избежать проблем поиска с огромным числом вариантов, рассматривая подзапросы отдельно,
если в предложении FROM родительского запроса оказывается больше чем from_collapse_limit
элементов. Изменяя этот параметр выполнения, можно подобрать оптимальное соотношение вре-
мени планирования и качества плана.
Параметры from_collapse_limit и join_collapse_limit называются похоже, потому что они делают
практически одно и то же: первый параметр определяет, когда планировщик будет «сносить» в
предложение FROM подзапросы, а второй — явные соединения. Обычно join_collapse_limit уста-
навливается равным from_collapse_limit (чтобы явные соединения и подзапросы обрабатывались
одинаково) или 1 (если требуется управлять порядком соединений). Но вы можете задать другие
значения, чтобы добиться оптимального соотношения времени планирования и времени выполне-
ния запросов.
14.4. Наполнение базы данных
Довольно часто в начале или в процессе использования базы данных возникает необходимость
загрузить в неё большой объём данных. В этом разделе приведены рекомендации, которые помогут
сделать это максимально эффективно.
14.4.1. Отключите автофиксацию транзакций
438Оптимизация производительности
Выполняя серию команд INSERT, выключите автофиксацию транзакций и зафиксируйте транзак-
цию только один раз в самом конце. (В обычном SQL это означает, что нужно выполнить BEGIN до,
и COMMIT после этой серии. Некоторые клиентские библиотеки могут делать это автоматически,
в таких случаях нужно убедиться, что это так.) Если вы будете фиксировать каждое добавление
по отдельности, PostgreSQL придётся проделать много действий для каждой добавляемой строки.
Выполнять все операции в одной транзакции хорошо ещё и потому, что в случае ошибки добавле-
ния одной из строк произойдёт откат к исходному состоянию и вы не окажетесь в сложной ситуа-
ции с частично загруженными данными.
14.4.2. Используйте COPY
Используйте COPY, чтобы загрузить все строки одной командой вместо серии INSERT. Команда
COPY оптимизирована для загрузки большого количества строк; хотя она не так гибка, как INSERT,
но при загрузке больших объёмов данных она влечёт гораздо меньше накладных расходов. Так как
COPY — это одна команда, применяя её, нет необходимости отключать автофиксацию транзакций.
В случаях, когда COPY не подходит, может быть полезно создать подготовленный оператор INSERT с
помощью PREPARE, а затем выполнять EXECUTE столько раз, сколько потребуется. Это позволит из-
бежать накладных расходов, связанных с разбором и анализом каждой команды INSERT. В разных
интерфейсах это может выглядеть по-разному; за подробностями обратитесь к описанию «подго-
товленных операторов» в документации конкретного интерфейса.
Заметьте, что с помощью COPY большое количество строк практически всегда загружается быст-
рее, чем с помощью INSERT, даже если используется PREPARE и серия операций добавления заклю-
чена в одну транзакцию.
COPY работает быстрее всего, если она выполняется в одной транзакции с командами CREATE TABLE
или TRUNCATE. В таких случаях записывать WAL не нужно, так как в случае ошибки файлы, содер-
жащие загружаемые данные, будут всё равно удалены. Однако это замечание справедливо, только
когда параметр wal_level равен minimal, так как в противном случае все команды должны записы-
вать свои изменения в WAL.
14.4.3. Удалите индексы
Если вы загружаете данные в только что созданную таблицу, быстрее всего будет загрузить данные
с помощью COPY, а затем создать все необходимые для неё индексы. На создание индекса для
уже существующих данных уйдёт меньше времени, чем на последовательное его обновление при
добавлении каждой строки.
Если вы добавляете данные в существующую таблицу, может иметь смысл удалить индексы, за-
грузить таблицу, а затем пересоздать индексы. Конечно, при этом надо учитывать, что времен-
ное отсутствие индексов может отрицательно повлиять на скорость работы других пользователей.
Кроме того, следует дважды подумать, прежде чем удалять уникальные индексы, так как без них
соответствующие проверки ключей не будут выполняться.
14.4.4. Удалите ограничения внешних ключей
Как и с индексами, проверки, связанные с ограничениями внешних ключей, выгоднее выполнять
«массово», а не для каждой строки в отдельности. Поэтому может быть полезно удалить ограни-
чения внешних ключей, загрузить данные, а затем восстановить прежние ограничения. И в этом
случае тоже приходится выбирать между скоростью загрузки данных и риском допустить ошибки
в отсутствие ограничений.
Более того, когда вы загружаете данные в таблицу с существующими ограничениями внешнего
ключа, для каждой новой строки добавляется запись в очередь событий триггера (так как именно
срабатывающий триггер проверяет такие ограничения для строки). При загрузке многих миллио-
нов строк очередь событий триггера может занять всю доступную память, что приведёт к недопу-
стимой нагрузке на файл подкачки или даже к сбою команды. Таким образом, загружая большие
объёмы данных, может быть не просто желательно, а необходимо удалять, а затем восстанавливать
439Оптимизация производительности
внешние ключи. Если же временное отключение этого ограничения неприемлемо, единственно
возможным решением может быть разделение всей операции загрузки на меньшие транзакции.
14.4.5. Увеличьте maintenance_work_mem
Ускорить загрузку больших объёмов данных можно, увеличив параметр конфигурации
maintenance_work_mem на время загрузки. Это приведёт к увеличению быстродействия CREATE
INDEX и ALTER TABLE ADD FOREIGN KEY. На скорость самой команды COPY это не повлияет, так что
этот совет будет полезен, только если вы применяете какой-либо из двух вышеописанных приёмов.
14.4.6. Увеличьте max_wal_size
Также массовую загрузку данных можно ускорить, изменив на время загрузки параметр конфигу-
рации max_wal_size. Загружая большие объёмы данных, PostgreSQL вынужден увеличивать частоту
контрольных точек по сравнению с обычной (которая задаётся параметром checkpoint_timeout), а
значит и чаще сбрасывать «грязные» страницы на диск. Временно увеличив max_wal_size, можно
уменьшить частоту контрольных точек и связанных с ними операций ввода-вывода.
14.4.7. Отключите архивацию WAL и потоковую репликацию
Для загрузки больших объёмов данных в среде, где используется архивация WAL или потоковая
репликация, быстрее будет сделать копию базы данных после загрузки данных, чем обрабатывать
множество операций изменений в WAL. Чтобы отключить передачу изменений через WAL в про-
цессе загрузки, отключите архивацию и потоковую репликацию, назначьте параметру wal_level
значение minimal, archive_mode — off, а max_wal_senders — 0. Но имейте в виду, что изменённые
параметры вступят в силу только после перезапуска сервера.
Это не только поможет сэкономить время архивации и передачи WAL, но и непосредственно уско-
рит некоторые команды, которые могут вовсе не использовать WAL, если wal_level равен minimal.
(Они могут гарантировать безопасность при сбое, не записывая все изменения в WAL, а выполнив
только fsync в конце операции, что будет гораздо дешевле.) Это относится к следующим командам:
• CREATE TABLE AS SELECT
• CREATE INDEX (и подобные команды, как например ALTER TABLE ADD PRIMARY KEY)
• ALTER TABLE SET TABLESPACE
• CLUSTER
• COPY FROM, когда целевая таблица была создана или опустошена ранее в той же транзакции
14.4.8. Выполните в конце ANALYZE
Всякий раз, когда распределение данных в таблице значительно меняется, настоятельно рекомен-
дуется выполнять ANALYZE. Эта рекомендация касается и загрузки в таблицу большого объёма
данных. Выполнив ANALYZE (или VACUUM ANALYZE), вы тем самым обновите статистику по данной
таблице для планировщика. Когда планировщик не имеет статистики или она не соответствует
действительности, он не сможет правильно планировать запросы, что приведёт к снижению быст-
родействия при работе с соответствующими таблицами. Заметьте, что если включён демон авто-
очистки, он может запускать ANALYZE автоматически; подробнее об этом можно узнать в Подраз-
деле 24.1.3 и Подразделе 24.1.6.
14.4.9. Несколько замечаний относительно pg_dump
В скриптах загрузки данных, которые генерирует pg_dump, автоматически учитываются некото-
рые, но не все из этих рекомендаций. Чтобы загрузить данные, которые выгрузил pg_dump, мак-
симально быстро, вам нужно будет выполнить некоторые дополнительные действия вручную. (За-
метьте, что эти замечания относятся только к восстановлению данных, но не к выгрузке их. Следу-
ющие рекомендации применимы вне зависимости от того, загружается ли архивный файл pg_dump
в psql или в pg_restore.)
440Оптимизация производительности
По умолчанию pg_dump использует команду COPY и когда она выгружает полностью схему и дан-
ные, в сгенерированном скрипте она сначала предусмотрительно загружает данные, а потом со-
здаёт индексы и внешние ключи. Так что в этом случае часть рекомендаций выполняется автома-
тически. Вам остаётся учесть только следующие:
• Установите подходящие (то есть превышающие обычные) значения для maintenance_work_mem
и max_wal_size.
• Если вы используете архивацию WAL или потоковую репликацию, по возможности отклю-
чите их на время восстановления. Для этого перед загрузкой данных, присвойте параметру
archive_mode значение off, wal_level — minimal, а max_wal_senders — 0. Закончив восстанов-
ление, верните их обычные значения и сделайте свежую базовую резервную копию.
• Поэкспериментируйте с режимами параллельного копирования и восстановления команд
pg_dump и pg_restore, и подберите оптимальное число параллельных заданий. Параллельное
копирование и восстановление данных, управляемое параметром -j, должно дать значитель-
ный выигрыш в скорости по сравнению с последовательным режимом.
• Если это возможно в вашей ситуации, восстановите все данные в рамках одной транзакции.
Для этого передайте параметр -1 или –single-transaction команде psql или pg_restore. Но
учтите, что в этом режиме даже незначительная ошибка приведёт к откату всех изменений и
часы восстановления будут потрачены зря. В зависимости от того, насколько взаимосвязаны
данные, предпочтительнее может быть вычистить их вручную. Команды COPY будут работать
максимально быстро, когда они выполняются в одной транзакции и архивация WAL выключе-
на.
• Если на сервере баз данных установлено несколько процессоров, полезным может оказаться
параметр –jobs команды pg_restore. С его помощью можно выполнить загрузку данных и со-
здание индексов параллельно.
• После загрузки данных запустите ANALYZE.
При выгрузке данных без схемы тоже используется команда COPY, но индексы, как обычно и
1
внешние ключи, при этом не удаляются и не пересоздаются. Поэтому, загружая только дан-
ные, вы сами должны решить, нужно ли для ускорения загрузки удалять и пересоздавать индек-
сы и внешние ключи. При этом будет так же полезно увеличить параметр max_wal_size, но не
maintenance_work_mem; его стоит менять, только если вы впоследствии пересоздаёте индексы и
внешние ключи вручную. И не забудьте выполнить ANALYZE после; подробнее об этом можно узнать
в Подразделе 24.1.3 и Подразделе 24.1.6.
14.5. Оптимизация, угрожающая стабильности
Стабильность — это свойство базы данных, гарантирующее, что результат зафиксированных тран-
закций будет сохранён даже в случае сбоя сервера или отключения питания. Однако обеспечива-
ется стабильность за счёт значительной дополнительной нагрузки. Поэтому, если вы можете отка-
заться от такой гарантии, PostgreSQL можно ускорить ещё больше, применив следующие методы
оптимизации. Кроме явно описанных исключений, даже с такими изменениями конфигурации при
сбое программного ядра СУБД гарантия стабильности сохраняется; риск потери или разрушения
данных возможен только в случае внезапной остановки операционной системы.
• Поместите каталог данных кластера БД в файловую систему, размещённую в памяти (т. е. в
RAM-диск). Так вы исключите всю активность ввода/вывода, связанную с базой данных, если
только размер базы данных не превышает объём свободной памяти (возможно, с учётом фай-
ла подкачки).
• Выключите fsync; сбрасывать данные на диск не нужно.
• Выключите synchronous_commit; нет необходимости принудительно записывать WAL на диск
при фиксации каждой транзакции. Но учтите, это может привести к потере транзакций (хотя
данные останутся согласованными) в случае сбоя базы данных.
1
Вы можете отключить внешние ключи, используя параметр –disable-triggers — но при этом нужно понимать, что тем самым вы не просто отложите, а
полностью выключите соответствующие проверки, что позволит вставить недопустимые данные.
441Оптимизация производительности
• Выключите full_page_writes; защита от частичной записи страниц не нужна.
• Увеличьте max_wal_size и checkpoint_timeout; это уменьшит частоту контрольных точек, хотя
объём /pg_wal при этом вырастет.
• Создавайте нежурналируемые таблицы для оптимизации записи в WAL (но учтите, что такие
таблицы не защищены от сбоя).</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    
      
        <li><a href="http://localhost:4000/page21/" class="btn">Previous</a></li>
      
    

    
    
      <li><a href="http://localhost:4000">1</a></li>
    

    
    
      
      
      <li>…</li>
    

    
    
    

    
      
        
        
        
        <li><a href="http://localhost:4000/page20/">20</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page21/">21</a></li>
      
    
      
        <li><strong class="current-page">22</strong></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page23/">23</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page24/">24</a></li>
      
    

    
    
      <li>…</li>
    

    
      <li><a href="http://localhost:4000/page36/">36</a></li>
    

    
    
      <li><a href="http://localhost:4000/page23/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Sergey Khatsiola. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-130427752-1', 'auto');  
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>


          

</body>
</html>