<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Последние посты &#8211; Sirius Blog</title>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130427752-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130427752-1');
</script>

</head>
<meta name="description" content="Describtion ..">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/abstract-1.jpg">

<meta name="twitter:title" content="Последние посты">
<meta name="twitter:description" content="Describtion ..">
<meta name="twitter:creator" content="@2hotab2">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Последние посты">
<meta property="og:description" content="Describtion ..">
<meta property="og:url" content="http://localhost:4000/page22/">
<meta property="og:site_name" content="Sirius Blog">





<link rel="canonical" href="http://localhost:4000/page22/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Sirius Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.jpg">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.jpg">
<!-- 114x72 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x72" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.jpg">
<!-- 144x72 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x72" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.jpg">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Sergey Khatsiola photo" class="author-photo">
					<h4>Sergey Khatsiola</h4>
					<p>Кратко обо мне ...</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:2hotab2@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/2hotab2"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				<li>
					<a href="https://facebook.com/sergej.ha1"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/Sergey-sirius"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	    
	    <li><a href="http://localhost:4000/handbook/" >HandBook</a></li>
	  
	    
	    <li><a href="https://github.com/Sergey-sirius" target="_blank">Main Link</a></li>
	  
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/abstract-1.jpg" alt="Последние посты">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Sirius Blog</h1>
      <h2>Последние посты</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-015/" title="Глава 15. Параллельный запрос"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 15. Параллельный запрос"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-015/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~14 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-015/" rel="bookmark" title="Глава 15. Параллельный запрос" itemprop="url">Глава 15. Параллельный запрос</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 15. Параллельный запрос</p>

<p>PostgreSQL может вырабатывать такие планы запросов, которые будут задействовать несколько
CPU, чтобы получить ответ на запросы быстрее. Эта возможность называется распараллеливанием
запросов. Для многих запросов параллельное выполнение не даёт никакого выигрыша, либо из-за
ограничений текущей реализации, либо из-за принципиальной невозможности построить парал-
лельный план, который был бы быстрее последовательного. Однако для запросов, в которых это
может быть полезно, распараллеливание часто даёт очень значительное ускорение. Многие та-
кие запросы могут выполняться в параллельном режиме как минимум двое быстрее, а некоторые
— быстрее в четыре и даже более раз. Обычно наибольший выигрыш можно получить с запроса-
ми, обрабатывающими большой объём данных, но возвращающими пользователю всего несколько
строк. В этой главе достаточно подробно рассказывается, как работают параллельные запросы и в
каких ситуациях их можно использовать, чтобы пользователи, желающие применять их, понима-
ли, чего ожидать.
15.1. Как работают параллельно выполняемые запро-
сы
Когда оптимизатор определяет, что параллельное выполнение будет наилучшей стратегией для
конкретного запроса, он создаёт план запроса, включающий узел Gather (Сбор) или Gather Merge
(Сбор со слиянием). Взгляните на простой пример:
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE ‘%x%’;
QUERY PLAN
————————————————————————————-
Gather (cost=1000.00..217018.43 rows=1 width=97)
Workers Planned: 2
-&gt; Parallel Seq Scan on pgbench_accounts (cost=0.00..216018.33 rows=1 width=97)
Filter: (filler ~~ ‘%x%’::text)
(4 rows)
Во всех случаях узел Gather или Gather Merge будет иметь ровно один дочерний план, представ-
ляющий часть общего плана, выполняемую в параллельном режиме. Если узел Gather или Gather
Merge располагается на самом верху дерева плана, в параллельном режиме будет выполняться весь
запрос. Если он находится где-то в другом месте плана, параллельно будет выполняться только
часть плана ниже него. В приведённом выше примере запрос обращается только к одной таблице,
так что помимо узла Gather есть только ещё один узел плана; и так как этот узел является потом-
ком узла Gather, он будет выполняться в параллельном режиме.
Используя EXPLAIN, вы можете узнать количество исполнителей, выбранное планировщиком
для данного запроса. Когда при выполнении запроса достигается узел Gather, процесс, обслу-
живающий сеанс пользователя, запрашивает фоновые рабочие процессы в этом количестве. Ко-
личество исполнителей, которое может попытаться задействовать планировщик, ограничива-
ется значением max_parallel_workers_per_gather. Общее число фоновых рабочих процессов, ко-
торые могут существовать одновременно, ограничивается параметрами max_worker_processes
и max_parallel_workers. Таким образом, вполне возможно, что параллельный запрос будет
выполняться меньшим числом рабочих процессов, чем планировалось, либо вообще без до-
полнительных рабочих процессов. Оптимальность плана может зависеть от числа доступ-
ных рабочих процессов, так что их нехватка может повлечь значительное снижение произ-
водительности. Если это наблюдается часто, имеет смысл увеличить max_worker_processes и
max_parallel_workers, чтобы одновременно могло работать больше процессов, либо наоборот
уменьшить max_parallel_workers_per_gather, чтобы планировщик запрашивал их в меньшем ко-
личестве.
Каждый фоновый рабочий процесс, успешно запущенный для данного параллельного запроса, бу-
дет выполнять параллельную часть плана. Ведущий процесс также будет выполнять эту часть пла-
на, но он несёт дополнительную ответственность: он должен также прочитать все кортежи, выдан-
ные рабочими процессами. Когда параллельная часть плана выдаёт лишь небольшое количество
443Параллельный запрос
кортежей, ведущий часто ведёт себя просто как один из рабочих процессов, ускоряя выполнение
запроса. И напротив, когда параллельная часть плана выдаёт множество кортежей, ведущий мо-
жет быть почти всё время занят чтением кортежей, выдаваемых другими рабочими процессами, и
выполнять другие шаги обработки, связанные с узлами плана выше узла Gather или Gather Merge.
В таких случаях ведущий процесс может вносить лишь минимальный вклад в выполнение парал-
лельной части плана.
Когда над параллельной частью плана оказывается узел Gather Merge, а не Gather, это означает,
что все процессы, выполняющие части параллельного плана, выдают кортежи в отсортированном
порядке, и что ведущий процесс выполняет слияние с сохранением порядка. Узел же Gather, на-
против, получает кортежи от подчинённых процессов в произвольном удобном ему порядке, нару-
шая порядок сортировки, который мог существовать.
15.2. Когда может применяться распараллеливание за-
просов?
Планировщик запросов может отказаться от построения параллельных планов запросов в любом
случае под влиянием нескольких параметров. Чтобы он строил параллельные планы запросов при
каких-бы то ни было условиях, описанные далее параметры необходимо настроить указанным об-
разом.
• max_parallel_workers_per_gather должен иметь значение, большее нуля. Это особый вариант
более общего ограничения на суммарное число используемых рабочих процессов, задаваемо-
го параметром max_parallel_workers_per_gather.
• dynamic_shared_memory_type должен иметь значение, отличное от none. Для параллельного
выполнения запросов нужна динамическая общая память, через которую будут передаваться
данные между взаимодействующими процессами.
В дополнение к этому, система должна работать не в однопользовательском режиме. Так как в
этом режиме вся СУБД работает в одном процессе, фоновые рабочие процессы в нём недоступны.
Даже если принципиально возможно построить параллельные планы выполнения, планировщик
не будет строить такой план для определённого запроса, если имеет место одно из следующих
обстоятельств:
• Запрос выполняет запись данных или блокирует строки в базе данных. Если запрос содержит
операцию, изменяющую данные либо на верхнем уровне, либо внутри CTE, для такого запроса
не будут строиться параллельные планы. Исключение составляют команды CREATE TABLE …
AS, SELECT INTO и CREATE MATERIALIZED VIEW, которые создают новую таблицу и наполняют
её, и при этом могут использовать параллельный план.
• Запрос может быть приостановлен в процессе выполнения. В ситуациях, когда система реша-
ет, что может иметь место частичное или дополнительное выполнение, план параллельного
выполнения не строится. Например, курсор, созданный предложением DECLARE CURSOR, ни-
когда не будет использовать параллельный план. Подобным образом, цикл PL/pgSQL вида FOR
x IN query LOOP .. END LOOP никогда не будет использовать параллельный план, так как си-
стема параллельных запросов не сможет определить, может ли безопасно выполняться код
внутри цикла во время параллельного выполнения запроса.
• В запросе используются функции, помеченные как PARALLEL UNSAFE. Большинство систем-
ных функций безопасны для параллельного выполнения (PARALLEL SAFE), но пользовательские
функции по умолчанию помечаются как небезопасные (PARALLEL UNSAFE). Эта характеристика
функции рассматривается в Разделе 15.4.
• Запрос работает внутри другого запроса, уже параллельного. Например, если функция, вызы-
ваемая в параллельном запросе, сама выполняет SQL-запрос, последний запрос никогда не
будет выполняться параллельно. Это ограничение текущей реализации, но убирать его вряд
ли следует, так как это может привести к использованию одним запросом чрезмерного коли-
чества процессов.
444Параллельный запрос
• Для транзакции установлен сериализуемый уровень изоляции. Это ограничение текущей реа-
лизации.
Даже когда для определённого запроса построен параллельный план, возможны различные обсто-
ятельства, при которых этот план нельзя будет выполнить в параллельном режиме. В этих случаях
ведущий процесс выполнит часть плана ниже узла Gather полностью самостоятельно, как если бы
узла Gather вовсе не было. Это произойдёт только при выполнении одного из следующих условий:
• Невозможно получить ни одного фонового рабочего процесса из-за ограничения общего чис-
ла этих процессов значением max_worker_processes.
• Невозможно получить ни одного фонового рабочего процесса из-за ограничения общего чис-
ла таких процессов для параллельного выполнения значением max_parallel_workers.
• Клиент передаёт сообщение Execute с ненулевым количеством выбираемых кортежей. За
подробностями обратитесь к описанию протокола расширенных запросов. Так как libpq в
настоящее время не позволяет передавать такие сообщения, это возможно только с кли-
ентом, задействующим не libpq. Если это происходит часто, имеет смысл установить в
max_parallel_workers_per_gather 0 в сеансах, для которых это актуально, чтобы система не пы-
талась строить планы, которые могут быть неэффективны при последовательном выполнении.
• Для транзакции установлен сериализуемый уровень изоляции. Обычно эта ситуация не возни-
кает, так как при таком уровне изоляции не строятся параллельные планы выполнения. Од-
нако она возможна, если уровень изоляции транзакции меняется на сериализуемый после по-
строения плана и до его выполнения.
15.3. Параллельные планы
Так как каждый рабочий процесс выполняет параллельную часть плана до конца, нельзя просто
взять обычный план запроса и запустить его в нескольких исполнителях. В этом случае все испол-
нители выдавали бы полные копии выходного набора результатов, так что запрос выполнится не
быстрее, чем обычно, а его результаты могут быть некорректными. Вместо этого параллельной
частью плана должно быть то, что для оптимизатора представляется как частичный план; то есть
такой план, при выполнении которого в отдельном процессе будет получено только подмножество
выходных строк, а каждая требующаяся строка результата будет гарантированно выдана ровно
одним из сотрудничающих процессов. Вообще говоря, это означает, что сканирование нижележа-
щей таблицы запроса должно проводиться с учётом распараллеливания.
15.3.1. Параллельные сканирования
В настоящее время поддерживаются следующие виды сканирований таблицы, рассчитанные на
параллельное выполнение.
• При параллельном последовательном сканировании блоки таблицы будут разделены меж-
ду взаимодействующими процессами. Блоки выдаются по очереди, так что доступ к таблице
остаётся последовательным.
• При параллельном сканировании кучи по битовой карте один процесс выбирается на роль ве-
дущего. Этот процесс производит сканирование одного или нескольких индексов и строит би-
товую карту, показывающую, какие блоки таблицы нужно посетить. Затем эти блоки разделя-
ются между взаимодействующими процессами как при параллельном последовательном ска-
нировании. Другими словами, сканирование кучи выполняется в параллельном режиме, а ска-
нирование нижележащего индекса — нет.
• При параллельном сканировании по индексу или параллельном сканировании только индек-
са, взаимодействующие процессы читают данные из индекса по очереди. В настоящее время
параллельное сканирование индекса поддерживается только для индексов-B-деревьев. Каж-
дый процесс будет выбирать один блок индекса с тем, чтобы просканировать и вернуть все
кортежи, на которые он ссылается; другой процесс может в то же время возвращать кортежи
для другого блока индекса. Результаты параллельного сканирования B-дерева каждый рабо-
чий процесс возвращает в отсортированном порядке.
445Параллельный запрос
В будущем может появиться поддержка параллельного выполнения и для других вариантов ска-
нирования, например, сканирования индексов, отличных от B-дерева.
15.3.2. Параллельные соединения
Как и в непараллельном плане, целевая таблица может соединяться с одной или несколькими дру-
гими таблицами с использованием вложенных циклов, соединения по хешу или соединения слия-
нием. Внутренней стороной соединения может быть любой вид непараллельного плана, который
в остальном поддерживается планировщиком, при условии, что он безопасен для выполнения в
параллельном исполнителе. Внутренней стороной может быть и параллельный план, в зависимо-
сти от типа соединения.
• В соединении с вложенным циклом внутренняя сторона всегда непараллельная. Хотя она вы-
полняется полностью, это эффективно, если с внутренней стороны производится сканирова-
ние индекса, так как внешние кортежи, а значит и циклы, находящие значения в индексе,
разделяются по параллельным процессам.
• При соединении слиянием с внутренней стороны всегда будет непараллельный план и, та-
ким образом, он будет выполняться полностью. Это может быть неэффективно, особенно если
потребуется произвести сортировку, так как работа и конечные данные будут повторяться в
каждом параллельном процессе.
• При соединении по хешу (непараллельном, без префикса «parallel») внутреннее соединение
выполняется полностью в каждом параллельном процессе, и в результате они строят одинако-
вые копии хеш-таблицы. Это может быть неэффективно при большой хеш-таблице или дорого-
стоящем плане. В параллельном соединении по хешу с внутренней стороны выполняется па-
раллельное хеширование, при котором работа по построению общей хеш-таблицы разделяет-
ся между параллельными процессами.
15.3.3. Параллельное агрегирование
PostgreSQL поддерживает параллельное агрегирование, выполняя агрегирование в два этапа. Сна-
чала каждый процесс, задействованный в параллельной части запроса, выполняет шаг агрегиро-
вания, выдавая частичный результат для каждой известной ему группы. В плане это отражает
узел Partial Aggregate. Затем эти промежуточные результаты передаются ведущему через узел
Gather или Gather Merge. И наконец, ведущий заново агрегирует результаты всех рабочих процес-
сов, чтобы получить окончательный результат. Это отражает в плане узел Finalize Aggregate.
Так как узел Finalize Aggregate выполняется в ведущем процессе, запросы, выдающие достаточ-
но большое количество групп по отношению к числу входных строк, будут расцениваться плани-
ровщиком как менее предпочтительные. Например, в худшем случае количество групп, выявлен-
ных узлом Finalize Aggregate, может равняться числу входных строк, обработанных всеми ра-
бочими процессами на этапе Partial Aggregate. Очевидно, что в такой ситуации использование
параллельного агрегирования не даст никакого выигрыша производительности. Планировщик за-
просов учитывает это в процессе планирования, так что выбор параллельного агрегирования в по-
добных случаях очень маловероятен.
Параллельное агрегирование поддерживается не во всех случаях. Чтобы оно поддерживалось, аг-
регатная функция должна быть безопасной для распараллеливания и должна иметь комбинирую-
щую функцию. Если переходное состояние агрегатной функции имеет тип internal, она должна
также иметь функции сериализации и десериализации. За подробностями обратитесь к CREATE
AGGREGATE. Параллельное агрегирование не поддерживается, если вызов агрегатной функции
содержит предложение DISTINCT или ORDER BY. Также оно не поддерживается для сортирующих аг-
регатов или когда запрос включает предложение GROUPING SETS. Оно может использоваться толь-
ко когда все соединения, задействованные в запросе, также входят в параллельную часть плана.
15.3.4. Параллельное присоединение
Когда требуется объединить строки из различных источников в единый набор результатов, в
PostgreSQL используются узлы плана Append или MergeAppend. Это обычно происходит при реали-
446Параллельный запрос
зации UNION ALL или при сканировании секционированной таблицы. Данные узлы могут приме-
няться как в параллельных, так и в обычных планах. Однако в параллельных планах планировщик
может заменить их на узел Parallel Append.
Если в параллельном плане используется узел Append, все задействованные процессы выполняют
очередной дочерний план совместно, пока он не будет завершён, и лишь затем, примерно в одно
время, переходят к выполнению следующего дочернего плана. Когда же применяется Parallel
Append, исполнитель старается равномерно распределить между задействованными процессами
все дочерние планы, чтобы они выполнялись параллельно. Это позволяет избежать конкуренции и
не тратить ресурсы на запуск дочернего плана для тех процессов, которые не будут его выполнять.
Кроме того, в отличие от обычного узла Append, использование которого внутри параллельного
плана допускается только для частичных дочерних планов, узел Parallel Append может обрабаты-
вать как частичные, так и не частичные дочерние планы. Для сканирования не частичного плана
будет использоваться только один процесс, поскольку его многократное сканирование приведёт
лишь к дублированию результатов. Таким образом, для планов, объединяющих несколько наборов
результатов, можно достичь параллельного выполнения на высоком уровне, даже когда эффектив-
ные частичные планы отсутствуют. Например, рассмотрим запрос к секционированной таблице,
который может быть эффективно реализован только с помощью индекса, не поддерживающего па-
раллельное сканирование. Планировщик может выбрать узел Parallel Append для параллельного
объединения нескольких обычных планов Index Scan; в этом случае каждое сканирование индекса
будет выполняться до полного завершения одним процессом, но при этом разные сканирования
будут осуществляться параллельно.
Отключить данную функциональность можно с помощью enable_parallel_append.
15.3.5. Советы по параллельным планам
Если для запроса ожидается параллельный план, но такой план не строится, можно попытаться
уменьшить parallel_setup_cost или parallel_tuple_cost. Разумеется, этот план может оказаться мед-
леннее последовательного плана, предпочитаемого планировщиком, но не всегда. Если вы не по-
лучаете параллельный план даже с очень маленькими значениями этих параметров (например,
сбросив оба их в ноль), может быть какая-то веская причина тому, что планировщик запросов не
может построить параллельный план для вашего запроса. За информацией о возможных причинах
обратитесь к Разделу 15.2 и Разделу 15.4.
Когда выполняется параллельный план, вы можете применить EXPLAIN (ANALYZE, VERBOSE), чтобы
просмотреть статистику по каждому узлу плана в разрезе рабочих процессов. Это может помочь
определить, равномерно ли распределяется работа между всеми узлами плана, и на более общем
уровне понимать характеристики производительности плана.
15.4. Безопасность распараллеливания
Планировщик классифицирует операции, вовлечённые в выполнение запроса, как либо безопас-
ные для распараллеливания, либо ограниченно распараллеливаемые, либо небезопасные для рас-
параллеливания. Безопасной для распараллеливания операцией считается такая, которая не ме-
шает параллельному выполнению запроса. Ограниченно распараллеливаемой операцией считает-
ся такая, которая не может выполняться в параллельном рабочем процессе, но может выполнять-
ся в ведущем процессе, когда запрос выполняется параллельно. Таким образом, ограниченно па-
раллельные операции никогда не могут оказаться ниже узла Gather или Gather Merge, но могут
встречаться в других местах плана, содержащего такой узел. Небезопасные для распараллелива-
ния операции не могут выполняться в параллельных запросах, даже в ведущем процессе. Когда
запрос содержит что-либо небезопасное для распараллеливания, параллельное выполнение для
такого запроса полностью исключается.
Ограниченно распараллеливаемыми всегда считаются следующие операции.
• Сканирование общих табличных выражений (CTE).
• Сканирование временных таблиц.
447Параллельный запрос
• Сканирование сторонних таблиц, если только обёртка сторонних данных не предоставляет
функцию IsForeignScanParallelSafe, которая допускает распараллеливание.
• Узлы плана, к которым присоединён узел InitPlan.
• Узлы плана, которые ссылаются на связанный SubPlan.
15.4.1. Пометки параллельности для функций и агрегатов
Планировщик не может автоматически определить, является ли пользовательская обычная или
агрегатная функция безопасной для распараллеливания, так как это потребовало бы предсказа-
ния действия каждой операции, которую могла бы выполнять функция. В общем случае это рав-
нозначно решению проблемы остановки, а значит, невозможно. Даже для простых функций, где
это в принципе возможно, мы не пытаемся это делать, так как это будет слишком дорогой и по-
тенциально неточной процедурой. Вместо этого, все определяемые пользователем функции пола-
гаются небезопасными для распараллеливания, если явно не отмечено обратное. Когда исполь-
зуется CREATE FUNCTION или ALTER FUNCTION, функции можно назначить отметку PARALLEL
SAFE, PARALLEL RESTRICTED или PARALLEL UNSAFE, отражающую её характер. В команде CREATE
AGGREGATE для параметра PARALLEL можно задать SAFE, RESTRICTED или UNSAFE в виде соответ-
ствующего значения.
Обычные и агрегатные функции должны помечаться небезопасными для распараллеливания
(PARALLEL UNSAFE), если они пишут в базу данных, обращаются к последовательностям, изменя-
ют состояние транзакции, даже временно (как, например, функция PL/pgSQL, устанавливающая
блок EXCEPTION для перехвата ошибок), либо производят постоянные изменения параметров. По-
добным образом, функции должны помечаться как ограниченно распараллеливаемые (PARALLEL
RESTRICTED), если они обращаются к временным таблицам, состоянию клиентского подключения,
курсорам, подготовленным операторам или разнообразному локальному состоянию обслуживаю-
щего процесса, которое система не может синхронизировать между рабочими процессами. Напри-
мер, по этой причине ограниченно параллельными являются функции setseed и random.
В целом, если функция помечена как безопасная, когда на самом деле она небезопасна или огра-
ниченно безопасна, или если она помечена как ограниченно безопасная, когда на самом деле она
небезопасная, такая функция может выдавать ошибки или возвращать неправильные ответы при
использовании в параллельном запросе. Функции на языке C могут теоретически проявлять пол-
ностью неопределённое появление при некорректной пометке, так как система никаким образом
не может защитить себя от произвольного кода C, но чаще всего результат будет не хуже, чем с
любой другой функцией. В случае сомнений, вероятно, лучше всего будет помечать функции как
небезопасные (UNSAFE).
Если функция, выполняемая в параллельном рабочем процессе, затребует блокировки, которыми
не владеет ведущий, например, обращаясь к таблице, не упомянутой в запросе, эти блокировки
будут освобождены по завершении процесса, а не в конце транзакции. Если вы разрабатываете
функцию с таким поведением, и эта особенность выполнения оказывается критичной, пометьте
такую функцию как PARALLEL RESTRICTED, чтобы она выполнялась только в ведущем процессе.
Заметьте, что планировщик запросов не рассматривает возможность отложенного выполнения
ограниченно распараллеливаемых обычных или агрегатных функций, задействованных в запросе,
для получения лучшего плана. Поэтому, например, если предложение WHERE, применяемое к кон-
кретной таблице, является ограниченно параллельным, планировщик запросов исключит возмож-
ность сканирования этой таблицы в параллельной части плана. В некоторых случаях возможно (и,
вероятно, более эффективно) включить сканирование этой таблицы в параллельную часть запроса
и отложить вычисление предложения WHERE, чтобы оно происходило над узлом Gather, но плани-
ровщик этого не делает.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" title="Глава 14. Оптимизация производительности"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 14. Оптимизация производительности"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~45 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" rel="bookmark" title="Глава 14. Оптимизация производительности" itemprop="url">Глава 14. Оптимизация производительности</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 14. Оптимизация производительности</p>

<p>Быстродействие запросов зависит от многих факторов. На некоторые из них могут воздейство-
вать пользователи, а другие являются фундаментальными особенностями системы. В этой главе
приводятся полезные советы, которые помогут понять их и оптимизировать производительность
PostgreSQL.
14.1. Использование EXPLAIN
Выполняя любой полученный запрос, PostgreSQL разрабатывает для него план запроса. Выбор
правильного плана, соответствующего структуре запроса и характеристикам данным, крайне ва-
жен для хорошей производительности, поэтому в системе работает сложный планировщик, зада-
ча которого — подобрать хороший план. Узнать, какой план был выбран для какого-либо запроса,
можно с помощью команды EXPLAIN. Понимание плана — это искусство, и чтобы овладеть им,
нужен определённый опыт, но этот раздел расскажет о самых простых вещах.
Приведённые ниже примеры показаны на тестовой базе данных, которая создаётся для выявления
регрессий в исходных кодах PostgreSQL текущей версии. Для неё предварительно выполняется
VACUUM ANALYZE. Вы должны получить похожие результаты, если возьмёте ту же базу данных и
проделаете следующие действия, но примерная стоимость и ожидаемое число строк у вас может
немного отличаться из-за того, что статистика команды ANALYZE рассчитывается по случайной
выборке, а оценки стоимости зависят от конкретной платформы.
В этих примерах используется текстовый формат вывода EXPLAIN, принятый по умолчанию, как
более компактный и удобный для восприятия человеком. Если вывод EXPLAIN нужно передать ка-
кой-либо программе для дальнейшего анализа, лучше использовать один из машинно-ориентиро-
ванных форматов (XML, JSON или YAML).
14.1.1. Азы EXPLAIN
Структура плана запроса представляет собой дерево узлов плана. Узлы на нижнем уровне дере-
ва — это узлы сканирования, которые возвращают необработанные данные таблицы. Разным ти-
пам доступа к таблице соответствуют разные узлы: последовательное сканирование, сканирование
индекса и сканирование битовой карты. Источниками строк могут быть не только таблицы, но и
например, предложения VALUES и функции, возвращающие множества во FROM, и они представля-
ются отдельными типами узлов сканирования. Если запрос требует объединения, агрегатных вы-
числений, сортировки или других операций с исходными строками, над узлами сканирования по-
являются узлы, обозначающие эти операции. И так как обычно операции могут выполняться раз-
ными способами, на этом уровне тоже могут быть узлы разных типов. В выводе команды EXPLAIN
для каждого узла в дереве плана отводится одна строка, где показывается базовый тип узла плюс
оценка стоимости выполнения данного узла, которую сделал для него планировщик. Если для уз-
ла выводятся дополнительные свойства, в вывод могут добавляться дополнительные строки, с от-
ступом от основной информации узла. В самой первой строке (основной строке самого верхнего
узла) выводится общая стоимость выполнения для всего плана; именно это значение планировщик
старается минимизировать.
Взгляните на следующий простейший пример, просто иллюстрирующий формат вывода:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Этот запрос не содержит предложения WHERE, поэтому он должен просканировать все строки таб-
лицы, так что планировщик выбрал план простого последовательного сканирования. Числа, пере-
численные в скобках (слева направо), имеют следующий смысл:
422Оптимизация производительности
• Приблизительная стоимость запуска. Это время, которое проходит, прежде чем начнётся этап
вывода данных, например для сортирующего узла это время сортировки.
• Приблизительная общая стоимость. Она вычисляется в предположении, что узел плана вы-
полняется до конца, то есть возвращает все доступные строки. На практике родительский
узел может досрочно прекратить чтение строк дочернего (см. приведённый ниже пример с
LIMIT).
• Ожидаемое число строк, которое должен вывести этот узел плана. При этом так же предпола-
гается, что узел выполняется до конца.
• Ожидаемый средний размер строк, выводимых этим узлом плана (в байтах).
Стоимость может измеряться в произвольных единицах, определяемых параметрами планировщи-
ка (см. Подраздел 19.7.2). Традиционно единицей стоимости считается операция чтения страницы
с диска; то есть seq_page_cost обычно равен 1.0, а другие параметры задаётся относительно него.
Примеры в этом разделе выполняются со стандартными параметрами стоимости.
Важно понимать, что стоимость узла верхнего уровня включает стоимость всех его потомков.
Также важно осознавать, что эта стоимость отражает только те факторы, которые учитывает пла-
нировщик. В частности, она не зависит от времени, необходимого для передачи результирующих
строк клиенту, хотя оно может составлять значительную часть общего времени выполнения за-
проса. Тем не менее планировщик игнорирует эту величину, так как он всё равно не сможет из-
менить её, выбрав другой план. (Мы верим в то, что любой правильный план запроса выдаёт один
и тот же набор строк.)
Значение rows здесь имеет особенность — оно выражает не число строк, обработанных или про-
сканированных узлом плана, а число строк, выданных этим узлом. Часто оно окажется меньше
числа просканированных строк в результате применённой к узлу фильтрации по условиям WHERE.
В идеале, на верхнем уровне это значение будет приблизительно равно числу строк, которое фак-
тически возвращает, изменяет или удаляет запрос.
Возвращаясь к нашему примеру:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Эти числа получаются очень просто. Выполните:
SELECT relpages, reltuples FROM pg_class WHERE relname = ‘tenk1’;
и вы увидите, что tenk1 содержит 358 страниц диска и 10000 строк. Общая стоимость вычисляется
как (число_чтений_диска * seq_page_cost) + (число_просканированных_строк * cpu_tuple_cost). По
умолчанию, seq_page_cost равно 1.0, а cpu_tuple_cost — 0.01, так что приблизительная стоимость
запроса равна (358 * 1.0) + (10000 * 0.01) = 458.
Теперь давайте изменим запрос, добавив в него предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;
QUERY PLAN
————————————————————
Seq Scan on tenk1 (cost=0.00..483.00 rows=7001 width=244)
Filter: (unique1 &lt; 7000)
Заметьте, что в выводе EXPLAIN показано, что условие WHERE применено как «фильтр» к узлу плана
Seq Scan (Последовательное сканирование). Это означает, что узел плана проверяет это условие
для каждого просканированного им узла и выводит только те строки, которые удовлетворяют ему.
Предложение WHERE повлияло на оценку числа выходных строк. Однако при сканировании потре-
423Оптимизация производительности
буется прочитать все 10000 строк, поэтому общая стоимость не уменьшилась. На деле она даже
немного увеличилась (на 10000 * cpu_operator_cost, если быть точными), отражая дополнительное
время, которое потребуется процессору на проверку условия WHERE.
Фактическое число строк результата этого запроса будет равно 7000, но значение rows даёт толь-
ко приблизительное значение. Если вы попытаетесь повторить этот эксперимент, вы можете по-
лучить немного другую оценку; более того, она может меняться после каждой команды ANALYZE,
так как ANALYZE получает статистику по случайной выборке таблицы.
Теперь давайте сделаем ограничение более избирательным:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.01 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
В данном случае планировщик решил использовать план из двух этапов: сначала дочерний узел
плана просматривает индекс и находит в нём адреса строк, соответствующих условию индекса, а
затем верхний узел собственно выбирает эти строки из таблицы. Выбирать строки по отдельности
гораздо дороже, чем просто читать их последовательно, но так как читать придётся не все стра-
ницы таблицы, это всё равно будет дешевле, чем сканировать всю таблицу. (Использование двух
уровней плана объясняется тем, что верхний узел сортирует адреса строк, выбранных из индек-
са, в физическом порядке, прежде чем читать, чтобы снизить стоимость отдельных чтений. Слово
«bitmap» (битовая карта) в имени узла обозначает механизм, выполняющий сортировку.)
Теперь давайте добавим ещё одно условие в предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = ‘xxx’;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.01..229.40 rows=1 width=244)
Recheck Cond: (unique1 &lt; 100)
Filter: (stringu1 = ‘xxx’::name)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
Добавленное условие stringu1 = ‘xxx’ уменьшает оценку числа результирующих строк, но не
стоимость запроса, так как просматриваться будет тот же набор строк, что и раньше. Заметьте, что
условие на stringu1 не добавляется в качестве условия индекса, так как индекс построен только
по столбцу unique1. Вместо этого оно применяется как фильтр к строкам, полученным по индексу.
В результате стоимость даже немного увеличилась, отражая добавление этой проверки.
В некоторых случаях планировщик предпочтёт «простой» план сканирования индекса:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
QUERY PLAN
—————————————————————————
Index Scan using tenk1_unique1 on tenk1 (cost=0.29..8.30 rows=1 width=244)
Index Cond: (unique1 = 42)
В плане такого типа строки таблицы выбираются в порядке индекса, в результате чего чтение их
обходится дороже, но так как их немного, дополнительно сортировать положения строк не стоит.
Вы часто будете встречать этот тип плана в запросах, которые выбирают всего одну строку. Также
424Оптимизация производительности
он часто задействуется там, где условие ORDER BY соответствует порядку индекса, так как в этих
случаях для выполнения ORDER BY не требуется дополнительный шаг сортировки.
Если в таблице есть отдельные индексы по разным столбцам, фигурирующим в WHERE, планировщик
может выбрать сочетание этих индексов (с AND и OR):
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
————————————————————————————-
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
Index Cond: (unique2 &gt; 9000)
Но для этого потребуется обойти оба индекса, так что это не обязательно будет выгоднее, чем
просто просмотреть один индекс, а второе условие обработать как фильтр. Измените диапазон и
вы увидите, как это повлияет на план.
Следующий пример иллюстрирует эффекты LIMIT:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
————————————————————————————-
Limit (cost=0.29..14.48 rows=2 width=244)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..71.27 rows=10 width=244)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Это тот же запрос, что и раньше, но добавили мы в него LIMIT, чтобы возвращались не все стро-
ки, и планировщик решает выполнять запрос по-другому. Заметьте, что общая стоимость и число
строк для узла Index Scan рассчитываются в предположении, что он будет выполняться полностью.
Однако узел Limit должен остановиться, получив только пятую часть всех строк, так что его сто-
имость будет составлять одну пятую от вычисленной ранее, и это и будет итоговой оценкой стои-
мости запроса. С другой стороны, планировщик мог бы просто добавить в предыдущий план узел
Limit, но это не избавило бы от затрат на запуск сканирования битовой карты, а значит, общая
стоимость была бы выше 25 единиц.
Давайте попробуем соединить две таблицы по столбцам, которые мы уже использовали:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
Index Cond: (unique2 = t1.unique2)
В этом плане появляется узел соединения с вложенным циклом, на вход которому поступают дан-
ные от двух его потомков, узлов сканирования. Эту структуру плана отражает отступ основных
425Оптимизация производительности
строк его узлов. Первый, или «внешний», потомок соединения — узел сканирования битовой кар-
ты, похожий на те, что мы видели раньше. Его стоимость и число строк те же, что мы получили
бы для запроса SELECT … WHERE unique1 &lt; 10, так как к этому узлу добавлено предложение
WHERE unique1 &lt; 10. Условие t1.unique2 = t2.unique2 ещё не учитывается, поэтому оно не влияет
на число строк узла внешнего сканирования. Узел соединения с вложенным циклом будет выпол-
нять узел «внутреннего» потомка для каждой строки, полученной из внешнего потомка. Значения
столбцов из текущей внешней строки могут использоваться во внутреннем сканировании (в дан-
ном случае это значение t1.unique2), поэтому мы получаем план и стоимость примерно такие,
как и раньше для простого запроса SELECT … WHERE t2.unique2 = константа. (На самом деле
оценочная стоимость немного меньше, в предположении, что при неоднократном сканировании
индекса по t2 положительную роль сыграет кеширование.) В результате стоимость узла цикла
складывается из стоимости внешнего сканирования, цены внутреннего сканирования, умножен-
ной на число строк (здесь 10 * 7.91), и небольшой наценки за обработку соединения.
В этом примере число выходных строк соединения равно произведению чисел строк двух узлов
сканирования, но это не всегда будет так, потому что в дополнительных условиях WHERE могут
упоминаться обе таблицы, так что применить их можно будет только в точке соединения, а не в
одном из узлов сканирования. Например:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t2.unique2 &lt; 10 AND t1.hundred &lt; t2.hundred;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..49.46 rows=33 width=488)
Join Filter: (t1.hundred &lt; t2.hundred)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Materialize (cost=0.29..8.51 rows=10 width=244)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..8.46 rows=10
width=244)
Index Cond: (unique2 &lt; 10)
Условие t1.hundred &lt; t2.hundred не может быть проверено в индексе tenk2_unique2, поэтому оно
применяется в узле соединения. Это уменьшает оценку числа выходных строк, тогда как число
строк в узлах сканирования не меняется.
Заметьте, что здесь планировщик решил «материализовать» внутреннее отношение соединения,
поместив поверх него узел плана Materialize (Материализовать). Это значит, что сканирование
индекса t2 будет выполняться только единожды, при том, что узлу вложенного цикла соединения
потребуется прочитать данные десять раз, по числу строк во внешнем соединении. Узел Materialize
сохраняет считанные данные в памяти, чтобы затем выдать их из памяти на следующих проходах.
Выполняя внешние соединения, вы можете встретить узлы плана с присоединёнными условиями,
как обычными «Filter», так и «Join Filter» (Фильтр соединения). Условия Join Filter формируются
из предложения ON для внешнего соединения, так что если строка не удовлетворяет условию Join
Filter, она всё же выдаётся как строка, дополненная значениями NULL. Обычное же условие Filter
применяется после правил внешнего соединения и поэтому полностью исключает строки. Во внут-
реннем соединении оба этих фильтра работают одинаково.
Если немного изменить избирательность запроса, мы можем получить совсем другой план соеди-
нения:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
426Оптимизация производительности
QUERY PLAN
——————————————————————————————
Hash Join (cost=230.47..713.98 rows=101 width=488)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0)
Index Cond: (unique1 &lt; 100)
Здесь планировщик выбирает соединение по хешу, при котором строки одной таблицы записыва-
ются в хеш-таблицу в памяти, после чего сканируется другая таблица и для каждой её строки про-
веряется соответствие по хеш-таблице. Обратите внимание, что и здесь отступы отражают струк-
туру плана: результат сканирования битовой карты по tenk1 подаётся на вход узлу Hash, который
конструирует хеш-таблицу. Затем она передаётся узлу Hash Join, который читает строки из узла
внешнего потомка и проверяет их по этой хеш-таблице.
Ещё один возможный тип соединения — соединение слиянием:
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=198.11..268.19 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Sort (cost=197.83..200.33 rows=1000 width=244)
Sort Key: t2.unique2
-&gt; Seq Scan on onek t2 (cost=0.00..148.00 rows=1000 width=244)
Соединение слиянием требует, чтобы входные данные для него были отсортированы по ключам
соединения. В этом плане данные tenk1 сортируются после сканирования индекса, при котором
все строки просматриваются в правильном порядке, но таблицу onek выгоднее оказывается после-
довательно просканировать и отсортировать, так как в этой таблице нужно обработать гораздо
больше строк. (Последовательное сканирование и сортировка часто бывает быстрее сканирования
индекса, когда нужно отсортировать много строк, так как при сканировании по индексу обраще-
ния к диску не упорядочены.)
Один из способов посмотреть различные планы — принудить планировщик не считать выбранную
им стратегию самой выгодной, используя флаги, описанные в Подразделе 19.7.1. (Это полезный,
хотя и грубый инструмент. См. также Раздел 14.3.) Например, если мы убеждены, что последова-
тельное сканирование и сортировка — не лучший способ обработать таблицу onek в предыдущем
примере, мы можем попробовать
SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=0.56..292.65 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
427Оптимизация производительности
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Index Scan using onek_unique2 on onek t2 (cost=0.28..224.79 rows=1000
width=244)
Видно, что планировщик считает сортировку onek со сканированием индекса примерно на 12%
дороже, чем последовательное сканирование и сортировку. Конечно, может возникнуть вопрос —
а правильно ли это? Мы можем ответить на него, используя описанную ниже команду EXPLAIN
ANALYZE.
14.1.2. EXPLAIN ANALYZE
Точность оценок планировщика можно проверить, используя команду EXPLAIN с параметром
ANALYZE. С этим параметром EXPLAIN на самом деле выполняет запрос, а затем выводит фактиче-
ское число строк и время выполнения, накопленное в каждом узле плана, вместе с теми же оцен-
ками, что выдаёт обычная команда EXPLAIN. Например, мы можем получить примерно такой ре-
зультат:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488) (actual time=0.128..0.377 rows=10
loops=1)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244) (actual
time=0.057..0.121 rows=10 loops=1)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
(actual time=0.024..0.024 rows=10 loops=1)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
(actual time=0.021..0.022 rows=1 loops=10)
Index Cond: (unique2 = t1.unique2)
Planning time: 0.181 ms
Execution time: 0.501 ms
Заметьте, что значения «actual time» (фактическое время) приводятся в миллисекундах, тогда как
оценки cost (стоимость) выражаются в произвольных единицах, так что они вряд ли совпадут.
Обычно важнее определить, насколько приблизительная оценка числа строк близка к действи-
тельности. В этом примере они в точности совпали, но на практике так бывает редко.
В некоторых планах запросов некоторый внутренний узел может выполняться неоднократно. На-
пример, внутреннее сканирование индекса будет выполняться для каждой внешней строки во вло-
женном цикле верхнего уровня. В таких случаях значение loops (циклы) показывает, сколько все-
го раз выполнялся этот узел, а фактическое время и число строк вычисляется как среднее по всем
итерациям. Это делается для того, чтобы полученные значения можно было сравнить с выводимы-
ми приблизительными оценками. Чтобы получить общее время, затраченное на выполнение узла,
время одной итерации нужно умножить на значение loops. В показанном выше примере мы по-
тратили в общей сложности 0.220 мс на сканирование индекса в tenk2.
В ряде случаев EXPLAIN ANALYZE выводит дополнительную статистику по выполнению, включаю-
щую не только время выполнения узлов и число строк. Для узлов Sort и Hash, например выводится
следующая информация:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;
428Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Sort (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100
loops=1)
Sort Key: t1.fivethous
Sort Method: quicksort Memory: 77kB
-&gt; Hash Join (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427
rows=100 loops=1)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244) (actual
time=0.007..2.583 rows=10000 loops=1)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659
rows=100 loops=1)
Buckets: 1024 Batches: 1 Memory Usage: 28kB
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
(actual time=0.080..0.526 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0) (actual time=0.049..0.049 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.194 ms
Execution time: 8.008 ms
Для узла Sort показывается использованный метод и место сортировки (в памяти или на диске),
а также задействованный объём памяти. Для узла Hash выводится число групп и пакетов хеша, а
также максимальный объём, который заняла в памяти хеш-таблица. (Если число пакетов больше
одного, часть хеш-таблицы будет выгружаться на диск и занимать какое-то пространство, но его
объём здесь не показывается.)
Другая полезная дополнительная информация — число строк, удалённых условием фильтра:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;
QUERY PLAN
——————————————————————————————–
Seq Scan on tenk1 (cost=0.00..483.00 rows=7000 width=244) (actual time=0.016..5.107
rows=7000 loops=1)
Filter: (ten &lt; 7)
Rows Removed by Filter: 3000
Planning time: 0.083 ms
Execution time: 5.905 ms
Эти значения могут быть особенно ценны для условий фильтра, применённых к узлам соединения.
Строка «Rows Removed» выводится, только когда условие фильтра отбрасывает минимум одну про-
сканированную строку или потенциальную пару соединения, если это узел соединения.
Похожую ситуацию можно наблюдать при сканировании «неточного» индекса. Например, рас-
смотрим этот план поиска многоугольников, содержащих указанную точку:
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Seq Scan on polygon_tbl (cost=0.00..1.05 rows=1 width=32) (actual time=0.044..0.044
rows=0 loops=1)
Filter: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Filter: 4
Planning time: 0.040 ms
Execution time: 0.083 ms
429Оптимизация производительности
Планировщик полагает (и вполне справедливо), что таблица слишком мала для сканирования по
индексу, поэтому он выбирает последовательное сканирование, при котором все строки отбрасы-
ваются условием фильтра. Но если мы принудим его выбрать сканирование по индексу, мы полу-
чим:
SET enable_seqscan TO off;
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Index Scan using gpolygonind on polygon_tbl (cost=0.13..8.15 rows=1 width=32) (actual
time=0.062..0.062 rows=0 loops=1)
Index Cond: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Index Recheck: 1
Planning time: 0.034 ms
Execution time: 0.144 ms
Здесь мы видим, что индекс вернул одну потенциально подходящую строку, но затем она была
отброшена при перепроверке условия индекса. Это объясняется тем, что индекс GiST является
«неточным» для проверок включений многоугольников: фактически он возвращает строки с мно-
гоугольниками, перекрывающими точку по координатам, а затем для этих строк нужно выполнять
точную проверку.
EXPLAIN принимает параметр BUFFERS (который также можно применять с ANALYZE), включающий
ещё более подробную статистику выполнения запроса:
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
——————————————————————————————–
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244) (actual
time=0.323..0.342 rows=10 loops=1)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
Buffers: shared hit=15
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0) (actual time=0.309..0.309 rows=0
loops=1)
Buffers: shared hit=7
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Buffers: shared hit=2
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
(actual time=0.227..0.227 rows=999 loops=1)
Index Cond: (unique2 &gt; 9000)
Buffers: shared hit=5
Planning time: 0.088 ms
Execution time: 0.423 ms
Значения, которые выводятся с параметром BUFFERS, помогают понять, на какие части запроса
приходится большинство операций ввода-вывода.
Не забывайте, что EXPLAIN ANALYZE действительно выполняет запрос, хотя его результаты могут
не показываться, а заменяться выводом команды EXPLAIN. Поэтому при таком анализе возможны
побочные эффекты. Если вы хотите проанализировать запрос, изменяющий данные, но при этом
сохранить прежние данные таблицы, вы можете откатить транзакцию после запроса:
BEGIN;
EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;
430Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Update on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual time=14.628..14.628
rows=0 loops=1)
-&gt; Bitmap Heap Scan on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual
time=0.101..0.439 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.079 ms
Execution time: 14.727 ms
ROLLBACK;
Как показано в этом примере, когда выполняется команда INSERT, UPDATE или DELETE, собственно
изменение данных в таблице происходит в узле верхнего уровня Insert, Update или Delete. Узлы
плана более низких уровней выполняют работу по нахождению старых строк и/или вычислению
новых данных. Поэтому вверху мы видим тот же тип сканирования битовой карты, что и раньше,
только теперь его вывод подаётся узлу Update, который сохраняет изменённые строки. Стоит от-
метить, что узел, изменяющий данные, может выполняться значительное время (в данном случае
это составляет львиную часть всего времени), но планировщик не учитывает эту работу в оценке
общей стоимости. Это связано с тем, что эта работа будет одинаковой при любом правильном пла-
не запроса, и поэтому на выбор плана она не влияет.
Когда команда UPDATE или DELETE имеет дело с иерархией наследования, вывод может быть таким:
EXPLAIN UPDATE parent SET f2 = f2 + 1 WHERE f1 = 101;
QUERY PLAN
———————————————————————————–
Update on parent (cost=0.00..24.53 rows=4 width=14)
Update on parent
Update on child1
Update on child2
Update on child3
-&gt; Seq Scan on parent (cost=0.00..0.00 rows=1 width=14)
Filter: (f1 = 101)
-&gt; Index Scan using child1_f1_key on child1 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child2_f1_key on child2 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child3_f1_key on child3 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
В этом примере узлу Update помимо изначально упомянутой в запросе родительской таблицы нуж-
но обработать ещё три дочерние таблицы. Поэтому формируются четыре плана сканирования, по
одному для каждой таблицы. Ясности ради для узла Update добавляется примечание, показываю-
щее, какие именно таблицы будут изменяться, в том же порядке, в каком они идут в соответствую-
щих внутренних планах. (Эти примечания появились в PostgreSQL 9.5; до этого о целевых таблицах
приходилось догадываться, изучая внутренние планы узла.)
Под заголовком Planning time (Время планирования) команда EXPLAIN ANALYZE выводит время,
затраченное на построение плана запроса из разобранного запроса и его оптимизацию. Время
собственно разбора или перезаписи запроса в него не включается.
Значение Execution time (Время выполнения), выводимое командой EXPLAIN ANALYZE, включает
продолжительность запуска и остановки исполнителя запроса, а также время выполнения всех
сработавших триггеров, но не включает время разбора, перезаписи и планирования запроса. Вре-
мя, потраченное на выполнение триггеров BEFORE (если такие имеются) включается во время соот-
431Оптимизация производительности
ветствующих узлов Insert, Update или Delete node; но время выполнения триггеров AFTER не учиты-
вается, так как триггеры AFTER срабатывают после выполнения всего плана. Общее время, прове-
дённое в каждом триггере (BEFORE или AFTER), также выводится отдельно. Заметьте, что триггеры
отложенных ограничений выполняются только в конце транзакции, так что время их выполнения
EXPLAIN ANALYZE не учитывает.
14.1.3. Ограничения
Время выполнения, измеренное командой EXPLAIN ANALYZE, может значительно отличаться от
времени выполнения того же запроса в обычном режиме. Тому есть две основных причины. Во-
первых, так как при анализе никакие строки результата не передаются клиенту, время ввода/вы-
вода и передачи по сети не учитывается. Во-вторых, может быть существенной дополнительная
нагрузка, связанная с функциями измерений EXPLAIN ANALYZE, особенно в системах, где вызов
gettimeofday() выполняется медленно. Для измерения этой нагрузки вы можете воспользоваться
утилитой pg_test_timing.
Результаты EXPLAIN не следует распространять на ситуации, значительно отличающиеся от тех, в
которых вы проводите тестирование. В частности, не следует полагать, что выводы, полученные
для игрушечной таблицы, будут применимы и для настоящих больших таблиц. Оценки стоимости
нелинейны и планировщик может выбирать разные планы в зависимости от размера таблицы. На-
пример, в крайнем случае вся таблица может уместиться в одну страницу диска, и тогда вы почти
наверняка получите план последовательного сканирования, независимо от того, есть у неё и ин-
дексы или нет. Планировщик понимает, что для обработки таблицы ему в любом случае потребу-
ется прочитать одну страницу, так что нет никакого смысла обращаться к ещё одной странице за
индексом. (Мы наблюдали это в показанном выше примере с polygon_tbl.)
Бывает, что фактическое и приближённо оценённое значения не совпадают, но в этом нет ничего
плохого. Например, это возможно, когда выполнение плана узла прекращается преждевременно
из-за указания LIMIT или подобного эффекта. Например, для запроса с LIMIT, который мы пробо-
вали раньше:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
——————————————————————————————–
Limit (cost=0.29..14.71 rows=2 width=244) (actual time=0.177..0.249 rows=2 loops=1)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..72.42 rows=10 width=244)
(actual time=0.174..0.244 rows=2 loops=1)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Rows Removed by Filter: 287
Planning time: 0.096 ms
Execution time: 0.336 ms
Оценки стоимости и числа строк для узла Index Scan показываются в предположении, что этот узел
будет выполняться до конца. Но в действительности узел Limit прекратил запрашивать строки,
как только получил первые две, так что фактическое число строк равно 2 и время выполнения
запроса будет меньше, чем рассчитал планировщик. Но это не ошибка, а просто следствие того,
что оценённые и фактические значения выводятся по-разному.
Соединения слиянием также имеют свои особенности, которые могут ввести в заблуждение. Со-
единение слиянием прекратит читать один источник данных, если второй будет прочитан до кон-
ца, а следующее значение ключа в первом больше последнего значения во втором. В этом случае
пар строк больше не будет, так что сканировать первый источник дальше нет смысла. В результате
будут прочитаны не все строки одного потомка и вы получите тот же эффект, что и с LIMIT. Кро-
ме того, если внешний (первый) потомок содержит строки с повторяющимися значениями клю-
ча, внутренний (второй) потомок сдвинется назад и повторно выдаст строки для этого значения
ключа. EXPLAIN ANALYZE считает эти повторяющиеся строки, как если бы это действительно были
дополнительные строки внутреннего источника. Когда во внешнем узле много таких повторений
432Оптимизация производительности
ключей, фактическое число строк, подсчитанное для внутреннего узла, может значительно пре-
вышать число строк в соответствующей таблице.
Для узлов BitmapAnd (Логическое произведение битовых карт) и BitmapOr (Логическое сложение
битовых карт) фактическое число строк всегда равно 0 из-за ограничений реализации.
Обычно EXPLAIN выводит подробности для каждого узла плана, сгенерированного планировщиком.
Однако бывают ситуации, когда исполнитель может определить, что некоторые узлы не требуют-
ся, и не выполнять их; в настоящее время это поддерживает только узел Append. Узел этого типа
может отбросить подчинённые узлы, определив, что они не выдадут ни одной записи, нужной для
запроса. Понять, что узлы были удалены таким образом, можно по наличию свойства «Subplans
Removed» (Подпланов удалено) в выводе EXPLAIN.
14.2. Статистика, используемая планировщиком
14.2.1. Статистика по одному столбцу
Как было показано в предыдущем разделе, планировщик запросов должен оценить число строк,
возвращаемых запросов, чтобы сделать правильный выбор в отношении плана запроса. В этом
разделе кратко описывается статистика, которую использует система для этих оценок.
В частности, статистика включает общее число записей в каждой таблице и индексе, а также
число дисковых блоков, которые они занимают. Эта информация содержится в таблице pg_class,
в столбцах reltuples и relpages. Получить её можно, например так:
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE ‘tenk1%’;
relname
| relkind | reltuples | relpages
———————-+———+———–+———-
tenk1
| r
|
10000 |
358
tenk1_hundred
| i
|
10000 |
30
tenk1_thous_tenthous | i
|
10000 |
30
tenk1_unique1
| i
|
10000 |
30
tenk1_unique2
| i
|
10000 |
30
(5 rows)
Здесь мы видим, что tenk1 содержит 10000 строк данных и столько же строк в индексах (что неуди-
вительно), но объём индексов гораздо меньше таблицы.
Для большей эффективности reltuples и relpages не пересчитываются «на лету», так что они
обычно содержат несколько устаревшие значения. Их обновляют команды VACUUM, ANALYZE и
несколько команд DDL, такие как CREATE INDEX. VACUUM и ANALYZE могут не сканировать всю таб-
лицу (и обычно так и делают), а только вычислить приращение reltuples по части таблицы, так
что результат остаётся приблизительным. В любом случае планировщик пересчитывает значения,
полученные из pg_class, в пропорции к текущему физическому размеру таблицы и таким образом
уточняет приближение.
Большинство запросов возвращают не все строки таблицы, а только немногие из них, ограничен-
ные условиями WHERE. Поэтому планировщику нужно оценить избирательность условий WHERE,
то есть определить, какой процент строк будет соответствовать каждому условию в предложении
WHERE. Нужная для этого информация хранится в системном каталоге pg_statistic. Значения в
pg_statistic обновляются командами ANALYZE и VACUUM ANALYZE и никогда не бывают точными,
даже сразу после обновления.
Для исследования статистики лучше обращаться не непосредственно к таблице pg_statistic, а к
представлению pg_stats, предназначенному для облегчения восприятия этой информации. Кроме
того, представление pg_stats доступно для чтения всем, тогда как pg_statistic — только супер-
433Оптимизация производительности
пользователям. (Это сделано для того, чтобы непривилегированные пользователи не могли ничего
узнать о содержимом таблиц других людей из статистики. Представление pg_stats устроено так,
что оно показывает строки только для тех таблиц, которые может читать данный пользователь.)
Например, мы можем выполнить:
SELECT attname, inherited, n_distinct,
array_to_string(most_common_vals, E’\n’) as most_common_vals
FROM pg_stats
WHERE tablename = ‘road’;
attname | inherited | n_distinct |
most_common_vals
———+———–+————+————————————
name
| f
| -0.363388 | I- 580
Ramp+
|
|
| I- 880
Ramp+
|
|
| Sp Railroad
+
|
|
| I- 580
+
|
|
| I- 680
Ramp
name
| t
| -0.284859 | I- 880
Ramp+
|
|
| I- 580
Ramp+
|
|
| I- 680
Ramp+
|
|
| I- 580
+
|
|
| State Hwy 13
Ramp
(2 rows)
Заметьте, что для одного столбца показываются две строки: одна соответствует полной иерархии
наследования, построенной для таблицы road (inherited=t), и другая относится непосредственно
к таблице road (inherited=f).
Объём информации, сохраняемой в pg_statistic командой ANALYZE, в частности максимальное
число записей в массивах most_common_vals (самые популярные значения) и histogram_bounds
(границы гистограмм) для каждого столбца, можно ограничить на уровне столбцов с помо-
щью команды ALTER TABLE SET STATISTICS или глобально, установив параметр конфигурации
default_statistics_target. В настоящее время ограничение по умолчанию равно 100 записям. Уве-
личивая этот предел, можно увеличить точность оценок планировщика, особенно для столбцов
с нерегулярным распределением данных, ценой большего объёма pg_statistic и, возможно, уве-
личения времени расчёта этой статистики. И напротив, для столбцов с простым распределением
данных может быть достаточно меньшего предела.
Подробнее использование статистики планировщиком описывается в Главе 70.
14.2.2. Расширенная статистика
Часто наблюдается картина, когда медленное выполнение запросов объясняется плохим выбором
плана из-за того, что несколько столбцов, фигурирующих в условиях запроса, оказываются свя-
занными. Обычно планировщик полагает, что несколько условий не зависят друг от друга, а это
предположение оказывается неверным, когда значения этих столбцов коррелируют. Обычная ста-
тистика, которая по природе своей строится по отдельным столбцам, не может выявить корреля-
ции между столбцами. Однако PostgreSQL имеет возможность вычислять многовариантную ста-
тистику, которая может собирать необходимую для этого информацию.
Так как число возможных комбинаций столбцов очень велико, автоматически вычислять много-
вариантную статистику непрактично. Вместо этого можно создать объекты расширенной стати-
стики, чаще называемые просто объектами статистики, чтобы сервер собирал статистику по
некоторым наборам столбцов, представляющим интерес.
Объекты статистики создаются командой CREATE STATISTICS (за подробностями обратитесь к
её описанию). При создании такого объекта просто создаётся запись в каталоге, выражающая
востребованность этой статистики. Собственно сбор данных выполняется командой ANALYZE (при
запуске вручную или фоновом автоанализе). Изучить собранные значения можно в каталоге
pg_statistic_ext.
434Оптимизация производительности
Команда ANALYZE вычисляет расширенную статистику по той же выборке строк таблицы, которая
используется и для вычисления обычной статистики по отдельным столбцам. Так как размер вы-
борки увеличивается с увеличением целевого ограничения статистики для таблицы или любых её
столбцов (как описано в предыдущем разделе), при большем целевом ограничении обычно полу-
чается более точная расширенная статистика, но и времени на её вычисление требуется больше.
В следующих подразделах описываются виды расширенной статистики, поддерживаемые в насто-
ящее время.
14.2.2.1. Функциональные зависимости
Простейший вид расширенной статистики отслеживает функциональные зависимости (это поня-
тие используется в определении нормальных форм баз данных). Мы называем столбец b функцио-
нально зависимым от столбца a, если знания значения a достаточно для определения значения b,
то есть не существует двух строк с одинаковыми значениями a, но разными значениями b. В пол-
ностью нормализованной базе данных функциональные зависимости должны существовать только
в первичных ключах и суперключах. Однако на практике многие наборы данных не нормализуют-
ся полностью по разным причинам; например, денормализация часто производится намеренно по
соображениям производительности.
Существование функциональных зависимостей напрямую влияет на точность оценок в определён-
ных запросах. Если запрос содержит условия как по независимым, так и по зависимым столбцам,
условия по зависимым столбцам дополнительно не сокращают размер результата. Однако без зна-
ния о функциональной зависимости планировщик запросов будет полагать, что все условия неза-
висимы, и недооценит размер результата.
Для информирования планировщика о функциональных зависимостях команда ANALYZE может со-
бирать показатели зависимостей между столбцами. Оценить степень зависимости между всеми
наборами столбцов обошлось бы непозволительно дорого, поэтому сбор данных ограничивается
только теми группами столбцов, которые фигурируют вместе в объекте статистики, определённом
со свойством dependencies. Во избежание ненужных издержек при выполнении ANALYZE и после-
дующем планировании запросов статистику с dependencies рекомендуется создавать только для
групп сильно коррелирующих столбцов.
Взгляните на пример сбора статистики функциональной зависимости:
CREATE STATISTICS stts (dependencies) ON zip, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxname, stxkeys, stxdependencies
FROM pg_statistic_ext
WHERE stxname = ‘stts’;
stxname | stxkeys |
stxdependencies
———+———+——————————————
stts
| 1 5
| {“1 =&gt; 5”: 1.000000, “5 =&gt; 1”: 0.423130}
(1 row)
В показанном случае столбец 1 (код zip) полностью определяет столбец 5 (city), так что коэффи-
циент равен 1.0, тогда как город (столбец city) определяет код ZIP только в 42% всех случаев, что
означает, что многие города (58%) представлены несколькими кодами ZIP.
При вычислении избирательности запроса, в котором задействованы функционально зависимые
столбцы, планировщик корректирует оценки избирательности по условиям, используя коэффици-
енты зависимостей, чтобы не допустить недооценки размера результата.
14.2.2.1.1. Ограничения функциональных зависимостей
Функциональные зависимости в настоящее время применяются только при рассмотрении простых
условий с равенствами, сравнивающих значения столбцов с константами. Они не используются для
улучшения оценок при проверке равенства двух столбцов или сравнении столбца с выражением,
а также в условиях с диапазоном, условиях LIKE или любых других видах условий.
435Оптимизация производительности
Рассматривая функциональные зависимости, планировщик предполагает, что условия по задей-
ствованным столбцам совместимы и таким образом избыточны. Если условия несовместимы, пра-
вильной оценкой должен быть ноль строк, но эта возможность не рассматривается. Например, с
таким запросом
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘94105’;
планировщик отбросит условие с city, так как оно не влияет на избирательность, что верно. Од-
нако он сделает то же предположение и в таком случае:
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘90210’;
хотя на самом деле этому запросу будет удовлетворять ноль строк. Но статистика функциональной
зависимости не даёт достаточно информации, чтобы прийти к такому заключению.
Во многих практических ситуациях это предположение обычно удовлетворяется; например, гра-
фический интерфейс приложения для последующего формирования запроса может не допускать
выбор несовместимого сочетания города и кода ZIP. Но когда это не так, статистика функциональ-
ной зависимости может не подойти.
14.2.2.2. Многовариантное число различных значений
Статистика по одному столбцу содержит число различных значений в каждом отдельном столбце.
Оценки числа различных значений в сочетании нескольких столбцов (например, в GROUP BY a,
b) часто оказываются ошибочными, когда планировщик имеет статистические данные только по
отдельным столбцам, что приводит к выбору плохих планов.
Для улучшения таких оценок операция ANALYZE может собирать статистику по различным значе-
ниям для группы столбцов. Как и ранее, это непрактично делать для каждой возможной группы
столбцов, так что данные собираются только по тем группам столбцов, которые указаны в опре-
делении объекта статистики, создаваемого со свойством ndistinct. Данные будут собираться по
всем возможным сочетаниям из двух или нескольких столбцов из перечисленных в определении.
В продолжение предыдущего примера, количества различных значений в таблице ZIP-кодов могут
выглядеть так:
CREATE STATISTICS stts2 (ndistinct) ON zip, state, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxkeys AS k, stxndistinct AS nd
FROM pg_statistic_ext
WHERE stxname = ‘stts2’;
-[ RECORD 1 ]——————————————————–
k | 1 2 5
nd | {“1, 2”: 33178, “1, 5”: 33178, “2, 5”: 27435, “1, 2, 5”: 33178}
(1 row)
Как видно, есть три комбинации столбцов, имеющих 33178 различных значений: код ZIP и штат;
код ZIP и город; код ZIP, город и штат (то, что все эти числа равны, ожидаемый факт, так как сам
по себе код ZIP в этой таблице уникален). С другой стороны, сочетание города и штата даёт только
27435 различных значений.
Объект статистики ndistinct рекомендуется создавать только для тех сочетаний столбцов, кото-
рые действительно используются при группировке, и только когда неправильная оценка числа
групп может привести к выбору плохих планов. В противном случае усилия, потраченные на вы-
полнение ANALYZE, будут напрасными.
14.3. Управление планировщиком с помощью явных
предложений JOIN
436Оптимизация производительности
Поведением планировщика в некоторой степени можно управлять, используя явный синтаксис
JOIN. Понять, когда и почему это бывает нужно, поможет небольшое введение.
В простом запросе с соединением, например таком:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
планировщик может соединять данные таблицы в любом порядке. Например, он может разрабо-
тать план, в котором сначала A соединяется с B по условию WHERE a.id = b.id, а затем C соединя-
ется с получившейся таблицей по другому условию WHERE. Либо он может соединить B с C, а затем
с A результатом соединения. Он также может соединить сначала A с C, а затем результат с B — но
это будет не эффективно, так как ему придётся сформировать полное декартово произведение A
и C из-за отсутствия в предложении WHERE условия, подходящего для оптимизации соединения. (В
PostgreSQL исполнитель запросов может соединять только по две таблицы, поэтому для получения
результата нужно выбрать один из этих способов.) При этом важно понимать, что все эти разные
способы соединения дают одинаковые по смыслу результаты, но стоимость их может различаться
многократно. Поэтому планировщик должен изучить их все и найти самый эффективный способ
выполнения запроса.
Когда запрос включает только две или три таблицы, возможны всего несколько вариантов их со-
единения. Но их число растёт экспоненциально с увеличением числа задействованных таблиц.
Если число таблиц больше десяти, уже практически невозможно выполнить полный перебор всех
вариантов, и даже для шести или семи таблиц планирование может занять недопустимо много
времени. Когда таблиц слишком много, планировщик PostgreSQL переключается с полного поис-
ка на алгоритм генетического вероятностного поиска в ограниченном числе вариантов. (Порог
для этого переключения задаётся параметром выполнения geqo_threshold.) Генетический поиск
выполняется быстрее, но не гарантирует, что найденный план будет наилучшим.
Когда запрос включает внешние соединения, планировщик имеет меньше степеней свободы, чем
с обычными (внутренними) соединениями. Например, рассмотрим запрос:
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Хотя ограничения в этом запросе очень похожи на показанные в предыдущем примере, смысл его
отличается, так как результирующая строка должна выдаваться для каждой строки A, даже если
для неё не находится соответствия в соединении B и C. Таким образом, здесь планировщик не мо-
жет выбирать порядок соединения: он должен соединить B с C, а затем соединить A с результатом.
Соответственно, и план этого запроса построится быстрее, чем предыдущего. В других случаях
планировщик сможет определить, что можно безопасно выбрать один из нескольких способов со-
единения. Например, для запроса:
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
можно соединить A либо с B, либо с C. В настоящее время только FULL JOIN полностью ограничи-
вает порядок соединения. На практике в большинстве запросов с LEFT JOIN и RIGHT JOIN порядком
можно управлять в некоторой степени.
Синтаксис явного внутреннего соединения (INNER JOIN, CROSS JOIN или лаконичный JOIN) по смыс-
лу равнозначен перечислению отношений в предложении FROM, так что он никак не ограничивает
порядок соединений.
Хотя большинство видов JOIN не полностью ограничивают порядок соединения, в PostgreSQL мож-
но принудить планировщик обрабатывать все предложения JOIN как ограничивающие этот поря-
док. Например, следующие три запроса логически равнозначны:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Но если мы укажем планировщику соблюдать порядок JOIN, на планирование второго и третьего
уйдёт меньше времени. Когда речь идёт только о трёх таблицах, выигрыш будет незначительным,
но для множества таблиц это может быть очень эффективно.
437Оптимизация производительности
Чтобы планировщик соблюдал порядок внутреннего соединения, выраженный явно предложения-
ми JOIN, нужно присвоить параметру выполнения join_collapse_limit значение 1. (Другие допусти-
мые значения обсуждаются ниже.)
Чтобы сократить время поиска, необязательно полностью ограничивать порядок соединений, в
JOIN можно соединять элементы как в обычном списке FROM. Например, рассмотрите следующий
запрос:
SELECT * FROM a CROSS JOIN b, c, d, e WHERE …;
Если join_collapse_limit = 1, планировщик будет вынужден соединить A с B раньше, чем резуль-
тат с другими таблицами, но в дальнейшем выборе вариантов он не ограничен. В данном примере
число возможных вариантов соединения уменьшается в 5 раз.
Упрощать для планировщика задачу перебора вариантов таким способом — это полезный приём,
помогающий не только выбрать сократить время планирования, но и подтолкнуть планировщик
к хорошему плану. Если планировщик по умолчанию выбирает неудачный порядок соединения,
вы можете заставить его выбрать лучший, применив синтаксис JOIN, конечно если вы сами его
знаете. Эффект подобной оптимизации рекомендуется подтверждать экспериментально.
На время планирования влияет и другой, тесно связанный фактор — решение о включении подза-
просов в родительский запрос. Пример такого запроса:
SELECT *
FROM x, y,
(SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;
Такая же ситуация может возникнуть с представлением, содержащим соединение; вместо ссылки
на это представление будет вставлено его выражение SELECT и в результате получится запрос, по-
хожий на показанный выше. Обычно планировщик старается включить подзапрос в родительский
запрос и получить таким образом:
SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;
Часто это позволяет построить лучший план, чем при планировании подзапросов по отдельности.
(Например, внешние условия WHERE могут быть таковы, что при соединении сначала X с A будет ис-
ключено множество строк A, а значит формировать логический результат подзапроса полностью
не потребуется.) Но в то же время тем самым мы увеличиваем время планирования; две задачи
соединения трёх элементов мы заменяем одной с пятью элементами. Так как число вариантов уве-
личивается экспоненциально, сложность задачи увеличивается многократно. Планировщик пыта-
ется избежать проблем поиска с огромным числом вариантов, рассматривая подзапросы отдельно,
если в предложении FROM родительского запроса оказывается больше чем from_collapse_limit
элементов. Изменяя этот параметр выполнения, можно подобрать оптимальное соотношение вре-
мени планирования и качества плана.
Параметры from_collapse_limit и join_collapse_limit называются похоже, потому что они делают
практически одно и то же: первый параметр определяет, когда планировщик будет «сносить» в
предложение FROM подзапросы, а второй — явные соединения. Обычно join_collapse_limit уста-
навливается равным from_collapse_limit (чтобы явные соединения и подзапросы обрабатывались
одинаково) или 1 (если требуется управлять порядком соединений). Но вы можете задать другие
значения, чтобы добиться оптимального соотношения времени планирования и времени выполне-
ния запросов.
14.4. Наполнение базы данных
Довольно часто в начале или в процессе использования базы данных возникает необходимость
загрузить в неё большой объём данных. В этом разделе приведены рекомендации, которые помогут
сделать это максимально эффективно.
14.4.1. Отключите автофиксацию транзакций
438Оптимизация производительности
Выполняя серию команд INSERT, выключите автофиксацию транзакций и зафиксируйте транзак-
цию только один раз в самом конце. (В обычном SQL это означает, что нужно выполнить BEGIN до,
и COMMIT после этой серии. Некоторые клиентские библиотеки могут делать это автоматически,
в таких случаях нужно убедиться, что это так.) Если вы будете фиксировать каждое добавление
по отдельности, PostgreSQL придётся проделать много действий для каждой добавляемой строки.
Выполнять все операции в одной транзакции хорошо ещё и потому, что в случае ошибки добавле-
ния одной из строк произойдёт откат к исходному состоянию и вы не окажетесь в сложной ситуа-
ции с частично загруженными данными.
14.4.2. Используйте COPY
Используйте COPY, чтобы загрузить все строки одной командой вместо серии INSERT. Команда
COPY оптимизирована для загрузки большого количества строк; хотя она не так гибка, как INSERT,
но при загрузке больших объёмов данных она влечёт гораздо меньше накладных расходов. Так как
COPY — это одна команда, применяя её, нет необходимости отключать автофиксацию транзакций.
В случаях, когда COPY не подходит, может быть полезно создать подготовленный оператор INSERT с
помощью PREPARE, а затем выполнять EXECUTE столько раз, сколько потребуется. Это позволит из-
бежать накладных расходов, связанных с разбором и анализом каждой команды INSERT. В разных
интерфейсах это может выглядеть по-разному; за подробностями обратитесь к описанию «подго-
товленных операторов» в документации конкретного интерфейса.
Заметьте, что с помощью COPY большое количество строк практически всегда загружается быст-
рее, чем с помощью INSERT, даже если используется PREPARE и серия операций добавления заклю-
чена в одну транзакцию.
COPY работает быстрее всего, если она выполняется в одной транзакции с командами CREATE TABLE
или TRUNCATE. В таких случаях записывать WAL не нужно, так как в случае ошибки файлы, содер-
жащие загружаемые данные, будут всё равно удалены. Однако это замечание справедливо, только
когда параметр wal_level равен minimal, так как в противном случае все команды должны записы-
вать свои изменения в WAL.
14.4.3. Удалите индексы
Если вы загружаете данные в только что созданную таблицу, быстрее всего будет загрузить данные
с помощью COPY, а затем создать все необходимые для неё индексы. На создание индекса для
уже существующих данных уйдёт меньше времени, чем на последовательное его обновление при
добавлении каждой строки.
Если вы добавляете данные в существующую таблицу, может иметь смысл удалить индексы, за-
грузить таблицу, а затем пересоздать индексы. Конечно, при этом надо учитывать, что времен-
ное отсутствие индексов может отрицательно повлиять на скорость работы других пользователей.
Кроме того, следует дважды подумать, прежде чем удалять уникальные индексы, так как без них
соответствующие проверки ключей не будут выполняться.
14.4.4. Удалите ограничения внешних ключей
Как и с индексами, проверки, связанные с ограничениями внешних ключей, выгоднее выполнять
«массово», а не для каждой строки в отдельности. Поэтому может быть полезно удалить ограни-
чения внешних ключей, загрузить данные, а затем восстановить прежние ограничения. И в этом
случае тоже приходится выбирать между скоростью загрузки данных и риском допустить ошибки
в отсутствие ограничений.
Более того, когда вы загружаете данные в таблицу с существующими ограничениями внешнего
ключа, для каждой новой строки добавляется запись в очередь событий триггера (так как именно
срабатывающий триггер проверяет такие ограничения для строки). При загрузке многих миллио-
нов строк очередь событий триггера может занять всю доступную память, что приведёт к недопу-
стимой нагрузке на файл подкачки или даже к сбою команды. Таким образом, загружая большие
объёмы данных, может быть не просто желательно, а необходимо удалять, а затем восстанавливать
439Оптимизация производительности
внешние ключи. Если же временное отключение этого ограничения неприемлемо, единственно
возможным решением может быть разделение всей операции загрузки на меньшие транзакции.
14.4.5. Увеличьте maintenance_work_mem
Ускорить загрузку больших объёмов данных можно, увеличив параметр конфигурации
maintenance_work_mem на время загрузки. Это приведёт к увеличению быстродействия CREATE
INDEX и ALTER TABLE ADD FOREIGN KEY. На скорость самой команды COPY это не повлияет, так что
этот совет будет полезен, только если вы применяете какой-либо из двух вышеописанных приёмов.
14.4.6. Увеличьте max_wal_size
Также массовую загрузку данных можно ускорить, изменив на время загрузки параметр конфигу-
рации max_wal_size. Загружая большие объёмы данных, PostgreSQL вынужден увеличивать частоту
контрольных точек по сравнению с обычной (которая задаётся параметром checkpoint_timeout), а
значит и чаще сбрасывать «грязные» страницы на диск. Временно увеличив max_wal_size, можно
уменьшить частоту контрольных точек и связанных с ними операций ввода-вывода.
14.4.7. Отключите архивацию WAL и потоковую репликацию
Для загрузки больших объёмов данных в среде, где используется архивация WAL или потоковая
репликация, быстрее будет сделать копию базы данных после загрузки данных, чем обрабатывать
множество операций изменений в WAL. Чтобы отключить передачу изменений через WAL в про-
цессе загрузки, отключите архивацию и потоковую репликацию, назначьте параметру wal_level
значение minimal, archive_mode — off, а max_wal_senders — 0. Но имейте в виду, что изменённые
параметры вступят в силу только после перезапуска сервера.
Это не только поможет сэкономить время архивации и передачи WAL, но и непосредственно уско-
рит некоторые команды, которые могут вовсе не использовать WAL, если wal_level равен minimal.
(Они могут гарантировать безопасность при сбое, не записывая все изменения в WAL, а выполнив
только fsync в конце операции, что будет гораздо дешевле.) Это относится к следующим командам:
• CREATE TABLE AS SELECT
• CREATE INDEX (и подобные команды, как например ALTER TABLE ADD PRIMARY KEY)
• ALTER TABLE SET TABLESPACE
• CLUSTER
• COPY FROM, когда целевая таблица была создана или опустошена ранее в той же транзакции
14.4.8. Выполните в конце ANALYZE
Всякий раз, когда распределение данных в таблице значительно меняется, настоятельно рекомен-
дуется выполнять ANALYZE. Эта рекомендация касается и загрузки в таблицу большого объёма
данных. Выполнив ANALYZE (или VACUUM ANALYZE), вы тем самым обновите статистику по данной
таблице для планировщика. Когда планировщик не имеет статистики или она не соответствует
действительности, он не сможет правильно планировать запросы, что приведёт к снижению быст-
родействия при работе с соответствующими таблицами. Заметьте, что если включён демон авто-
очистки, он может запускать ANALYZE автоматически; подробнее об этом можно узнать в Подраз-
деле 24.1.3 и Подразделе 24.1.6.
14.4.9. Несколько замечаний относительно pg_dump
В скриптах загрузки данных, которые генерирует pg_dump, автоматически учитываются некото-
рые, но не все из этих рекомендаций. Чтобы загрузить данные, которые выгрузил pg_dump, мак-
симально быстро, вам нужно будет выполнить некоторые дополнительные действия вручную. (За-
метьте, что эти замечания относятся только к восстановлению данных, но не к выгрузке их. Следу-
ющие рекомендации применимы вне зависимости от того, загружается ли архивный файл pg_dump
в psql или в pg_restore.)
440Оптимизация производительности
По умолчанию pg_dump использует команду COPY и когда она выгружает полностью схему и дан-
ные, в сгенерированном скрипте она сначала предусмотрительно загружает данные, а потом со-
здаёт индексы и внешние ключи. Так что в этом случае часть рекомендаций выполняется автома-
тически. Вам остаётся учесть только следующие:
• Установите подходящие (то есть превышающие обычные) значения для maintenance_work_mem
и max_wal_size.
• Если вы используете архивацию WAL или потоковую репликацию, по возможности отклю-
чите их на время восстановления. Для этого перед загрузкой данных, присвойте параметру
archive_mode значение off, wal_level — minimal, а max_wal_senders — 0. Закончив восстанов-
ление, верните их обычные значения и сделайте свежую базовую резервную копию.
• Поэкспериментируйте с режимами параллельного копирования и восстановления команд
pg_dump и pg_restore, и подберите оптимальное число параллельных заданий. Параллельное
копирование и восстановление данных, управляемое параметром -j, должно дать значитель-
ный выигрыш в скорости по сравнению с последовательным режимом.
• Если это возможно в вашей ситуации, восстановите все данные в рамках одной транзакции.
Для этого передайте параметр -1 или –single-transaction команде psql или pg_restore. Но
учтите, что в этом режиме даже незначительная ошибка приведёт к откату всех изменений и
часы восстановления будут потрачены зря. В зависимости от того, насколько взаимосвязаны
данные, предпочтительнее может быть вычистить их вручную. Команды COPY будут работать
максимально быстро, когда они выполняются в одной транзакции и архивация WAL выключе-
на.
• Если на сервере баз данных установлено несколько процессоров, полезным может оказаться
параметр –jobs команды pg_restore. С его помощью можно выполнить загрузку данных и со-
здание индексов параллельно.
• После загрузки данных запустите ANALYZE.
При выгрузке данных без схемы тоже используется команда COPY, но индексы, как обычно и
1
внешние ключи, при этом не удаляются и не пересоздаются. Поэтому, загружая только дан-
ные, вы сами должны решить, нужно ли для ускорения загрузки удалять и пересоздавать индек-
сы и внешние ключи. При этом будет так же полезно увеличить параметр max_wal_size, но не
maintenance_work_mem; его стоит менять, только если вы впоследствии пересоздаёте индексы и
внешние ключи вручную. И не забудьте выполнить ANALYZE после; подробнее об этом можно узнать
в Подразделе 24.1.3 и Подразделе 24.1.6.
14.5. Оптимизация, угрожающая стабильности
Стабильность — это свойство базы данных, гарантирующее, что результат зафиксированных тран-
закций будет сохранён даже в случае сбоя сервера или отключения питания. Однако обеспечива-
ется стабильность за счёт значительной дополнительной нагрузки. Поэтому, если вы можете отка-
заться от такой гарантии, PostgreSQL можно ускорить ещё больше, применив следующие методы
оптимизации. Кроме явно описанных исключений, даже с такими изменениями конфигурации при
сбое программного ядра СУБД гарантия стабильности сохраняется; риск потери или разрушения
данных возможен только в случае внезапной остановки операционной системы.
• Поместите каталог данных кластера БД в файловую систему, размещённую в памяти (т. е. в
RAM-диск). Так вы исключите всю активность ввода/вывода, связанную с базой данных, если
только размер базы данных не превышает объём свободной памяти (возможно, с учётом фай-
ла подкачки).
• Выключите fsync; сбрасывать данные на диск не нужно.
• Выключите synchronous_commit; нет необходимости принудительно записывать WAL на диск
при фиксации каждой транзакции. Но учтите, это может привести к потере транзакций (хотя
данные останутся согласованными) в случае сбоя базы данных.
1
Вы можете отключить внешние ключи, используя параметр –disable-triggers — но при этом нужно понимать, что тем самым вы не просто отложите, а
полностью выключите соответствующие проверки, что позволит вставить недопустимые данные.
441Оптимизация производительности
• Выключите full_page_writes; защита от частичной записи страниц не нужна.
• Увеличьте max_wal_size и checkpoint_timeout; это уменьшит частоту контрольных точек, хотя
объём /pg_wal при этом вырастет.
• Создавайте нежурналируемые таблицы для оптимизации записи в WAL (но учтите, что такие
таблицы не защищены от сбоя).</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-013/" title="Глава 13. Управление конкурентным доступом"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 13. Управление конкурентным доступом"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-013/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~34 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-013/" rel="bookmark" title="Глава 13. Управление конкурентным доступом" itemprop="url">Глава 13. Управление конкурентным доступом</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 13. Управление конкурентным доступом</p>

<p>В этой главе описывается поведение СУБД PostgreSQL в ситуациях, когда два или более сеансов
пытаются одновременно обратиться к одним и тем же данным. В таких ситуациях важно, чтобы
все сеансы могли эффективно работать с данными, и при этом сохранялась целостность данных.
Обсуждаемые в этой главе темы заслуживают внимания всех разработчиков баз данных.
13.1. Введение
PostgreSQL предоставляет разработчикам богатый набор средств для управления конкурент-
ным доступом к данным. Внутри он поддерживает целостность данных, реализуя модель MVCC
(Multiversion Concurrency Control, Многоверсионное управление конкурентным доступом). Это
означает, что каждый SQL-оператор видит снимок данных (версию базы данных) на определённый
момент времени, вне зависимости от текущего состояния данных. Это защищает операторы от
несогласованности данных, возможной, если другие конкурирующие транзакции внесут измене-
ния в те же строки данных, и обеспечивает тем самым изоляцию транзакций для каждого сеан-
са баз данных. MVCC, отходя от методик блокирования, принятых в традиционных СУБД, снижа-
ет уровень конфликтов блокировок и таким образом обеспечивает более высокую производитель-
ность в многопользовательской среде.
Основное преимущество использования модели MVCC по сравнению с блокированием заключа-
ется в том, что блокировки MVCC, полученные для чтения данных, не конфликтуют с блокиров-
ками, полученными для записи, и поэтому чтение никогда не мешает записи, а запись чтению.
PostgreSQL гарантирует это даже для самого строгого уровня изоляции транзакций, используя ин-
новационный уровень изоляции SSI (Serializable Snapshot Isolation, Сериализуемая изоляция сним-
ков).
Для приложений, которым в принципе не нужна полная изоляция транзакций и которые предпо-
читают явно определять точки конфликтов, в PostgreSQL также есть средства блокировки на уров-
не таблиц и строк. Однако при правильном использовании MVCC обычно обеспечивает лучшую
производительность, чем блокировки. Кроме этого, приложения могут использовать рекоменда-
тельные блокировки, не привязанные к какой-либо одной транзакции.
13.2. Изоляция транзакций
Стандарт SQL определяет четыре уровня изоляции транзакций. Наиболее строгий из них — сериа-
лизуемый, определяется одним абзацем, говорящем, что при параллельном выполнении несколь-
ко сериализуемых транзакций должны гарантированно выдавать такой же результат, как если бы
они запускались по очереди в некотором порядке. Остальные три уровня определяются через опи-
сания особых явлений, которые возможны при взаимодействии параллельных транзакций, но не
допускаются на определённом уровне. Как отмечается в стандарте, из определения сериализуе-
мого уровня вытекает, что на этом уровне ни одно из этих явлений не возможно. (В самом деле
— если эффект транзакций должен быть тем же, что и при их выполнении по очереди, как можно
было бы увидеть особые явления, связанные с другими транзакциями?)
Стандарт описывает следующие особые условия, недопустимые для различных уровней изоляции:
«грязное» чтение
Транзакция читает данные, записанные параллельной незавершённой транзакцией.
неповторяемое чтение
Транзакция повторно читает те же данные, что и раньше, и обнаруживает, что они были изме-
нены другой транзакцией (которая завершилась после первого чтения).
407Управление конку-
рентным доступом
фантомное чтение
Транзакция повторно выполняет запрос, возвращающий набор строк для некоторого условия,
и обнаруживает, что набор строк, удовлетворяющих условию, изменился из-за транзакции, за-
вершившейся за это время.
аномалия сериализации
Результат успешной фиксации группы транзакций оказывается несогласованным при всевоз-
можных вариантах исполнения этих транзакций по очереди.
Уровни изоляции транзакций, описанные в стандарте SQL и реализованные в PostgreSQL, описы-
ваются в Таблице 13.1.
Таблица 13.1. Уровни изоляции транзакций
Уровень
ции
изоля- «Грязное»
ние
Read uncommited Допускается,
(Чтение незафик- не в PG
сированных дан-
ных)
чте- Неповторяемое
чтение
Фантомное
ние
чте- Аномалия сериа-
лизации
но Возможно Возможно Возможно
Read committed ( Невозможно
Чтение зафикси-
рованных данных) Возможно Возможно Возможно
Repeatable read ( Невозможно
Повторяемое чте-
ние) Невозможно Допускается,
не в PG Serializable (Сери- Невозможно
ализуемость) Невозможно Невозможно
но Возможно
Невозможно
В PostgreSQL вы можете запросить любой из четырёх уровней изоляции транзакций, однако внут-
ри реализованы только три различных уровня, то есть режим Read Uncommitted в PostgreSQL дей-
ствует как Read Committed. Причина этого в том, что только так можно сопоставить стандартные
уровни изоляции с реализованной в PostgreSQL архитектурой многоверсионного управления кон-
курентным доступом.
В этой таблице также показано, что реализация Repeatable Read в PostgreSQL не допускает фан-
томное чтение. Стандарт SQL допускает возможность более строгого поведения: четыре уровня
изоляции определяют только, какие особые условия не должны наблюдаться, но не какие обяза-
тельно должны. Поведение имеющихся уровней изоляции подробно описывается в следующих
подразделах.
Для выбора нужного уровня изоляции транзакций используется команда SET TRANSACTION.
Важно
Поведение некоторых функций и типов данных PostgreSQL в транзакциях подчиняет-
ся особым правилам. В частности, изменения последовательностей (и следовательно,
счётчика в столбце, объявленному как serial) немедленно видны во всех остальных
транзакциях и не откатываются назад, если выполнившая их транзакция прерывается.
См. Раздел 9.16 и Подраздел 8.1.4.
13.2.1. Уровень изоляции Read Committed
Read Committed — уровень изоляции транзакции, выбираемый в PostgreSQL по умолчанию. В тран-
закции, работающей на этом уровне, запрос SELECT (без предложения FOR UPDATE/SHARE) видит
только те данные, которые были зафиксированы до начала запроса; он никогда не увидит неза-
фиксированных данных или изменений, внесённых в процессе выполнения запроса параллельны-
408Управление конку-
рентным доступом
ми транзакциями. По сути запрос SELECT видит снимок базы данных в момент начала выполнения
запроса. Однако SELECT видит результаты изменений, внесённых ранее в этой же транзакции, да-
же если они ещё не зафиксированы. Также заметьте, что два последовательных оператора SELECT
могут видеть разные данные даже в рамках одной транзакции, если какие-то другие транзакции
зафиксируют изменения после запуска первого SELECT, но до запуска второго.
Команды UPDATE, DELETE, SELECT FOR UPDATE и SELECT FOR SHARE ведут себя подобно SELECT при
поиске целевых строк: они найдут только те целевые строки, которые были зафиксированы на мо-
мент начала команды. Однако к моменту, когда они будут найдены, эти целевые строки могут быть
уже изменены (а также удалены или заблокированы) другой параллельной транзакцией. В этом
случае запланированное изменение будет отложено до фиксирования или отката первой изменя-
ющей данные транзакции (если она ещё выполняется). Если первая изменяющая транзакция от-
катывается, её результат отбрасывается и вторая изменяющая транзакция может продолжить из-
менение изначально полученной строки. Если первая транзакция зафиксировалась, но в резуль-
тате удалила эту строку, вторая будет игнорировать её, а в противном случае попытается выпол-
нить свою операцию с изменённой версией строки. Условие поиска в команде (предложение WHERE)
вычисляется повторно для выяснения, соответствует ли по-прежнему этому условию изменённая
версия строки. Если да, вторая изменяющая транзакция продолжают свою работу с изменённой
версией строки. Применительно к командам SELECT FOR UPDATE и SELECT FOR SHARE это означает,
что изменённая версия строки блокируется и возвращается клиенту.
Похожим образом ведёт себя INSERT с предложением ON CONFLICT DO UPDATE. В режиме Read
Committed каждая строка, предлагаемая для добавления, будет либо вставлена, либо изменена. Ес-
ли не возникнет несвязанных ошибок, гарантируется один из этих двух исходов. Если конфликт бу-
дет вызван другой транзакцией, результат которой ещё не видим для INSERT, предложение UPDATE
подействует на эту строку, даже несмотря на то, что эта команда обычным образом может не ви-
деть никакую версию этой строки.
При выполнении INSERT с предложением ON CONFLICT DO NOTHING строка может не добавиться в
результате действия другой транзакции, эффект которой не виден в снимке команды INSERT. Это
опять же имеет место только в режиме Read Committed.
Вследствие описанных выше правил, изменяющая команда может увидеть несогласованное состо-
яние: она может видеть результаты параллельных команд, изменяющих те же строки, что пытает-
ся изменить она, но при этом она не видит результаты этих команд в других строках таблиц. Из-за
этого поведения уровень Read Committed не подходит для команд со сложными условиями поиска;
однако он вполне пригоден для простых случаев. Например, рассмотрим изменение баланса счёта
в таких транзакциях:
BEGIN;
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 12345;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 7534;
COMMIT;
Если две такие транзакции пытаются параллельно изменить баланс счёта 12345, мы, естественно,
хотим, чтобы вторая транзакция работала с изменённой версией строки счёта. Так как каждая
команда влияет только на определённую строку, если она будет видеть изменённую версию строки,
это не приведёт к проблемам несогласованности.
В более сложных ситуациях уровень Read Committed может приводить к нежелательным резуль-
татам. Например, рассмотрим команду DELETE, работающую со строками, которые параллельно
добавляет и удаляет из множества, определённого её условием, другая команда. Например, пред-
положим, что website — таблица из двух строк, в которых website.hits равны 9 и 10:
BEGIN;
UPDATE website SET hits = hits + 1;
– выполняется параллельно: DELETE FROM website WHERE hits = 10;
COMMIT;
Команда DELETE не сделает ничего, даже несмотря на то, что строка с website.hits = 10 была в
таблице и до, и после выполнения UPDATE. Это происходит потому, что строка со значением 9 до
409Управление конку-
рентным доступом
изменения пропускается, а когда команда UPDATE завершается и DELETE получает освободившуюся
блокировку, строка с 10 теперь содержит 11, а это значение уже не соответствует условию.
Так как в режиме Read Committed каждая команда начинается с нового снимка состояния, кото-
рый включает результаты всех транзакций, зафиксированных к этому моменту, последующие ко-
манды в одной транзакции будут в любом случае видеть эффекты всех параллельных зафиксиро-
ванных транзакций. Вопрос здесь состоит в том, видит ли одна команда абсолютно согласованное
состояние базы данных.
Частичная изоляция транзакция, обеспечиваемая в режиме Read Committed, приемлема для мно-
жества приложений. Этот режим быстр и прост в использовании, однако он подходит не для всех
случаев. Приложениям, выполняющим сложные запросы и изменения, могут потребоваться более
строго согласованное представление данных, чем то, что даёт Read Committed.
13.2.2. Уровень изоляции Repeatable Read
В режиме Repeatable Read видны только те данные, которые были зафиксированы до начала тран-
закции, но не видны незафиксированные данные и изменения, произведённые другими транзак-
циями в процессе выполнения данной транзакции. (Однако запрос будет видеть эффекты предыду-
щих изменений в своей транзакции, несмотря на то, что они не зафиксированы.) Это самое стро-
гое требование, которое стандарт SQL вводит для этого уровня изоляции, и при его выполнении
предотвращаются все явления, описанные в Таблице 13.1, за исключением аномалий сериализа-
ции. Как было сказано выше, это не противоречит стандарту, так как он определяет только мини-
мальную защиту, которая должна обеспечиваться на каждом уровне изоляции.
Этот уровень отличается от Read Committed тем, что запрос в транзакции данного уровня видит
снимок данных на момент начала первого оператора в транзакции (не считая команд управле-
ния транзакциями), а не начала текущего оператора. Таким образом, последовательные команды
SELECT в одной транзакции видят одни и те же данные; они не видят изменений, внесённых и за-
фиксированных другими транзакциями после начала их текущей транзакции.
Приложения, использующие этот уровень, должны быть готовы повторить транзакции в случае
сбоев сериализации.
Команды UPDATE, DELETE, SELECT FOR UPDATE и SELECT FOR SHARE ведут себя подобно SELECT при
поиске целевых строк: они найдут только те целевые строки, которые были зафиксированы на мо-
мент начала транзакции. Однако к моменту, когда они будут найдены, эти целевые строки могут
быть уже изменены (а также удалены или заблокированы) другой параллельной транзакцией. В
этом случае транзакция в режиме Repeatable Read будет ожидать фиксирования или отката первой
изменяющей данные транзакции (если она ещё выполняется). Если первая изменяющая транзак-
ция откатывается, её результат отбрасывается и текущая транзакция может продолжить измене-
ние изначально полученной строки. Если же первая транзакция зафиксировалась и в результате
изменила или удалила эту строку, а не просто заблокировала её, произойдёт откат текущей тран-
закции с сообщением
ОШИБКА: не удалось сериализовать доступ из-за параллельного изменения
так как транзакция уровня Repeatable Read не может изменять или блокировать строки, изменён-
ные другими транзакциями с момента её начала.
Когда приложение получает это сообщение об ошибке, оно должна прервать текущую транзакцию
и попытаться повторить её с самого начала. Во второй раз транзакция увидит внесённое до этого
изменение как часть начального снимка базы данных, так что новая версия строки вполне может
использоваться в качестве отправной точки для изменения в повторной транзакции.
Заметьте, что потребность в повторении транзакции может возникнуть, только если эта транзак-
ция изменяет данные; в транзакциях, которые только читают данные, конфликтов сериализации
не бывает.
Режим Repeatable Read строго гарантирует, что каждая транзакция видит полностью стабильное
представление базы данных. Однако это представление не обязательно будет согласовано с неко-
410Управление конку-
рентным доступом
торым последовательным выполнением транзакций одного уровня. Например, даже транзакция,
которая только читает данные, в этом режиме может видеть строку, показывающую, что некото-
рое задание завершено, но не видеть одну из строк логических частей задания, так как эта тран-
закция может прочитать более раннюю версию строки задания, чем ту, для которой параллельно
добавлялась очередная логическая часть. Строго исполнить бизнес-правила в транзакциях, рабо-
тающих на этом уровне изоляции, скорее всего не удастся без явных блокировок конфликтующих
транзакций.
Примечание
До версии 9.1 в PostgreSQL при запросе режима Serializable поведение системы в точ-
ности соответствовало вышеописанному. Таким образом, чтобы сейчас получить ста-
рое поведение Serializable, нужно запрашивать режим Repeatable Read.
13.2.3. Уровень изоляции Serializable
Уровень Serializable обеспечивает самую строгую изоляцию транзакций. На этом уровне модели-
руется последовательное выполнение всех зафиксированных транзакций, как если бы транзак-
ции выполнялись одна за другой, последовательно, а не параллельно. Однако, как и на уровне
Repeatable Read, на этом уровне приложения должны быть готовы повторять транзакции из-за сбо-
ев сериализации. Фактически этот режим изоляции работает так же, как и Repeatable Read, только
он дополнительно отслеживает условия, при которых результат параллельно выполняемых сери-
ализуемых транзакций может не согласовываться с результатом этих же транзакций, выполняе-
мых по очереди. Это отслеживание не привносит дополнительных препятствий для выполнения,
кроме тех, что присущи режиму Repeatable Read, но тем не менее создаёт некоторую добавочную
нагрузку, а при выявлении исключительных условий регистрируется аномалия сериализации и
происходит сбой сериализации.
Например, рассмотрим таблицу mytab, изначально содержащую:
class | value
——-+——-
1 |
10
1 |
20
2 |
100
2 |
200
Предположим, что сериализуемая транзакция A вычисляет:
SELECT SUM(value) FROM mytab WHERE class = 1;
а затем вставляет результат (30) в поле value в новую строку со значением class = 2. В это же
время сериализуемая транзакция B вычисляет:
SELECT SUM(value) FROM mytab WHERE class = 2;
получает результат 300 и вставляет его в новую строку со значением class = 1. Затем обе транзак-
ции пытаются зафиксироваться. Если бы одна из этих транзакций работала в режиме Repeatable
Read, зафиксироваться могли бы обе; но так как полученный результат не соответствовал бы по-
следовательному порядку, в режиме Serializable будет зафиксирована только одна транзакция, а
вторая закончится откатом с сообщением:
ОШИБКА: не удалось сериализовать доступ из-за зависимостей чтения/записи между
транзакциями
Это объясняется тем, что при выполнении A перед B транзакция B вычислила бы сумму 330, а не
300, а при выполнении в обратном порядке A вычислила бы другую сумму.
Рассчитывая, что сериализуемые транзакции предотвратят аномалии, важно понимать, что любые
данные, полученные из постоянной таблицы пользователя, не должны считаться действительны-
ми, пока транзакция, прочитавшая их, не будет успешно зафиксирована. Это верно даже для тран-
закций, не модифицирующих данные, за исключением случая, когда данные считываются в от-
411Управление конку-
рентным доступом
кладываемой транзакции такого типа. В этом случае данные могут считаться действительными,
так как такая транзакция ждёт, пока не сможет получить снимок, гарантированно предотвраща-
ющий подобные проблемы. Во всех остальных случаях приложения не должны полагаться на ре-
зультаты чтения данных в транзакции, которая не была зафиксирована; в случае ошибки и отката
приложения должны повторять транзакцию, пока она не будет завершена успешно.
Для полной гарантии сериализуемости в PostgreSQL применяются предикатные блокировки, то
есть блокировки, позволяющие определить, когда запись могла бы повлиять на результат преды-
дущего чтения параллельной транзакции, если бы эта запись выполнялась сначала. В PostgreSQL
эти блокировки не приводят к фактическим блокировкам данным и следовательно никоим обра-
зом не могут повлечь взаимоблокировки транзакций. Они помогают выявить и отметить зависимо-
сти между параллельными транзакциями уровня Serializable, которые в определённых сочетани-
ях могут приводить к аномалиям сериализации. Транзакции Read Committed или Repeatable Read
для обеспечения целостности данных, напротив, должны либо блокировать таблицы целиком, что
помешает пользователям обращаться к этим таблицам, либо применять SELECT FOR UPDATE или
SELECT FOR SHARE, что не только заблокирует другие транзакции, но и создаст дополнительную
нагрузку на диск.
Предикатные блокировки в PostgreSQL, как и в большинстве других СУБД, устанавливаются для
данных, фактически используемых в транзакции. Они отображаются в системном представлении
pg_locks со значением mode равным SIReadLock. Какие именно блокировки будут затребованы при
выполнении запроса, зависит от плана запроса, при этом детализированные блокировки (напри-
мер, блокировки строк) могут объединяться в более общие (например, в блокировки страниц) в
процессе транзакции для экономии памяти, расходуемой для отслеживания блокировок. Транзак-
ция READ ONLY может даже освободить свои блокировки SIRead до завершения, если обнаружива-
ется, что конфликты, которые могли бы привести к аномалии сериализации, исключены. На самом
деле для транзакций READ ONLY этот факт чаще всего устанавливается в самом начале, так что
они обходятся без предикатных блокировок. Если же вы явно запросите транзакцию SERIALIZABLE
READ ONLY DEFERRABLE, она будет заблокирована до тех пор, пока не сможет установить этот
факт. (Это единственный случай, когда транзакции уровня Serializable блокируются, а транзакции
Repeatable Read — нет.) С другой стороны, блокировки SIRead часто должны сохраняться и после
фиксирования транзакции, пока не будут завершены другие, наложившиеся на неё транзакции.
При правильном использовании сериализуемые транзакции могут значительно упростить разра-
ботку приложений. Гарантия того, что любое сочетание успешно зафиксированных параллельных
сериализуемых транзакций даст тот же результат, что и последовательность этих транзакций, вы-
полненных по очереди, означает, что если вы уверены, что единственная транзакция определён-
ного содержания работает правильно, когда она запускается отдельно, вы можете быть уверены,
что она будет работать так же правильно в любом сочетании сериализуемых транзакций, вне за-
висимости от того, что они делают, либо же она не будет зафиксирована успешно. При этом важно,
чтобы в среде, где применяется этот подход, была реализована общая обработка сбоев сериализа-
ции (которые можно определить по значению SQLSTATE ‘40001’), так как заведомо определить,
какие именно транзакции могут стать жертвами зависимостей чтения/записи и не будут зафик-
сированы для предотвращения аномалий сериализации, обычно очень сложно. Отслеживание за-
висимостей чтения-записи неизбежно создаёт дополнительную нагрузку, как и перезапуск тран-
закций, не зафиксированных из-за сбоев сериализации, но если на другую чашу весов положить
нагрузку и блокирование, связанные с применением явных блокировок и SELECT FOR UPDATE или
SELECT FOR SHARE, использовать сериализуемые транзакции в ряде случаев окажется выгоднее.
Тогда как уровень изоляции транзакций Serializable в PostgreSQL позволяет фиксировать парал-
лельные транзакции, только если есть уверенность, что тот же результат будет получен при по-
следовательном их выполнении, он не всегда предотвращает ошибки, которые не возникли бы при
действительно последовательном выполнении. В частности, можно столкнуться с нарушениями
ограничений уникальности, вызванными наложением сериализуемых транзакций, даже после яв-
ной проверки отсутствия ключа перед добавлением его. Этого можно избежать, если все сериа-
лизуемые транзакции, добавляющие потенциально конфликтующие ключи, будут предварительно
явно проверять, можно ли вставить ключ. Например, приложение, добавляющее новый ключ, мо-
жет запрашивать его у пользователя и затем проверять, существует ли он, сначала пытаясь найти
его, либо генерировать новый ключ, выбирая максимальное существующее значение и увеличивая
412Управление конку-
рентным доступом
его на один. Если некоторые сериализуемые транзакции добавляют новые ключи сразу, не следуя
этому протоколу, возможны нарушения ограничений уникальности, даже когда они не наблюда-
лись бы при последовательном выполнении этих транзакций.
Применяя сериализуемые транзакции для управления конкурентным доступом, примите к сведе-
нию следующие рекомендации:
• Объявляйте транзакции как READ ONLY, если это отражает их суть.
• Управляйте числом активных подключений, при необходимости используя пул соединений.
Это всегда полезно для увеличения производительности, но особенно важно это в загружен-
ной системе с сериализуемыми транзакциями.
• Заключайте в одну транзакцию не больше команд, чем необходимо для обеспечения целост-
ности.
• Не оставляйте соединения «простаивающими в транзакции» дольше, чем необходимо. Для ав-
томатического отключения затянувшихся транзакций можно применить параметр конфигура-
ции idle_in_transaction_session_timeout.
• Исключите явные блокировки, SELECT FOR UPDATE и SELECT FOR SHARE там, где они не нужны
благодаря защите, автоматически предоставляемой сериализуемыми транзакциями.
• Когда система вынуждена объединять предикатные блокировки уровня страницы в одну пре-
дикатную блокировку уровня таблицы из-за нехватки памяти, может возрасти частота сбо-
ев сериализации. Избежать этого можно, увеличив параметр max_pred_locks_per_transaction,
max_pred_locks_per_relation и/или max_pred_locks_per_page.
• Последовательное сканирование всегда влечёт за собой предикатную блокировку на уровне
таблицы. Это приводит к увеличению сбоев сериализации. В таких ситуациях бывает полезно
склонить систему к использованию индексов, уменьшая random_page_cost и/или увеличивая
cpu_tuple_cost. Однако тут важно сопоставить выигрыш от уменьшения числа откатов и пере-
запусков транзакций с проигрышем от возможного менее эффективного выполнения запро-
сов.
13.3. Явные блокировки
Для управления параллельным доступом к данным в таблицах PostgreSQL предоставляет несколь-
ко режимов явных блокировок. Эти режимы могут применяться для блокировки данных со стороны
приложения в ситуациях, когда MVCC не даёт желаемый результат. Кроме того, большинство ко-
манд PostgreSQL автоматически получают блокировки соответствующих режимов, защищающие
от удаления или изменения задействованных таблиц, несовместимого с характером выполняемой
команды. (Например, TRUNCATE не может безопасно выполняться одновременно с другими опера-
циями с этой таблицей, так что во избежание конфликта эта команда получает исключительную
блокировку для данной таблицы.)
Список текущих активных блокировок на сервере можно получить, прочитав системное представ-
ление pg_locks. За дополнительными сведениями о наблюдении за состоянием менеджера блоки-
ровок обратитесь к Главе 28.
13.3.1. Блокировки на уровне таблицы
В приведённом ниже списке перечислены имеющиеся режимы блокировок и контексты, где их ав-
томатически применяет PostgreSQL. Вы можете также явно запросить любую из этих блокировок
с помощью команды LOCK. Помните, что все эти режимы работают на уровне таблицы, даже если
имя режима содержит слово «row»; такие имена сложились исторически. В некоторой степени эти
имена отражают типичное применение каждого режима блокировки, но смысл у всех один. Един-
ственное, что действительно отличает один режим блокировки от другого, это набор режимов, с
которыми конфликтует каждый из них (см. Таблицу 13.2). Две транзакции не могут одновременно
владеть блокировками конфликтующих режимов для одной и той же таблицы. (Однако учтите, что
транзакция никогда не конфликтует с собой. Например, она может запросить блокировку ACCESS
EXCLUSIVE, а затем ACCESS SHARE для той же таблицы.) При этом разные транзакции свободно могут
одновременно владеть блокировками неконфликтующих режимов. Заметьте, что некоторые режи-
413Управление конку-
рентным доступом
мы блокировки конфликтуют сами с собой (например, блокировкой ACCESS EXCLUSIVE в один мо-
мент времени может владеть только одна транзакция), а некоторые — нет (например, блокировку
ACCESS SHARE могут получить сразу несколько транзакций).
Режимы блокировок на уровне таблицы
ACCESS SHARE
Конфликтует только с режимом блокировки ACCESS EXCLUSIVE.
Команда SELECT получает такую блокировку для таблиц, на которые она ссылается. Вообще
говоря, блокировку в этом режиме получает любой запрос, который только читает таблицу,
но не меняет её данные.
ROW SHARE
Конфликтует с режимами блокировки EXCLUSIVE и ACCESS EXCLUSIVE.
Команды SELECT FOR UPDATE и SELECT FOR SHARE получают такую блокировку для своих целе-
вых таблиц (помимо блокировок ACCESS SHARE для любых таблиц, которые используется в этих
запросов, но не в предложении FOR UPDATE/FOR SHARE).
ROW EXCLUSIVE
Конфликтует с режимами блокировки SHARE, SHARE
EXCLUSIVE.
ROW
EXCLUSIVE, EXCLUSIVE и ACCESS
Команды UPDATE, DELETE и INSERT получают такую блокировку для целевой таблицы (в допол-
нение к блокировкам ACCESS SHARE для всех других задействованных таблиц). Вообще говоря,
блокировку в этом режиме получает любая команда, которая изменяет данные в таблице.
SHARE UPDATE EXCLUSIVE
Конфликтует с режимами блокировки SHARE UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE,
EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельного изменения
схемы и запуска процесса VACUUM.
Запрашивается командами VACUUM (без FULL), ANALYZE, CREATE INDEX CONCURRENTLY, CREATE
STATISTICS, ALTER TABLE VALIDATE и другими видами ALTER TABLE (за подробностями обрати-
тесь к ALTER TABLE).
SHARE
Конфликтует с режимами блокировки ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE ROW
EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельного
изменения данных.
Запрашивается командой CREATE INDEX (без параметра CONCURRENTLY).
SHARE ROW EXCLUSIVE
Конфликтует с режимами блокировки ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE, SHARE
ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельных
изменений данных и при этом он является самоисключающим, так что такую блокировку может
получить только один сеанс.
Запрашивается командой CREATE COLLATION, CREATE TRIGGER и многими формами ALTER TABLE
(см. ALTER TABLE).
EXCLUSIVE
Конфликтует с режимами блокировки ROW SHARE, ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE,
SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим совместим только с
блокировкой ACCESS SHARE, то есть параллельно с транзакцией, получившей блокировку в этом
режиме, допускается только чтение таблицы.
414Управление конку-
рентным доступом
Запрашивается командой REFRESH MATERIALIZED VIEW CONCURRENTLY.
ACCESS EXCLUSIVE
Конфликтует со всеми режимами блокировки (ACCESS SHARE, ROW SHARE, ROW EXCLUSIVE, SHARE
UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE). Этот режим
гарантирует, что кроме транзакции, получившей эту блокировку, никакая другая транзакция
не может обращаться к таблице каким-либо способом.
Запрашивается командами DROP TABLE, TRUNCATE, REINDEX, CLUSTER, VACUUM FULL и REFRESH
MATERIALIZED VIEW (без CONCURRENTLY). Блокировку на этом уровне запрашивают также многие
виды ALTER TABLE. В этом режиме по умолчанию запрашивают блокировку и операторы LOCK
TABLE, если явно не выбран другой режим.
Подсказка
Только блокировка ACCESS EXCLUSIVE блокирует оператор SELECT (без FOR UPDATE/
SHARE).
Полученная транзакцией блокировка обычно сохраняется до конца транзакции. Но если блокиров-
ка получена после установки точки сохранения, она освобождается немедленно в случае отката
к этой точке. Это согласуется с принципом действия ROLLBACK — эта команда отменяет эффекты
всех команд после точки сохранения. То же справедливо и для блокировок, полученных в блоке
исключений PL/pgSQL: при выходе из блока с ошибкой такие блокировки освобождаются.
Таблица 13.2. Конфликтующие режимы блокировки
Запраши Текущий режим блокировки
ваемый ACCESS ROW
ROW
SHARE
SHARE
режим
SHARE
SHARE
EXCLUSIVE
UPDATE
блоки
EXCLUSIVE
ровки
SHARE
EXCLU
ROW
SIVE
EXCLUSIVE
ACCESS
EXCLUSIVE
ACCESS
SHARE               X
ROW
SHARE             X X
ROW
EXCLUSIVE         X X X X
SHARE
UPDATE
EXCLUSIVE       X X X X X
SHARE     X X   X X X
SHARE
ROW
EXCLUSIVE     X X X X X X
EXCLU
SIVE   X X X X X X X
ACCESS
EXCLUSIVE X X X X X X X X
13.3.2. Блокировки на уровне строк
В дополнение к блокировкам на уровне таблицы, существуют блокировки на уровне строк, пере-
численные ниже с контекстами, где PostgreSQL применяет их по умолчанию. Полный перечень
конфликтов блокировок на уровне строк приведён в Таблице 13.3. Заметьте, что одна транзакция
415Управление конку-
рентным доступом
может владеть несколькими конфликтующими блокировками одной строки, даже в разных под-
транзакциях; но две разных транзакции никогда не получат конфликтующие блокировки одной и
той же строки. Блокировки на уровне строк блокируют только запись в определённые строки, но
никак не влияют на выборку.
Режимы блокировки на уровне строк
FOR UPDATE
В режиме FOR UPDATE строки, выданные оператором SELECT, блокируются как для изменения.
При этом они защищаются от блокировки, изменения и удаления другими транзакциями до за-
вершения текущей. То есть другие транзакции, пытающиеся выполнить UPDATE, DELETE, SELECT
FOR UPDATE, SELECT FOR NO KEY UPDATE, SELECT FOR SHARE или SELECT FOR KEY SHARE с эти-
ми строками, будут заблокированы до завершения текущей транзакции; и наоборот, команда
SELECT FOR UPDATE будет ожидать окончания параллельной транзакции, в которой выполни-
лась одна из этих команд с той же строкой, а затем установит блокировку и вернёт изменён-
ную строку (или не вернёт, если она была удалена). Однако в транзакции REPEATABLE READ или
SERIALIZABLE возникнет ошибка, если блокируемая строка изменилась с момента начала тран-
закции. Подробнее это обсуждается в Разделе 13.4.
Режим блокировки FOR UPDATE также запрашивается на уровне строки любой командой DELETE
и командой UPDATE, изменяющей значения определённых столбцов. В настоящее время блоки-
ровка с UPDATE касается столбцов, по которым создан уникальный индекс, применимый в каче-
стве внешнего ключа (так что на частичные индексы и индексы выражений это не распростра-
няется), но в будущем это может поменяться.
FOR NO KEY UPDATE
Действует подобно FOR UPDATE, но запрашиваемая в этом режиме блокировка слабее: она не
будет блокировать команды SELECT FOR KEY SHARE, пытающиеся получить блокировку тех же
строк. Этот режим блокировки также запрашивается любой командой UPDATE, которая не тре-
бует блокировки FOR UPDATE.
FOR SHARE
Действует подобно FOR NO KEY UPDATE, за исключением того, что для каждой из полученных
строк запрашивается разделяемая, а не исключительная блокировка. Разделяемая блокировка
не позволяет другим транзакциям выполнять с этими строками UPDATE, DELETE, SELECT FOR
UPDATE или SELECT FOR NO KEY UPDATE, но допускает SELECT FOR SHARE и SELECT FOR KEY SHARE.
FOR KEY SHARE
Действует подобно FOR SHARE, но устанавливает более слабую блокировку: блокируется SELECT
FOR UPDATE, но не SELECT FOR NO KEY UPDATE. Блокировка разделяемого ключа не позволяет
другим транзакциям выполнять команды DELETE и UPDATE, только если они меняют значение
ключа (но не другие UPDATE), и при этом допускает выполнение команд SELECT FOR NO KEY
UPDATE, SELECT FOR SHARE и SELECT FOR KEY SHARE.
PostgreSQL не держит информацию об изменённых строках в памяти, так что никаких ограниче-
ний на число блокируемых строк нет. Однако блокировка строки может повлечь запись на диск,
например, если SELECT FOR UPDATE изменяет выбранные строки, чтобы заблокировать их, при этом
происходит запись на диск.
Таблица 13.3. Конфликтующие блокировки на уровне строк
Запрашиваемый Текущий режим блокировки
режим
блоки FOR KEY SHARE FOR SHARE
ровки
FOR
NO
UPDATE
KEY FOR UPDATE
FOR KEY SHARE       X
FOR SHARE     X X
416Управление конку-
рентным доступом
Запрашиваемый Текущий режим блокировки
режим
блоки FOR KEY SHARE FOR SHARE
ровки
FOR
NO
UPDATE
FOR UPDATE
KEY
FOR
NO
UPDATE
KEY FOR UPDATE
  X X X
X X X X
13.3.3. Блокировки на уровне страниц
В дополнение к блокировкам на уровне таблицы и строк, для управления доступом к страницам
таблиц в общих буферах используются блокировки на уровне страниц, исключительные и разде-
ляемые. Эти блокировки освобождаются немедленно после выборки или изменения строк. Разра-
ботчикам приложений обычно можно не задумываться о блокировках страниц, здесь они упоми-
наются только для полноты картины.
13.3.4. Взаимоблокировки
Частое применение явных блокировок может увеличить вероятность взаимоблокировок, то есть
ситуаций, когда две (или более) транзакций держат блокировки так, что взаимно блокируют друг
друга. Например, если транзакция 1 получает исключительную блокировку таблицы A, а затем пы-
тается получить исключительную блокировку таблицы B, которую до этого получила транзакция
2, в данный момент требующая исключительную блокировку таблицы A, ни одна из транзакций
не сможет продолжить работу. PostgreSQL автоматически выявляет такие ситуации и разрешает
их, прерывая одну из сцепившихся транзакций и тем самым позволяя другой (другим) продолжить
работу. (Какая именно транзакция будет прервана, обычно сложно предсказать, так что рассчи-
тывать на определённое поведение не следует.)
Заметьте, что взаимоблокировки могут вызываться и блокировками на уровне строк (таким обра-
зом, они возможны, даже если не применяются явные блокировки). Рассмотрим случай, когда две
параллельных транзакции изменяют таблицу. Первая транзакция выполняет:
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 11111;
При этом она получает блокировку строки с указанным номером счёта. Затем вторая транзакция
выполняет:
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 22222;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 11111;
Первый оператор UPDATE успешно получает блокировку указанной строки и изменяет данные в
ней. Однако второй оператор UPDATE обнаруживает, что строка, которую он пытается изменить,
уже заблокирована, так что он ждёт завершения транзакции, получившей блокировку. Таким об-
разом, вторая транзакция сможет продолжиться только после завершения первой. Теперь первая
транзакция выполняет:
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 22222;
Первая транзакция пытается получить блокировку заданной строки, но ей это не удаётся: эта бло-
кировка уже принадлежит второй транзакции. Поэтому первой транзакции остаётся только ждать
завершения второй. В результате первая транзакция блокируется второй, а вторая — первой: про-
исходит взаимоблокировка. PostgreSQL выявляет эту ситуацию и прерывает одну из транзакций.
Обычно лучший способ предотвращения взаимоблокировок — добиться, чтобы все приложения,
обращающиеся к базе данных, запрашивали блокировки нескольких объектов единообразно. В дан-
ном примере, если бы обе транзакции изменяли строки в одном порядке, взаимоблокировка бы не
произошла. Блокировки в транзакции следует упорядочивать так, чтобы первой для какого-либо
объекта запрашивалась наиболее ограничивающая из тех, которые для него потребуются. Если
заранее обеспечить такой порядок нельзя, взаимоблокировки можно обработать по факту, повто-
ряя прерванные транзакции.
Если ситуация взаимоблокировки не будет выявлена, транзакция, ожидающая блокировки на уров-
не таблицы или строки, будет ждать её освобождения неограниченное время. Это означает, что
417Управление конку-
рентным доступом
приложения не должны оставлять транзакции открытыми долгое время (например, ожидая ввода
пользователя).
13.3.5. Рекомендательные блокировки
PostgreSQL также имеет средства создания блокировок, смысл которых определяют сами прило-
жения. Такие блокировки называются рекомендательными, так как система не форсирует их ис-
пользование — правильно их использовать должно само приложение. Рекомендательные блоки-
ровки бывают полезны для реализаций стратегий блокирования, плохо вписывающихся в модель
MVCC. Например, рекомендательные блокировки часто применяются для исполнения стратегии
пессимистичной блокировки, типичной для систем управления данными «плоский файл». Хотя для
этого можно использовать и дополнительные флаги в таблицах, рекомендательные блокировки ра-
ботают быстрее, не нагружают таблицы и автоматически ликвидируется сервером в конце сеанса.
В PostgreSQL есть два варианта получить рекомендательные блокировки: на уровне сеанса и на
уровне транзакции. Рекомендательная блокировка, полученная на уровне сеанса, удерживается,
пока она не будет явно освобождена, или до конца сеанса. В отличие от стандартных рекомен-
дательные блокировки уровня сеанса нарушают логику транзакций — блокировка, полученная в
транзакции, даже если произойдёт откат этой транзакции, будет сохраняться в сеансе; аналогич-
но, освобождение блокировки остаётся в силе, даже если транзакция, в которой оно было выпол-
нено, позже прерывается. Вызывающий процесс может запросить блокировку несколько раз; при
этом каждому запросу блокировки должен соответствовать запрос освобождения, чтобы она была
действительно освобождена. Рекомендательные блокировки на уровне транзакций, напротив, во
многом похожи на обычные блокировки: они автоматически освобождаются в конце транзакций и
не требуют явного освобождения. Для кратковременного применения блокировок это поведение
часто более уместно, чем поведение рекомендательных блокировок на уровне сеанса. Запросы ре-
комендательных блокировок одного идентификатора на уровне сеанса и на уровне транзакции бу-
дут блокировать друг друга вполне предсказуемым образом. Если сеанс уже владеет данной реко-
мендуемой блокировкой, дополнительные запросы её в том же сеансе будут всегда успешны, даже
если её ожидают другие сеансы. Это утверждение справедливо вне зависимости от того, на каком
уровне (сеанса или транзакции) установлены или запрашиваются новые блокировки.
Как и остальные блокировки в PostgreSQL, все рекомендательные блокировки, связанные с любы-
ми сеансами, можно просмотреть в системном представлении pg_locks.
И рекомендательные, и обычные блокировки сохраняются в области общей памяти, размер кото-
рой определяется параметрами конфигурации max_locks_per_transaction и max_connections. Важ-
но, чтобы этой памяти было достаточно, так как в противном случае сервер не сможет выдать ника-
кую блокировку. Таким образом, число рекомендуемых блокировок, которые может выдать сервер,
ограничивается обычно десятками или сотнями тысяч в зависимости от конфигурации сервера.
В определённых случаях при использовании рекомендательных блокировок, особенно в запросах
с явными указаниями ORDER BY и LIMIT, важно учитывать, что получаемые блокировки могут за-
висеть от порядка вычисления SQL-выражений. Например:
SELECT pg_advisory_lock(id) FROM foo WHERE id = 12345; – ok
SELECT pg_advisory_lock(id) FROM foo WHERE id &gt; 12345 LIMIT 100; – опасно!
SELECT pg_advisory_lock(q.id) FROM
(
SELECT id FROM foo WHERE id &gt; 12345 LIMIT 100
) q; – ok
В этом примере второй вариант опасен, так как LIMIT не обязательно будет применяться перед
вызовом функции блокировки. В результате приложение может получить блокировки, на которые
оно не рассчитывает и которые оно не сможет освободить (до завершения сеанса). С точки зрения
приложения такие блокировки окажутся в подвешенном состоянии, хотя они и будут отображаться
в pg_locks.
Функции, предназначенные для работы с рекомендательными блокировками, описаны в Подраз-
деле 9.26.10.
418Управление конку-
рентным доступом
13.4. Проверки целостности данных на уровне прило-
жения
Используя транзакции Read Committed, очень сложно обеспечить целостность данных с точки зре-
ния бизнес-логики, так как представление данных смещается с каждым оператором и даже один
оператор может не ограничиваться своим снимком состояния в случае конфликта записи.
Хотя транзакция Repeatable Read получает стабильное представление данных в процессе выпол-
нения, с использованием снимков MVCC для проверки целостности данных всё же связаны тонкие
моменты, включая так называемые конфликты чтения/записи. Если одна транзакция записыва-
ет данные, а другая в это же время пытается их прочитать (до или после записи), она не может
увидеть результат работы первой. В таком случае создаётся впечатление, что читающая транзак-
ция выполняется первой вне зависимости от того, какая из них была начата или зафиксирована
раньше. Если этим всё и ограничивается, нет никаких проблем, но если читающая транзакция
также пишет данные, которые читает параллельная транзакция, получается, что теперь эта тран-
закция будет исполняться, как будто она запущена перед другими вышеупомянутыми. Если же
транзакция, которая должна исполняться как последняя, на самом деле зафиксирована первой, в
графе упорядоченных транзакций легко может возникнуть цикл. И когда он возникает, проверки
целостности не будут работать правильно без дополнительных мер.
Как было сказано в Подразделе  13.2.3, сериализуемые транзакции представляют собой те же
транзакции Repeatable Read, но дополненные неблокирующим механизмом отслеживания опас-
ных условий конфликтов чтения/записи. Когда выявляется условие, приводящее к циклу в порядке
транзакций, одна из этих транзакций откатывается и этот цикл таким образом разрывается.
13.4.1. Обеспечение согласованности в сериализуемых транзак-
циях
Если для всех операций чтения и записи, нуждающихся в согласованном представлении данных,
используются транзакции уровня изоляции Serializable, это обеспечивает необходимую согласо-
ванность без дополнительных усилий. Приложения из других окружений, применяющие сериали-
зуемые транзакции для обеспечения целостности, в PostgreSQL в этом смысле будут «просто ра-
ботать».
Применение этого подхода избавляет программистов приложений от лишних сложностей, если
приложение использует инфраструктуру, которая автоматически повторяет транзакции в случае
отката из-за сбоев сериализации. Возможно, serializable стоит даже установить в качестве уров-
ня изоляции по умолчанию (default_transaction_isolation). Также имеет смысл принять меры
для предотвращения использования других уровней изоляции, непреднамеренного или с целью
обойти проверки целостности, например проверять уровень изоляции в триггерах.
Рекомендации по увеличению быстродействия приведены в Подразделе 13.2.3.
Предупреждение
Защита целостности с применением сериализуемых транзакций пока ещё не поддер-
живается в режиме горячего резерва (Раздел 26.5). Поэтому там, где применяется го-
рячий резерв, следует использовать уровень Repeatable Read и явные блокировки на
главном сервере.
13.4.2. Применение явных блокировок для обеспечения согласо-
ванности
Когда возможны несериализуемые операции записи, для обеспечения целостности строк и защи-
ты от одновременных изменений, следует использовать SELECT FOR UPDATE, SELECT FOR SHARE
или соответствующий оператор LOCK TABLE. (SELECT FOR UPDATE и SELECT FOR SHARE защищают
419Управление конку-
рентным доступом
от параллельных изменений только возвращаемые строки, тогда как LOCK TABLE блокирует всю
таблицу.) Это следует учитывать, перенося в PostgreSQL приложения из других СУБД.
Мигрируя в PostgreSQL из других СУБД также следует учитывать, что команда SELECT FOR UPDATE
сама по себе не гарантирует, что параллельная транзакция не изменит или не удалит выбранную
строку. Для получения такой гарантии в PostgreSQL нужно именно изменить эту строку, даже ес-
ли никакие значения в ней менять не требуется. SELECT FOR UPDATE временно блокирует другие
транзакции, не давая им получить ту же блокировку или выполнить команды UPDATE или DELETE,
которые бы повлияли на заблокированную строку, но как только транзакция, владеющая этой бло-
кировкой, фиксируется или откатывается, заблокированная транзакция сможет выполнить кон-
фликтующую операцию, если только для данной строки действительно не был выполнен UPDATE,
пока транзакция владела блокировкой.
Реализация глобальной целостности с использованием несериализуемых транзакций MVCC тре-
бует более вдумчивого подхода. Например, банковскому приложению может потребоваться про-
верить, равняется ли сумма всех расходов в одной таблице сумме приходов в другой, при том, что
обе таблицы активно изменяются. Просто сравнивать результаты двух успешных последователь-
ных команд SELECT sum(…) в режиме Read Committed нельзя, так как вторая команда может
захватить результаты транзакций, пропущенных первой. Подсчитывая суммы в одной транзакции
Repeatable Read, можно получить точную картину только для транзакций, которые были зафикси-
рованы до начала данной, но при этом может возникнуть законный вопрос — будет ли этот резуль-
тат актуален тогда, когда он будет выдан. Если транзакция Repeatable Read сама вносит какие-то
изменения, прежде чем проверять равенство сумм, полезность этой проверки становится ещё бо-
лее сомнительной, так как при проверке будут учитываться некоторые, но не все изменения, про-
изошедшие после начала транзакции. В таких случаях предусмотрительный разработчик может
заблокировать все таблицы, задействованные в проверке, чтобы получить картину действитель-
ности, не вызывающую сомнений. Для этого применяется блокировка SHARE (или более строгая),
которая гарантирует, что в заблокированной таблице не будет незафиксированных изменений, за
исключением тех, что внесла текущая транзакция.
Также заметьте, что, применяя явные блокировки для предотвращения параллельных операций
записи, следует использовать либо режим Read Committed, либо в режиме Repeatable Read обяза-
тельно получать блокировки прежде, чем выполнять запросы. Блокировка, получаемая транзакци-
ей Repeatable Read, гарантирует, что никакая другая транзакция, изменяющая таблицу, не выпол-
няется, но если снимок состояния, полученный транзакцией, предшествует блокировке, он может
не включать на данный момент уже зафиксированные изменения. Снимок состояния в транзакции
Repeatable Read создаётся фактически на момент начала первой команды выборки или изменения
данных (SELECT, INSERT, UPDATE или DELETE), так что получить явные блокировки можно до того,
как он будет сформирован.
13.5. Ограничения
Некоторые команды DDL, в настоящее время это TRUNCATE и формы ALTER TABLE, перезаписы-
вающие таблицу, не являются безопасными с точки зрения MVCC. Это значит, что после фиксации
усечения или перезаписи таблица окажется пустой для всех параллельных транзакций, если они
работают со снимком, полученным перед фиксацией такой команды DDL. Это может проявиться
только в транзакции, которая не обращалась к таблице до момента начала команды DDL — лю-
бая транзакция, которая обращалась к ней раньше, получила бы как минимум блокировку ACCESS
SHARE, которая заблокировала бы эту команду DDL до завершения транзакции. Поэтому такие ко-
манды не приводят ни к каким видимым несоответствиям с содержимым таблицы при последова-
тельных запросах к целевой таблице, хотя возможно видимое несоответствие между содержимым
целевой таблицы и другими таблицами в базе данных.
Поддержка уровня изоляции Serializable ещё не реализована для целевых серверов горячего ре-
зерва (они описываются в Разделе 26.5). На данный момент самый строгий уровень изоляции, под-
держиваемый в режиме горячего резерва, это Repeatable Read. Хотя и тогда, когда главный сервер
выполняет запись в транзакциях Serializable, все резервные серверы в итоге достигают согласо-
ванного состояния, но транзакция Repeatable Read на резервном сервере иногда может увидеть
420Управление конку-
рентным доступом
промежуточное состояние, не соответствующее результату последовательного выполнения тран-
закций на главном сервере.
13.6. Блокировки и индексы
Хотя PostgreSQL обеспечивает неблокирующий доступ на чтение/запись к данным таблиц, для ин-
дексов в настоящий момент это поддерживается не в полной мере. PostgreSQL управляет доступом
к различным типам индексов следующим образом:
Индексы типа B-дерево, GiST и SP-GiST
Для управления чтением/записью используются кратковременные блокировки на уровне стра-
ницы, исключительные и разделяемые. Блокировки освобождаются сразу после извлечения
или добавления строки индекса. Эти типы индексов обеспечивают максимальное распаралле-
ливание операций, не допуская взаимоблокировок.
Хеш-индексы
Для управления чтением/записью используются блокировки на уровне групп хеша. Блокиров-
ки освобождаются после обработки всей группы. Такие блокировки с точки зрения распарал-
леливания лучше, чем блокировки на уровне индекса, но не исключают взаимоблокировок, так
как они сохраняются дольше, чем выполняется одна операция с индексом.
Индексы GIN
Для управления чтением/записью используются кратковременные блокировки на уровне стра-
ницы, исключительные и разделяемые. Блокировки освобождаются сразу после извлечения
или добавления строки индекса. Но заметьте, что добавление значения в поле с GIN-индексом
обычно влечёт добавление нескольких ключей индекса, так что GIN может проделывать целый
ряд операций для одного значения.
В настоящее время в многопоточной среде наиболее производительны индексы-B-деревья; и так
как они более функциональны, чем хеш-индексы, их рекомендуется использовать в такой среде
для приложений, когда нужно индексировать скалярные данные. Если же нужно индексировать
не скалярные данные, B-деревья не подходят, и вместо них следует использовать индексы GiST,
SP-GiST или GIN.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    
      
        <li><a href="http://localhost:4000/page21/" class="btn">Previous</a></li>
      
    

    
    
      <li><a href="http://localhost:4000">1</a></li>
    

    
    
      
      
      <li>…</li>
    

    
    
    

    
      
        
        
        
        <li><a href="http://localhost:4000/page20/">20</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page21/">21</a></li>
      
    
      
        <li><strong class="current-page">22</strong></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page23/">23</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page24/">24</a></li>
      
    

    
    
      <li>…</li>
    

    
      <li><a href="http://localhost:4000/page36/">36</a></li>
    

    
    
      <li><a href="http://localhost:4000/page23/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Sergey Khatsiola. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-130427752-1', 'auto');  
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>


          

</body>
</html>