<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Последние посты &#8211; Sirius Blog</title>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130427752-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130427752-1');
</script>

</head>
<meta name="description" content="Describtion ..">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/abstract-1.jpg">

<meta name="twitter:title" content="Последние посты">
<meta name="twitter:description" content="Describtion ..">
<meta name="twitter:creator" content="@2hotab2">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Последние посты">
<meta property="og:description" content="Describtion ..">
<meta property="og:url" content="http://localhost:4000/page18/">
<meta property="og:site_name" content="Sirius Blog">





<link rel="canonical" href="http://localhost:4000/page18/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Sirius Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.jpg">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.jpg">
<!-- 114x72 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x72" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.jpg">
<!-- 144x72 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x72" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.jpg">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Sergey Khatsiola photo" class="author-photo">
					<h4>Sergey Khatsiola</h4>
					<p>Кратко обо мне ...</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:2hotab2@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/2hotab2"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				<li>
					<a href="https://facebook.com/sergej.ha1"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/Sergey-sirius"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	    
	    <li><a href="http://localhost:4000/handbook/" >HandBook</a></li>
	  
	    
	    <li><a href="https://github.com/Sergey-sirius" target="_blank">Main Link</a></li>
	  
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/abstract-1.jpg" alt="Последние посты">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Sirius Blog</h1>
      <h2>Последние посты</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-028/" title="Глава 28. Мониторинг работы СУБД"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 28. Мониторинг работы СУБД"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-028/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~63 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-028/" rel="bookmark" title="Глава 28. Мониторинг работы СУБД" itemprop="url">Глава 28. Мониторинг работы СУБД</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 28. Мониторинг работы СУБД</p>

<p>Администратор базы данных часто задумывается — «чем в данный момент занята система?» В
этой главе рассказывается о том, как это выяснить.
Для мониторинга работы СУБД и анализа её производительности существуют различные инстру-
менты. Большая часть этой главы посвящена описанию работы сборщика статистики PostgreSQL,
однако не следует пренебрегать и обычными командами мониторинга Unix, такими как ps, top,
iostat, и vmstat. Кроме того, после обнаружения запроса с низкой производительностью может
потребоваться дополнительное исследование с использованием PostgreSQL команды EXPLAIN. В
Разделе 14.1 рассматриваются EXPLAIN и другие методы для изучения поведения отдельного за-
проса.
28.1. Стандартные инструменты Unix
В большинстве Unix-платформ PostgreSQL модифицирует заголовок команды, который выводится
на экран при выполнении команды ps, так что серверные процессы можно легко различить. При-
мер вывода этой команды:
$ ps auxww | grep ^postgres
postgres 15551 0.0 0.1 57536 7132 pts/0
postgres 15554 0.0 0.0 57536 1184 ?
writer
postgres 15555 0.0 0.0 57536
916 ?
checkpointer
postgres 15556 0.0 0.0 57536
916 ?
postgres 15557 0.0 0.0 58504 2244 ?
launcher
postgres 15558 0.0 0.0 17512 1068 ?
collector
postgres 15582 0.0 0.0 58772 3080 ?
127.0.0.1 idle
postgres 15606 0.0 0.0 58772 3052 ?
regression [local] SELECT waiting
postgres 15610 0.0 0.0 58772 3056 ?
regression [local] idle in transaction
S
Ss 18:02
18:02 0:00 postgres -i
0:00 postgres: background
Ss 18:02 0:00 postgres:
Ss
Ss 18:02
18:02 0:00 postgres: walwriter
0:00 postgres: autovacuum
Ss 18:02 0:00 postgres: stats
Ss 18:04 0:00 postgres: joe runbug
Ss 18:07 0:00 postgres: tgl
Ss 18:07 0:00 postgres: tgl
(Формат вызова ps, а также детали отображаемой информации зависят от платформы. Это пример
для одной из последних Linux-систем.) Первым здесь отображается главный процесс сервера. Для
этого процесса отображены аргументы команды, которые использовались при его запуске. Следу-
ющие пять процессов — это фоновые рабочие процессы, которые были автоматически запущены
процессом сервера. (Процесса «stats collector» в этом списке не будет, если запуск сборщика ста-
тистики отключён в системе; аналогично может быть отключён и процесс «autovacuum launcher»
— фоновый процесс автоочистки.) Во всех остальных строках перечислены серверные процессы,
каждый из которых обслуживает одно клиентское подключение. Командная строка каждого тако-
го процесса имеет следующий формат:
postgres: имя_сервера база_данных компьютер активность
Пользователь, СУБД и компьютер (клиента) остаются неизменными на протяжении всего клиент-
ского подключения, а индикатор деятельности меняется. Возможные виды деятельности: idle (т.
е. ожидание команды клиента), idle in transaction (ожидание клиента внутри блока BEGIN) или
название типа команды, например, SELECT. Кроме того, если в настоящий момент серверный про-
цесс ожидает высвобождения блокировки, которую держит другая сессия, то к виду деятельности
добавляется waiting. В приведённом выше примере мы видим, что процесс 15606 ожидает, ко-
гда процесс 15610 завершит свою транзакцию и, следовательно, освободит какую-то блокировку.
(Процесс 15610 является блокирующим, поскольку никаких других активных сессий нет. В более
сложных случаях может потребоваться обращение к системному представлению pg_locks, для то-
го чтобы определить, кто кого блокирует.)
674Мониторинг работы СУБД
Если установлено значение cluster_name, имя кластера также будет показываться в выводе коман-
ды ps:
$ psql -c ‘SHOW cluster_name’
cluster_name
————–
server1
(1 row)
$ ps aux|grep server1
postgres
27093 0.0
background writer
…
0.0
30096
2752 ?
Ss
11:34
0:00 postgres: server1:
Если параметр update_process_title был отключён, то индикатор деятельности не обновляется; на-
звание процесса устанавливается только один раз при запуске нового процесса. На некоторых
платформах это позволяет значительно сократить накладные расходы при выполнении команды;
на других платформах этот выигрыш может быть незначителен.
Подсказка
В Solaris требуется особый подход. Следует использовать /usr/ucb/ps вместо /bin/ps.
Также следует использовать два флага w, а не один. Кроме того, при выводе статусов
команд с помощью ps статус для исходной команды postgres должен отображаться
в сокращённом формате для каждого серверного процесса. Если вы не сделаете все
три вещи, то вывод ps для каждого серверного процесса будет исходной командной
строкой postgres.
28.2. Сборщик статистики
Сборщик статистики в PostgreSQL представляет собой подсистему, которая собирает и отобра-
жает информацию о работе сервера. В настоящее время сборщик может подсчитывать количество
обращений к таблицам и индексам — в виде количества прочитанных блоков или строк с диска.
Кроме того, он отслеживает общее число строк в каждой таблице, информацию о выполнении
очистки и сбора статистики для каждой таблицы. Он также может подсчитывать вызовы пользо-
вательских функций и общее время, затраченное на выполнение каждой из них.
Кроме того, PostgreSQL может предоставить динамическую информацию о том, что происходит
в системе прямо сейчас, в частности, сообщить, какие именно команды выполняются другими
серверными процессами и какие другие соединения существуют в системе. Эта возможность не
зависит от процесса сборщика.
28.2.1. Конфигурация системы сбора статистики
Поскольку сбор статистики несколько увеличивает накладные расходы при выполнении запроса,
есть возможность настроить СУБД так, чтобы выполнять или не выполнять сбор статистической
информации. Это контролируется конфигурационными параметрами, которые обычно устанавли-
ваются в файле postgresql.conf. (Подробно установка конфигурационных параметров описыва-
ется в Главе 19.)
Параметр track_activities включает мониторинг текущих команд, выполняемой любым серверным
процессом.
Параметр track_counts определяет необходимость сбора статистики по обращениям к таблицам и
индексам.
Параметр track_functions включает отслеживание использования пользовательских функций.
Параметр track_io_timing включает мониторинг времени чтения и записи блоков.
675Мониторинг работы СУБД
Обычно эти параметры устанавливаются в postgresql.conf, поэтому они применяются ко всем
серверным процессам, однако, используя команду SET, их можно включать и выключать в отдель-
ных сессиях. (Для того чтобы обычные пользователи не скрывали свою работу от администратора
СУБД, изменять эти параметры с помощью команды SET могут только суперпользователи.)
Сборщик статистики использует временные файлы для передачи собранной информации дру-
гим процессам PostgreSQL. Имя каталога, в котором хранятся эти файлы, задаётся параметром
stats_temp_directory, по умолчанию он называется pg_stat_tmp. Для повышения производительно-
сти stats_temp_directory может указывать на каталог, расположенный в оперативной памяти,
что сокращает время физического ввода/вывода. При остановке сервера постоянная копия стати-
стической информации сохраняется в подкаталоге pg_stat, поэтому статистику можно хранить
на протяжении нескольких перезапусков сервера. Когда восстановление выполняется при запус-
ке сервера (например, после непосредственного завершения работы, катастрофического отказа
сервера, и восстановлении на заданную точку во времени), все статистические данные счётчиков
сбрасываются.
28.2.2. Просмотр статистики
Для просмотра текущего состояния системы предназначены несколько предопределённых пред-
ставлений, которые перечислены в Таблице 28.1. В дополнение к ним есть несколько других пред-
ставлений, перечисленных в Таблице 28.2, позволяющих просмотреть результаты сбора статисти-
ки. Кроме того, на базе нижележащих статистических функций можно создать собственные пред-
ставления, как описано в Подразделе 28.2.3.
Наблюдая собранные данные в сборщике статистики, важно понимать, что эта информация обнов-
ляется не сразу. Каждый серверный процесс передаёт новые статистические данные сборщику
статистики непосредственно перед переходом в режим ожидания; то есть запрос или транзакция
в процессе выполнения не влияют на отображаемые данные статистики. К тому же, сам сборщик
статистики формирует новый отчёт не чаще, чем раз в PGSTAT_STAT_INTERVAL миллисекунд (500
мс, если этот параметр не изменялся при компиляции сервера). Так что отображаемая информа-
ция отстаёт от того, что происходит в настоящий момент. Однако информация о текущем запросе,
собираемая с параметром track_activities, всегда актуальна.
Ещё одним важным моментом является то, что когда в серверном процессе запрашивают какую-ли-
бо статистику, сначала он получает наиболее свежий моментальный снимок от сборщика стати-
стики и затем до окончания текущей транзакции использует этот снимок для всех статистических
представлений и функций. Так что на протяжении одной транзакции статистическая информация
меняться не будет. Подобным же образом информация о текущих запросах во всех сессиях соби-
рается в тот момент, когда она впервые запрашивается в рамках транзакции, и эта же самая ин-
формация будет отображаться на протяжении всей транзакции. Это не ошибка, а полезное свой-
ство СУБД, поскольку оно позволяет выполнять запросы к статистическим данным и сравнивать
результаты, не беспокоясь о том, что статистические данные изменяются. Но если для каждого
запроса вам нужны новые результаты, то их следует выполнять вне любых транзакционных блоков.
Или же можно вызывать функцию pg_stat_clear_snapshot(), которая сбросит ранее полученный
снимок статистики в текущей транзакции (если он был). При следующем обращении к статисти-
ческой информации будет сформирован новый моментальный снимок.
Через
представления
pg_stat_xact_all_tables,
pg_stat_xact_sys_tables,
pg_stat_xact_user_tables, и pg_stat_xact_user_functions транзакции также доступна её соб-
ственная статистика (ещё не переданная сборщику статистики). Данные в этих представлениях
ведут себя не так, как описано выше; наоборот, в течение транзакции они постоянно обновляются.
Таблица 28.1. Динамические статистические представления
Имя представления Описание
pg_stat_activity Одна строка для каждого серверного процесса
c информацией по текущей активности процес-
са, такой как состояние и текущий запрос. За по-
дробностями обратитесь к pg_stat_activity.
676Мониторинг работы СУБД
Имя представления Описание
pg_stat_replication По одной строке для каждого процесса-передат-
чика WAL со статистикой по репликации на ве-
домом сервере, к которому подключён этот про-
цесс. За подробностями обратитесь к pg_stat_
replication.
pg_stat_wal_receiver Только одна строка со статистикой приёмника
WAL, полученной с сервера, на котором работа-
ет приёмник. За подробностями обратитесь к pg_
stat_wal_receiver.
pg_stat_subscription Как минимум одна строка для подписки, сообща-
ющая о рабочих процессах подписки. За подроб-
ностями обратитесь к pg_stat_subscription.
pg_stat_ssl Одна строка для каждого подключения (обычно-
го и реплицирующего), в которой показывается
информация об использовании SSL для данного
подключения. Подробности описаны в pg_stat_
ssl.
pg_stat_progress_vacuum По одной строке с текущим состоянием для каж-
дого обслуживающего процесса (включая рабо-
чие процессы автоочистки), в котором работает
VACUUM. См. Подраздел 28.4.1.
Таблица 28.2. Представления собранной статистики
Имя представления Описание
pg_stat_archiver Только одна строка со статистикой о работе ак-
тивности процесса архивации WAL. Более по-
дробно смотрите pg_stat_archiver.
pg_stat_bgwriter Только одна строка со статистикой о работе фо-
нового процесса записи. Более подробно смот-
рите pg_stat_bgwriter.
pg_stat_database Одна строка для каждой базы данных со стати-
стикой на уровне базы. Более подробно смотри-
те pg_stat_database.
pg_stat_database_conflicts По одной строке на каждую базу данных со
статистикой по отменам запросов, выполнен-
ным вследствие конфликта с процессами восста-
новления на ведомых серверах. Более подробно
смотрите pg_stat_database_conflicts.
pg_stat_all_tables По одной строке на каждую таблицу в текущей
базе данных со статистикой по обращениям к
этой таблице. Более подробно смотрите pg_stat_
all_tables.
pg_stat_sys_tables Аналогично pg_stat_all_tables
, за исклю-
чением того, что отображаются только систем-
ные таблицы.
pg_stat_user_tables Аналогично pg_stat_all_tables
, за исклю-
чением того, что отображаются только пользо-
вательские таблицы.
pg_stat_xact_all_tables Подобно pg_stat_all_tables
, но подсчиты-
вает действия, выполненные в текущей транзак-
ции к настоящему моменту (которые ещё не во-
677Мониторинг работы СУБД
Имя представления Описание
шли в pg_stat_all_tables
и связанные пред-
ставления). Столбцы для числа живых и мёртвых
строк, а также количества операций очистки и
сбора статистики, в этом представлении отсут-
ствуют.
pg_stat_xact_sys_tables Аналогично pg_stat_xact_all_tables
, за
исключением того, что отображаются только си-
стемные таблицы.
pg_stat_xact_user_tables Аналогично pg_stat_xact_all_tables
, за
исключением того, что отображаются только
пользовательские таблицы.
pg_stat_all_indexes По одной строке для каждого индекса в теку-
щей базе данных со статистикой по обращениям
к этому индексу. Более подробно смотрите pg_
stat_all_indexes.
pg_stat_sys_indexes Аналогично pg_stat_all_indexes
, за исклю-
чением того, что показываются только индексы
по системным таблицам.
pg_stat_user_indexes Аналогично pg_stat_all_indexes
, за исклю-
чением того, что показываются только индексы
по пользовательским таблицам.
pg_statio_all_tables По одной строке для каждой таблицы в теку-
щей базе данных со статистикой по операциям
ввода/вывода для этой таблицы. Более подробно
смотрите pg_statio_all_tables.
pg_statio_sys_tables Аналогично pg_statio_all_tables
, за ис-
ключением того, что показываются только си-
стемные таблицы.
pg_statio_user_tables Аналогично pg_statio_all_tables
, за ис-
ключением того, что показываются только поль-
зовательские таблицы.
pg_statio_all_indexes По одной строке для каждого индекса в теку-
щей базе данных со статистикой по операциям
ввода/вывода для этого индекса. Более подробно
смотрите pg_statio_all_indexes.
pg_statio_sys_indexes Аналогично pg_statio_all_indexes
, за ис-
ключением того, что показываются только ин-
дексы по системным таблицам.
pg_statio_user_indexes Аналогично pg_statio_all_indexes
, за ис-
ключением того, что показываются только ин-
дексы по пользовательским таблицам.
pg_statio_all_sequences По одной строке для каждой последователь-
ности в текущей базе данных со статистикой
по операциям ввода/вывода для этой последова-
тельности. Более подробно смотрите pg_statio_
all_sequences.
pg_statio_sys_sequences Аналогично pg_statio_all_sequences
, за ис-
ключением того, что показываются только си-
стемные последовательности. (В настоящее вре-
мя системных последовательностей нет, поэто-
му это представление всегда пусто.)
678Мониторинг работы СУБД
Имя представления Описание
pg_statio_user_sequences Аналогично pg_statio_all_sequences
, за ис-
ключением того, что показываются только поль-
зовательские последовательности.
pg_stat_user_functions По одной строке для каждой отслеживаемой
функции со статистикой по выполнениям этой
функции. Более подробно смотрите pg_stat_
user_functions.
pg_stat_xact_user_functions Аналогично pg_stat_user_functions
, одна-
ко подсчитываются только вызовы функций,
выполненные в текущей транзакции (которые
ещё не были включены в pg_stat_user_
functions ).
Статистика по отдельным индексам особенно полезна для определения того, какие индексы ис-
пользуются и насколько они эффективны.
Представления pg_statio_ полезны, прежде всего, для определения эффективности буферного
кеша. Если количество фактических дисковых чтений существенно меньше количества чтений
из буферного кеша, то это означает, что кеш справляется с большинством запросов на чтение
без обращения к ядру. Однако эта статистика не даёт полной картины: PostgreSQL обрабатывает
дисковый ввод/вывод так, что данные, не находящиеся в буферном кеше PostgreSQL, могут все ещё
располагаться в кеше ввода/вывода ядра, и, следовательно, для их получения физическое чтение
может не использоваться. Для получения более детальной информации о процессе ввода/вывода в
PostgreSQL рекомендуется использовать сборщик статистики PostgreSQL в сочетании с утилитами
операционной системы, которые дают более полное представление о том, как ядро осуществляет
ввод/вывод.
Таблица 28.3. Представление pg_stat_activity
Столбец Тип Описание
datid oid OID базы данных, к которой под-
ключён этот серверный процесс
datname name Имя базы данных, к которой
подключён этот серверный про-
цесс
pid integer Идентификатор процесса этого
серверного процесса
usesysid oid OID пользователя, подключён-
ного к этому серверному про-
цессу
usename name Имя пользователя, подключён-
ного к этому серверному про-
цессу
application_name text Название приложения, подклю-
чённого к этому серверному
процессу
client_addr inet IP-адрес клиента, подключённо-
го к этому серверному процес-
су. Значение null в этом поле
означает, что клиент подклю-
чён через сокет Unix на стороне
сервера или что это внутренний
процесс, например, автоочист-
ка.
679Мониторинг работы СУБД
Столбец Тип Описание
client_hostname text Имя компьютера для подклю-
чённого клиента, получаемое в
результате обратного поиска в
DNS по client_addr . Это поле
будет отлично от null только в
случае соединений по IP и толь-
ко при включённом режиме log_
hostname.
client_port integer Номер TCP-порта, который ис-
пользуется клиентом для соеди-
нения с этим серверным про-
цессом, или -1, если использу-
ется сокет Unix
backend_start timestamp with time zone Время
запуска
процесса.
Для процессов, обслуживающих
клиентов, это время подключе-
ния клиента к серверу.
xact_start timestamp with time zone Время начала текущей транзак-
ции в этом процессе или null
при отсутствии активной тран-
закции. Если текущий запрос
был первым в своей транзак-
ции, то значение в этом столбце
совпадает со значением столб-
ца query_start .
query_start timestamp with time zone Время начала выполнения ак-
тивного в данный момент запро-
са, или, если state не active, то
время начала выполнения по-
следнего запроса
state_change timestamp with time zone Время последнего изменения
состояния (поля state)
wait_event_type text Тип события, которого ждёт
обслуживающий процесс, если
это имеет место; в противном
случае — NULL. Возможные
значения:
• LWLock: обслуживающий
процесс ожидает лёгкую
блокировку. Такие блоки-
ровки защищают определён-
ные структуры данных в раз-
деляемой памяти. В wait_
event будет содержаться
имя, отражающее цель по-
лучения лёгкой блокиров-
ки. (Некоторые блокировки
имеют особые имена; другие
объединяются в группы бло-
кировок со схожим предна-
значением.)
• Lock: Обслуживающий про-
цесс ожидает тяжёлую бло-
680Мониторинг работы СУБД
Столбец
Тип
Описание
кировку. Тяжёлые блокиров-
ки, также называемые бло-
кировками менеджера бло-
кировок или просто блоки-
ровками, в основном защи-
щают объекты уровня SQL,
такие как таблицы. Однако
они также применяются для
взаимоисключающего вы-
полнения некоторых внут-
ренних операций, например,
для расширения отношений.
Тип ожидаемой блокировки
показывается в wait_event .
• BufferPin: Серверный про-
цесс ожидает доступа к бу-
феру данных, когда никакой
другой процесс не обраща-
ется к этому буферу. Ожи-
дание закрепления буфера
может растягиваться, если
другой процесс удержива-
ет открытый курсор, кото-
рый читал данные из нужно-
го буфера.
• Activity: Серверный про-
цесс простаивает. Это состо-
яние наблюдается в систем-
ных процессах, ожидающих
активности в основном цик-
ле обработки. В wait_event
обозначается конкретное
место ожидания.
• Extension: Серверный про-
цесс ожидает активности в
модуле расширения. Эта ка-
тегория полезна при исполь-
зовании модулей, она помо-
гает отслеживать нестан-
дартные места ожидания.
• Client: Серверный процесс
ожидает в сокете некоторую
активность пользовательско-
го приложения, и события,
ожидаемые сервером, не
зависят от его внутренних
процессов. В wait_event
обозначается конкретное
место ожидания.
• IPC: Серверный процесс
ожидает некоторой актив-
ности другого процесса на
сервере. В wait_event обо-
681Мониторинг работы СУБД
Столбец
Тип
Описание
значается конкретное место
ожидания.
• Timeout: Серверный процесс
ожидает истечения опреде-
лённого времени. В wait_
event обозначается кон-
кретное место ожидания.
• IO: Серверный процесс ожи-
дает завершения операции
ввода/вывода. В wait_event
обозначается конкретное
место ожидания.
wait_event text Имя ожидаемого события, ес-
ли обслуживающий процесс на-
ходится в состоянии ожидания,
а в противном случае — NULL.
За подробностями обратитесь к
Таблице 28.4.
state text Общее текущее состояние этого
серверного процесса. Возмож-
ные значения:
• active: серверный процесс
выполняет запрос.
• idle: серверный процесс
ожидает новой команды от
клиента.
• idle in transaction: сер-
верный процесс находится
внутри транзакции, но в на-
стоящее время не выполня-
ет никакой запрос.
• idle in transaction (
aborted) : Это состо-
яние подобно idle in
transaction, за исключени-
ем того, что один из опера-
торов в транзакции вызывал
ошибку.
• fastpath function call:
серверный процесс выполня-
ет fast-path функцию.
• disabled: Это состояние
отображается для сервер-
ных процессов, у которых
параметр track_activities от-
ключён.
backend_xid
Идентификатор верхнего уров-
ня транзакции этого серверного
процесса или любой другой.
xid
682Мониторинг работы СУБД
Столбец Тип Описание
backend_xmin xid текущая граница xmin для сер-
верного процесса.
query text Текст последнего запроса это-
го серверного процесса. Если
state имеет значение active,
то в этом поле отображается
запрос, который выполняется в
настоящий момент. Если про-
цесс находится в любом дру-
гом состоянии, то в этом по-
ле отображается последний вы-
полненный запрос. По умолча-
нию текст запроса обрезает-
ся до 1024 символов; это чис-
ло определяется параметром
track_activity_query_size.
backend_type text Тип текущего серверного про-
цесса.
Возможные
вариан-
ты: autovacuum
launcher,
autovacuum
worker,
background
worker,
background
writer, client
backend, checkpointer, startup,
walreceiver, walsender и
walwriter.
В представлении pg_stat_activity для каждого серверного процесса будет присутствовать по од-
ной строке с информацией, относящейся к текущей деятельности этого процесса.
Примечание
Значения в столбцах wait_event и state не зависят друг от друга. Если обслуживаю-
щий процесс находится в состоянии active (активен), он может ожидать какое-то со-
бытие, или не ожидать никакое. Если состояние active и поле wait_event содержит
не NULL, это означает, что запрос выполняется, но заблокирован чем-то в системе.
Таблица 28.4. Описание wait_event
Тип события ожидания Название
ния
события
LWLock ShmemIndexLock Ожидание при поиске или вы-
делении области в разделяемой
памяти.
OidGenLock Ожидание при выделении или
назначении OID.
XidGenLock Ожидание
при
выделении
или назначении идентификато-
ра транзакции.
ProcArrayLock Ожидание при получении сним-
ка или очистке идентификато-
ра транзакции в конце транзак-
ции.
683
ожида- ОписаниеМониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
SInvalReadLock Ожидание при получении или
удалении из общей очереди со-
общений аннулирования.
SInvalWriteLock Ожидание при добавлении в об-
щую очередь сообщения анну-
лирования.
WALBufMappingLock Ожидание при замене страни-
цы в буферах WAL.
WALWriteLock Ожидание при записи буферов
WAL на диск.
ControlFileLock Ожидание при чтении или из-
менении управляющего файла
либо при создании нового фай-
ла WAL.
CheckpointLock Ожидание при выполнении кон-
трольной точки.
CLogControlLock Ожидание при чтении или из-
менении состояния транзак-
ции.
SubtransControlLock Ожидание при чтении или из-
менении информации о под-
транзакции.
MultiXactGenLock Ожидание при чтении или
изменении общего состояния
мультитранзакций.
MultiXactOffsetControlLock Ожидание при чтении или из-
менении смещений мультит-
ранзакций.
MultiXactMemberControlLock Ожидание при чтении или из-
менении членов мультитран-
закций.
RelCacheInitLock Ожидание при чтении или запи-
си файла инициализации кеша
отношения.
CheckpointerCommLock Ожидание при управлении за-
просами fsync.
TwoPhaseStateLock Ожидание при чтении или из-
менении состояния подготов-
ленных транзакций.
TablespaceCreateLock Ожидание при создании или
удалении табличного простран-
ства.
BtreeVacuumLock Ожидание при чтении или из-
менении информации, связан-
ной с очисткой, для индекса-B-
дерева.
AddinShmemInitLock Ожидание при управлении вы-
делением блоков в общей памя-
ти.
684Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
AutovacuumLock Ожидание в рабочем процес-
се или процедуре запуска ав-
тоочистки при изменении или
чтении текущего состояния ра-
бочих процессов автоочистки.
AutovacuumScheduleLock Ожидание при подтверждении,
что таблица, выбранная для
очистки, всё ещё нуждается в
очистке.
SyncScanLock Ожидание при получении на-
чального положения сканиро-
вания таблицы для синхронизи-
рованного сканирования.
RelationMappingLock Ожидание при изменении в
файле сопоставления отноше-
ний, используемого для хране-
ния связей файловых узлов с ка-
талогом БД.
AsyncCtlLock Ожидание при чтении или из-
менении общего состояния уве-
домлений.
AsyncQueueLock Ожидание при чтении или из-
менении сообщений уведомле-
ний.
SerializableXactHashLock Ожидание при получении или
сохранении информации о сери-
ализуемых транзакциях.
SerializableFinishedListLock Ожидание при обращении к
списку завершённых сериали-
зуемых транзакций.
Ожидание при выполнении опе-
SerializablePredicateLockListLock
рации со списком блокировок,
удерживаемых сериализуемы-
ми транзакциями.
OldSerXidLock Ожидание при чтении или запи-
си информации о конфликтую-
щих сериализуемых транзакци-
ях.
SyncRepLock Ожидание при чтении или из-
менении сведений о синхрон-
ных репликах.
BackgroundWorkerLock Ожидание при чтении или из-
менении состояния фонового
рабочего процесса.
Ожидание при чтении или из-
DynamicSharedMemoryControlLock
менении состояния динамиче-
ской общей памяти.
AutoFileLock
685
Ожидание при изменении фай-
ла postgresql.auto.conf.Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
ReplicationSlotAllocationLockОжидание при выделении или
освобождении слота реплика-
ции.
ReplicationSlotControlLock Ожидание при чтении или из-
менении состояния слота ре-
пликации.
CommitTsControlLock Ожидание при чтении или из-
менении времени фиксирова-
ния транзакции.
CommitTsLock Ожидание при чтении или из-
менении последнего значения,
заданного в качестве времени
транзакции.
ReplicationOriginLock Ожидание при подготовке, уда-
лении или использовании ис-
точника репликации.
MultiXactTruncationLock Ожидание при чтении или
очистке информации мультит-
ранзакций.
OldSnapshotTimeMapLock Ожидание при чтении или из-
менении информации о старом
снимке.
BackendRandomLock Ожидание генерирования слу-
чайного числа.
LogicalRepWorkerLock Ожидание завершения дей-
ствия процесса логической ре-
пликации.
CLogTruncationLock Ожидание при усечении жур-
нала предзаписи или ожидание
завершения усечения журнала
предзаписи.
clog Ожидание при вводе/выводе с
буфером clog (буфер состояния
транзакций).
commit_timestamp Ожидание при вводе/выводе с
буфером времени фиксирова-
ния транзакций.
subtrans Ожидание при вводе/выводе с
буфером подтранзакций.
multixact_offset Ожидание при вводе/выводе с
буфером смещений мультитран-
закций.
multixact_member Ожидание при вводе/выводе с
буфером multixact_member.
async Ожидание при вводе/выводе с
буфером асинхронных сообще-
ний (уведомлений).
oldserxid Ожидание ввода/вывода для бу-
фера oldserxid.
686Мониторинг работы СУБД
Тип события ожидания
Lock
Название
ния
события
ожида- Описание
wal_insert Ожидание при добавлении за-
писей WAL в буфер в памяти.
buffer_content Ожидание при чтении или запи-
си страницы данных в памяти.
buffer_io Ожидание при вводе/выводе,
связанном со страницей дан-
ных.
replication_origin Ожидание при чтении или из-
менении состояния реплика-
ции.
replication_slot_io Ожидание при вводе/выводе со
слотом репликации.
proc Ожидание при чтении или из-
менении информации о блоки-
ровках по быстрому пути.
buffer_mapping Ожидание при связывании бло-
ка данных с буфером в пуле бу-
феров.
lock_manager Ожидание при добавлении или
обращении к блокировкам об-
служивающих процессов либо
ожидание входа или выхода из
группы блокировок (использу-
ется в параллельных запросах).
predicate_lock_manager Ожидание при добавлении или
обращении к информации о пре-
дикатных блокировках.
parallel_query_dsa Ожидание блокировки выделе-
ния динамической общей памя-
ти для параллельного запроса.
tbm Ожидание блокировки общего
итератора TBM.
parallel_append Ожидание выбора следующего
подплана в процессе выполне-
ния узла параллельного добав-
ления (Parallel Append).
parallel_hash_join Ожидание выделения или обме-
на блока памяти либо обновле-
ния счётчиков при выполнении
плана параллельного хеширова-
ния (Parallel Hash).
relation Ожидание при запросе блоки-
ровки для отношения.
extend Ожидание при расширении от-
ношения.
page Ожидание при запросе блоки-
ровки для страницы отношения.
tuple Ожидание при запросе блоки-
ровки для кортежа.
687Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
transactionid Ожидание завершения транзак-
ции.
virtualxid Ожидание при запросе блоки-
ровки виртуального xid.
speculative token Ожидание при запросе блоки-
ровки спекулятивного добавле-
ния.
object Ожидание при запросе блоки-
ровки для нереляционного объ-
екта БД.
userlock Ожидание при запросе пользо-
вательской блокировки.
advisory Ожидание при запросе ре-
комендательной пользователь-
ской блокировки.
BufferPin BufferPin Ожидание при закреплении бу-
фера.
Activity ArchiverMain Ожидание в основном цикле
процесса архиватора.
AutoVacuumMain Ожидание в основном цикле
процесса запуска автоочистки.
BgWriterHibernate Ожидание в фоновом процессе
записи, переход в режим «замо-
розки».
BgWriterMain Ожидание в основном цикле ра-
бочего процесса фоновой запи-
си.
CheckpointerMain Ожидание в основном цикле
процесса контрольной точки.
LogicalApplyMain Ожидание в основном цикле
процесса применения логиче-
ской репликации.
LogicalLauncherMain Ожидание в основном цикле
процесса запуска обработчиков
логической репликации.
PgStatMain Ожидание в основном цикле
процесса сборщика статистики.
RecoveryWalAll Ожидание поступления WAL из
любого источника (локального,
архива или потока) при восста-
новлении.
RecoveryWalStream Ожидание поступления WAL из
потока при восстановлении.
SysLoggerMain Ожидание в основном цикле
процесса системного журнала (
syslogger).
WalReceiverMain Ожидание в основном цикле
процесса-приёмника WAL.
688Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
WalSenderMain Ожидание в основном цикле
процесса-передатчика WAL.
WalWriterMain Ожидание в основном цикле
процесса, пишущего WAL.
ClientRead Ожидание при чтении данных,
получаемых от клиента.
ClientWrite Ожидание при записи данных,
передаваемых клиенту.
LibPQWalReceiverConnect Ожидание в приёмнике WAL
установления подключения к
удалённому серверу.
LibPQWalReceiverReceive Ожидание в приёмнике WAL по-
ступления данных от удалённо-
го сервера.
SSLOpenServer Ожидание SSL при попытке
установления соединения.
WalReceiverWaitStart Ожидание от стартового про-
цесса передачи начальных дан-
ных для потоковой репликации.
WalSenderWaitForWAL Ожидание сброса WAL в процес-
се-передатчике WAL.
WalSenderWriteData Ожидание какой-либо активно-
сти при обработке ответов от
WAL-приёмника в процессе-пе-
редатчике WAL.
Extension Extension Ожидание в расширении.
IPC BgWorkerShutdown Ожидание завершения фоново-
го рабочего процесса.
BgWorkerStartup Ожидание запуска фонового ра-
бочего процесса.
BtreePage Ожидание доступности номе-
ра страницы, необходимого
для продолжения параллельно-
го сканирования B-дерева.
ClogGroupUpdate Ожидание изменения состоя-
ния завершённой транзакции
ведущим процессом группы.
ExecuteGather Ожидание активности дочерне-
го процесса при выполнении уз-
ла Gather.
Hash/Batch/Allocating Ожидание выделения хеш-таб-
лицы выбранным участником
параллельного хеширования.
Hash/Batch/Electing Выбор участника параллельно-
го хеширования для выделения
хеш-таблицы.
Hash/Batch/Loading Ожидание завершения загруз-
ки хеш-таблицы другими участ-
Client
689Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
никами параллельного хеширо-
вания.
Hash/Build/Allocating Ожидание выделения началь-
ной хеш-таблицы выбранным
участником параллельного хе-
ширования.
Hash/Build/Electing Выбор участника параллельно-
го хеширования для выделения
начальной хеш-таблицы.
Hash/Build/HashingInner Ожидание завершения хеши-
рования внутреннего отноше-
ния другими участниками па-
раллельного хеширования.
Hash/Build/HashingOuter Ожидание завершения хеширо-
вания внешнего отношения дру-
гими участниками параллель-
ного хеширования.
Hash/GrowBatches/Allocating Ожидание выделения допол-
нительных пакетов выбранным
участником параллельного хе-
ширования.
Hash/GrowBatches/Deciding Выбор участника параллельно-
го хеширования для принятия
решений о предстоящем добав-
лении пакетов.
Hash/GrowBatches/Electing Выбор участника параллельно-
го хеширования для выделения
дополнительных пакетов.
Hash/GrowBatches/Finishing Ожидание решения о предстоя-
щем добавлении пакетов участ-
ником параллельного хеширо-
вания.
Hash/GrowBatches/
Repartitioning Ожидание завершения перераз-
биения другими участниками
параллельного хеширования.
Hash/GrowBuckets/Allocating Ожидание завершения выде-
ления дополнительных групп
выбранным участником парал-
лельного хеширования.
Hash/GrowBuckets/Electing Выбор участника параллельно-
го хеширования для выделения
дополнительных групп.
Hash/GrowBuckets/Reinserting Ожидание завершения добавле-
ния кортежей в новые груп-
пы другими участниками парал-
лельного хеширования.
LogicalSyncData
690
Ожидание от удалённого серве-
ра логической репликации пе-
редачи данных для начальной
синхронизации таблиц.Мониторинг работы СУБД
Тип события ожидания
Timeout
IO
Название
ния
события
ожида- Описание
LogicalSyncStateChange Ожидание изменения состоя-
ния удалённого сервера логиче-
ской репликации.
MessageQueueInternal Ожидание подключения друго-
го процесса к общей очереди со-
общений.
MessageQueuePutMessage Ожидание записи сообщения
протокола в общую очередь со-
общений.
MessageQueueReceive Ожидание получения байтов из
общей очереди сообщений.
MessageQueueSend Ожидание передачи байтов в
общую очередь сообщений.
ParallelBitmapScan Ожидание инициализации па-
раллельного сканирования по
битовой карте.
ParallelCreateIndexScan Ожидание завершения скани-
рования кучи параллельными
исполнителями CREATE INDEX.
ParallelFinish Ожидание завершения вычис-
лений параллельными рабочи-
ми процессами.
ProcArrayGroupUpdate Ожидание очистки ведущим
группы идентификатора тран-
закции в конце транзакции.
ReplicationOriginDrop Ожидание перехода источника
репликации в неактивное состо-
яние для последующего удале-
ния.
ReplicationSlotDrop Ожидание перехода слота ре-
пликации в неактивное состо-
яние для последующего удале-
ния.
SafeSnapshot Ожидание снимка для транзак-
ции READ ONLY DEFERRABLE.
SyncRep Ожидание подтверждения от
удалённого сервера при син-
хронной репликации.
BaseBackupThrottle Ожидание в процессе базового
резервного копирования из-за
ограничения активности.
PgSleep Ожидание в процессе, вызвав-
шем pg_sleep .
RecoveryApplyDelay Ожидание применения WAL
при восстановлении из-за за-
держки.
BufFileRead Ожидание чтения из буферизо-
ванного файла.
691Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
BufFileWrite Ожидание записи в буферизо-
ванный файл.
ControlFileRead Ожидание чтения из управляю-
щего файла.
ControlFileSync Ожидание помещения управля-
ющего файла в надёжное храни-
лище.
ControlFileSyncUpdate Ожидание переноса изменений
управляющего файла в надёж-
ное хранилище.
ControlFileWrite Ожидание записи в управляю-
щий файл.
ControlFileWriteUpdate Ожидание записи для измене-
ния управляющего файла.
CopyFileRead Ожидание чтения во время опе-
рации копирования файла.
CopyFileWrite Ожидание записи во время опе-
рации копирования файла.
DataFileExtend Ожидание расширения файла
данных отношения.
DataFileFlush Ожидание помещения файла
данных отношения в надёжное
хранилище.
DataFileImmediateSync Ожидание немедленной син-
хронизации файла данных от-
ношения с надёжным хранили-
щем.
DataFilePrefetch Ожидание асинхронной пред-
выборки из файла данных отно-
шения.
DataFileRead Ожидание чтения из файла дан-
ных отношения.
DataFileSync Ожидание переноса изменений
в файле данных отношений в на-
дёжное хранилище.
DataFileTruncate Ожидание усечения файла дан-
ных отношения.
DataFileWrite Ожидание записи в файл дан-
ных отношения.
DSMFillZeroWrite Ожидание записи нулевых байт
в файл, поддерживающий рабо-
ту динамической общей памя-
ти.
LockFileAddToDataDirRead Ожидание чтения при добавле-
нии строки в файл блокировки
каталога данных.
LockFileAddToDataDirSync Ожидание помещения данных
в надёжное хранилище при до-
692Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
бавлении строки в файл блоки-
ровки каталога данных.
LockFileAddToDataDirWrite Ожидание записи при добавле-
нии строки в файл блокировки
каталога данных.
LockFileCreateRead Ожидание чтения при созда-
нии файла блокировки каталога
данных.
LockFileCreateSync Ожидание помещения данных
в надёжное хранилище при со-
здании файла блокировки ката-
лога данных.
LockFileCreateWrite Ожидание записи при созда-
нии файла блокировки каталога
данных.
LockFileReCheckDataDirRead Ожидание чтения во время пе-
репроверки файла блокировки
каталога данных.
LogicalRewriteCheckpointSync Ожидание помещения отобра-
жений логической перезаписи
в надёжное хранилище во время
контрольной точки.
LogicalRewriteMappingSync Ожидание помещения данных
отображений в надёжное хра-
нилище в процессе логической
перезаписи.
LogicalRewriteMappingWrite Ожидание записи данных отоб-
ражений в процессе логической
перезаписи.
LogicalRewriteSync Ожидание помещения отобра-
жений логической перезаписи
в надёжное хранилище.
LogicalRewriteWrite Ожидание сохранения отобра-
жений логической перезаписи.
RelationMapRead Ожидание чтения файла отоб-
ражений отношений.
RelationMapSync Ожидание помещения файла
отображений отношений в на-
дёжное хранилище.
RelationMapWrite Ожидание записи в файл отоб-
ражений отношений.
ReorderBufferRead Ожидание чтения при работе с
буфером переупорядочивания.
ReorderBufferWrite Ожидание записи при работе с
буфером переупорядочивания.
ReorderLogicalMappingRead Ожидание чтения логического
отображения при работе с буфе-
ром переупорядочивания.
693Мониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
ReplicationSlotRead Ожидание чтения из управляю-
щего файла слота репликации.
ReplicationSlotRestoreSync Ожидание помещения в надёж-
ное хранилище управляющего
файла слота репликации при
восстановлении его в памяти.
ReplicationSlotSync Ожидание помещения в надёж-
ное хранилище управляющего
файла слота репликации.
ReplicationSlotWrite Ожидание записи в управляю-
щий файл слота репликации.
SLRUFlushSync Ожидание помещения данных
SLRU в надёжное хранилище во
время контрольной точки или
отключения базы данных.
SLRURead Ожидание
SLRU.
SLRUSync Ожидание помещения данных
SLRU в надёжное хранилище
после записи страницы.
SLRUWrite Ожидание
SLRU.
SnapbuildRead Ожидание чтения сериализо-
ванного исторического снимка
каталога БД.
SnapbuildSync Ожидание помещения сериали-
зованного исторического сним-
ка каталога БД в надёжное хра-
нилище.
SnapbuildWrite Ожидание записи сериализо-
ванного исторического снимка
каталога БД.
TimelineHistoryFileSync Ожидание помещения в надёж-
ное хранилище файла истории
линии времени, полученного
через потоковую репликацию.
TimelineHistoryFileWrite Ожидание записи файла исто-
рии линии времени, получен-
ного через потоковую реплика-
цию.
TimelineHistoryRead Ожидание чтения файла исто-
рии линии времени.
TimelineHistorySync Ожидание помещения в надёж-
ное хранилище только что со-
зданного файла истории линии
времени.
TimelineHistoryWrite Ожидание записи только что со-
зданного файла истории линии
времени.
694
чтения
записи
страницы
страницыМониторинг работы СУБД
Тип события ожидания
Название
ния
события
ожида- Описание
TwophaseFileRead Ожидание чтения файла двух-
фазного состояния.
TwophaseFileSync Ожидание помещения файла
двухфазного состояния в на-
дёжное хранилище.
TwophaseFileWrite Ожидание записи файла двух-
фазного состояния.
WALBootstrapSync Ожидание помещения WAL в
надёжное хранилище в процес-
се начальной загрузки.
WALBootstrapWrite Ожидание записи страницы
WAL в процессе начальной за-
грузки.
WALCopyRead Ожидание чтения при создании
нового сегмента WAL путём ко-
пирования существующего.
WALCopySync Ожидание помещения в надёж-
ное хранилище нового сегмента
WAL, созданного путём копиро-
вания существующего.
WALCopyWrite Ожидание записи при создании
нового сегмента WAL путём ко-
пирования существующего.
WALInitSync Ожидание помещения в надёж-
ное хранилище нового инициа-
лизированного файла WAL.
WALInitWrite Ожидание записи при инициа-
лизации нового файла WAL.
WALRead Ожидание
WAL.
чтения
из
файла
WALSenderTimelineHistoryRead Ожидание чтения из файла ис-
тории линии времени при обра-
ботки процессом walsender ко-
манды timeline.
WALSyncMethodAssign Ожидание помещения данных в
надёжное хранилище при смене
метода синхронизации WAL.
WALWrite Ожидание записи в файл WAL.
Примечание
Для траншей, регистрируемых расширениями, в поле wait_event выводится имя, ука-
зываемое расширением. Пользователь вполне может зарегистрировать транш и в об-
служивающем процессе (воспользовавшись динамической общей памятью), в резуль-
тате чего другие процессы не получат доступа к этой информации; в таких случаях в
этом поле выводится extension.
Следующая команда показывает, как можно просмотреть события ожидания:
695Мониторинг работы СУБД
SELECT pid, wait_event_type, wait_event FROM pg_stat_activity WHERE wait_event is NOT
NULL;
pid | wait_event_type | wait_event
——+—————–+—————
2540 | Lock
| relation
6644 | LWLock
| ProcArrayLock
(2 rows)
Таблица 28.5. Представление pg_stat_replication
Столбец Тип Описание
pid integer Идентификатор процесса-пере-
датчика WAL
usesysid oid OID пользователя, подключён-
ного к этому процессу-передат-
чику WAL
usename name Имя пользователя, подключён-
ного к этому процессу-передат-
чику WAL
application_name text Имя приложения, которое под-
ключено к этому процессу-пере-
датчику WAL
client_addr inet IP-адрес клиента, подключённо-
го к этому процессу-передатчи-
ку WAL. Значение null в этом
поле говорит о том, что клиент
подсоединён через сокет Unix
на сервере.
client_hostname text Имя компьютера для подклю-
чённого клиента, получаемое в
результате обратного поиска в
DNS по client_addr . Это поле
будет отлично от null только в
случае соединений по IP и толь-
ко при включённом режиме log_
hostname.
client_port integer Номер TCP-порта, который ис-
пользуется клиентом для вза-
имодействия с процессом-пере-
датчиком WAL, или -1, если ис-
пользуется сокет Unix
backend_start timestamp with time zone Время запуска процесса, т. е.
время подключения клиента
к этому процессу-передатчику
WAL
backend_xmin xid Значение xmin, полученное от
ведомого сервера при включён-
ном hot_standby_feedback.
state text Текущее состояние процес-
са-передатчика WAL. Возмож-
ные значения:
• startup: Передатчик WAL
запускается.
696Мониторинг работы СУБД
Столбец
Тип
Описание
• catchup: Подключённый к
этому передатчику WAL ве-
домый сервер догоняет веду-
щий.
• streaming: Передатчик WAL
транслирует изменения по-
сле того, как подключённый
к нему ведомый сервер на-
гнал ведущий.
• backup: Передатчик WAL пе-
редаёт резервную копию.
• stopping: Передатчик WAL
останавливается.
sent_lsn pg_lsn Последняя позиция в журнале
предзаписи, переданная через
это соединение
write_lsn pg_lsn Последняя позиция в журна-
ле предзаписи, записанная на
диск этим ведомым сервером
flush_lsn pg_lsn Последняя позиция в журна-
ле предзаписи, сброшенная на
диск этим ведомым сервером
replay_lsn pg_lsn Последняя позиция в журнале
предзаписи, воспроизведённая
в базе данных этим ведомым
сервером
write_lag interval Время, прошедшее с момента
локального сброса последних
данных WAL до получения уве-
домления о том, что этот ве-
домый сервер записал их (но
ещё не сбросил на диск и не
применил). Это позволяет оце-
нить задержку, возникающую
при фиксации транзакции, ко-
гда в synchronous_commit вы-
бран уровень remote_write , ес-
ли данный сервер будет настро-
ен как синхронный ведомый.
flush_lag interval Время, прошедшее с момента
локального сброса последних
данных WAL до получения уве-
домления о том, что этот ве-
домый сервер записал и сбро-
сил их на диск (но ещё не
применил). Это позволяет оце-
нить задержку, возникающую
при фиксации транзакции, ко-
гда в synchronous_commit вы-
бран уровень remote_flush , ес-
ли данный сервер будет настро-
ен как синхронный ведомый.
697Мониторинг работы СУБД
Столбец Тип Описание
replay_lag interval Время, прошедшее с момен-
та локального сброса послед-
них данных WAL до получе-
ния уведомления о том, что
этот ведомый сервер записал,
сбросил на диск и приме-
нил их. Это позволяет оце-
нить задержку, возникающую
при фиксации транзакции, ко-
гда в synchronous_commit вы-
бран уровень remote_apply , ес-
ли данный сервер будет настро-
ен как синхронный ведомый.
sync_priority integer Приоритет этого ведомого сер-
вера для выбора в качестве
синхронного ведомого при син-
хронной репликации с учётом
приоритетов. При синхронной
репликации с учётом кворума
не имеет значения.
sync_state text Состояние синхронизации это-
го ведомого сервера. Возмож-
ные значения:
• async: Этот ведомый сервер
является асинхронным.
• potential: Этот ведомый
сервер сейчас является
асинхронным, но может
стать синхронным в случае
отказа одного из текущих
синхронных серверов.
• sync: Этот ведомый сервер
является синхронным.
• quorum: Этот ведомый сер-
вер считается кандитатом
на участие в кворуме.
Представление pg_stat_replication для каждого процесса-передатчика WAL будет содержать по
одной строке со статистикой о репликации на ведомый сервер, к которому подключён этот про-
цесс. В представлении перечисляются только ведомые серверы, подключённые напрямую; инфор-
мация о ведомых серверах, подключённых опосредованно, не представлена.
Длительность задержек, показываемая в представлении pg_stat_replication, включает время,
которое потребовалось для того, чтобы записать, сбросить на диск и воспроизвести последние за-
писи WAL и для того, чтобы передатчик WAL узнал об этом. Эта длительность отражает задерж-
ку фиксации, которая была (или могла быть) добавлена на уровнях синхронной фиксации, если
ведомый сервер был настроен как синхронный. Для асинхронного ведомого в столбце replay_lag
показывается примерная задержка перед тем, как последние транзакции становятся видны для
запросов. Если ведомый сервер нагоняет передающий и в WAL отсутствует активность, последние
длительности задержек будут отображаться ещё некоторое время, а затем сменятся на NULL.
Длительность задержек автоматически определяется при физической репликации. Модули логи-
ческого декодирования могут не выдавать необходимые контрольные сообщения; в их отсутствие
механизм отслеживания просто выводит задержку NULL.
698Мониторинг работы СУБД
Примечание
Выдаваемые длительности задержек не являются предсказанием времени, которое по-
требуется ведомому серверу, чтобы нагнать передающий сервер с учётом текущей ско-
рости воспроизведения. Эти показатели будут близки в процессе генерирования ново-
го WAL, но не в то время, когда передающий сервер будет простаивать. В частности,
когда ведомый сервер нагоняет ведущий, в pg_stat_replication показывается, сколь-
ко времени потребовалось для записи, сброса на диск и воспроизведения последних
данных WAL, а не 0, как могли ожидать некоторые пользователи. Это соответствует
задаче измерения задержек синхронной фиксации и видимости транзакций для недав-
но записанных транзакций. Чтобы меньше смущать пользователей, ожидающих видеть
другую модель задержек, столбцы задержек сбрасываются в NULL после небольшой
паузы в системе, которая воспроизвела все изменения и теперь простаивает. Системы
мониторинга могут представлять это как отсутствующие данные, 0 или продолжать
показывать последнее известное значение.
Таблица 28.6. Представление pg_stat_wal_receiver
Столбец Тип Описание
pid integer Идентификатор процесса WAL-
приёмника
status text Состояние активности процесса
WAL-приёмника
receive_start_lsn pg_lsn Первая позиция в журнале
предзаписи в момент запуска
приёмника WAL
receive_start_tli integer Первый номер линии времени
в момент запуска приёмника
WAL
received_lsn pg_lsn Последняя позиция в журнале
предзаписи, уже полученная и
сброшенная на диск; началь-
ным значением этого поля бу-
дет первая позиция в журна-
ле в момент запуска приёмника
WAL
received_tli integer Номер линии времени послед-
ней позиции в журнале предза-
писи, уже полученной и сбро-
шенной на диск; начальным
значением этого поля будет но-
мер линии времени первой по-
зиции в момент запуска приём-
ника WAL
last_msg_send_time timestamp with time zone Время отправки последнего со-
общения, полученного от изна-
чального передатчика WAL
last_msg_receipt_time timestamp with time zone Время поступления последнего
сообщения, полученного от из-
начального передатчика WAL
latest_end_lsn pg_lsn Последняя позиция в журнале
предзаписи, сообщённая изна-
чальному передатчику WAL
699Мониторинг работы СУБД
Столбец Тип Описание
latest_end_time timestamp with time zone Время последней позиции в
журнале предзаписи, сообщён-
ной изначальному передатчику
WAL
slot_name text Имя слота репликации, исполь-
зуемого этим приёмником WAL
sender_host text Узел, где работает сервер
PostgreSQL,
обслуживающий
данный приёмник WAL. Может
задаваться именем или IP-адре-
сом компьютера либо путём ка-
талога (если подключение уста-
новлено через сокет Unix). (
Подключение к сокету легко
распознать, потому что путь
всегда абсолютный и начинает-
ся с /.)
sender_port integer Номер
порта
сервера
PostgreSQL, к которому подклю-
чён этот приёмник WAL.
conninfo text Строка подключения, использу-
емая этим приёмником WAL (
секретные поля в ней скрыты).
Представление pg_stat_wal_receiver будет иметь только одну строку со статистикой приёмника
WAL от сервера, на котором работает приёмник.
Таблица 28.7. Представление pg_stat_subscription
Столбец Тип Описание
subid oid OID подписки
subname text Имя подписки
pid integer Идентификатор рабочего про-
цесса, обслуживающего под-
писку
relid Oid OID отношения, которое син-
хронизирует рабочий процесс
сейчас; null для основного про-
цесса применения изменений
received_lsn pg_lsn Последняя позиция в журнале
предзаписи (начальное значе-
ние этого поля — 0)
last_msg_send_time timestamp with time zone Время отправки последнего со-
общения, полученного от изна-
чального передатчика WAL
last_msg_receipt_time timestamp with time zone Время поступления последнего
сообщения, полученного от из-
начального передатчика WAL
latest_end_lsn pg_lsn Последняя позиция в журнале
предзаписи, сообщённая изна-
чальному передатчику WAL
700Мониторинг работы СУБД
Столбец Тип Описание
latest_end_time timestamp with time zone Время последней позиции в
журнале предзаписи, сообщён-
ной изначальному передатчику
WAL
Представление pg_stat_subscription содержит по одной строке для подписки для основного ра-
бочего процесса (с NULL в PID, если процесс не работает) и дополнительные строки для рабочих
процессов, осуществляющих копирование начальных данных для таблиц в подписке.
Таблица 28.8. Представление pg_stat_ssl
Столбец Тип Описание
pid integer Идентификатор
обслуживаю-
щего процесса или процесса,
передающего WAL
ssl boolean True, если для этого подключе-
ния используется SSL
version text Версия SSL либо NULL, если
SSL для этого подключения не
используется
cipher text Имя применяемого шифра SSL
либо NULL, если SSL для этого
подключения не используется
bits integer Число бит в применяемом алго-
ритме шифрования либо NULL,
если SSL для этого подключе-
ния не используется
compression boolean True, если применяется сжатие
SSL, false в противном случае,
либо NULL, если SSL для этого
подключения не используется
clientdn text Поле DN (Distinguished Name,
Уникальное имя) из используе-
мого клиентского сертификата
либо NULL, если клиент не пе-
редал сертификат или SSL для
этого подключения не исполь-
зуется. Это значение усекает-
ся, если поле DN оказывает-
ся длиннее NAMEDATALEN симво-
лов (64 символов в стандартной
сборке)
Представление pg_stat_ssl содержит по одной строке для каждого обслуживающего процесса
и процесса, передающего WAL, и показывает статистику использования SSL для подключений.
Его можно соединить с pg_stat_activity или pg_stat_replication по столбцу pid и получить
дополнительные сведения о подключении.
Таблица 28.9. Представление pg_stat_archiver
Столбец Тип Описание
archived_count bigint Число файлов WAL, которые бы-
ли успешно архивированы
701Мониторинг работы СУБД
Столбец Тип Описание
last_archived_wal text Имя последнего файла WAL
успешно архивированного
last_archived_time timestamp with time zone Время последней успешной ар-
хивации
failed_count bigint Число неудачных попыток архи-
вации файлов WAL
last_failed_wal text Имя файла WAL последней
неудавшейся архивации
last_failed_time timestamp with time zone Время последней неудавшейся
архивации
stats_reset timestamp with time zone Последнее время сброса этих
статистических данных
Представление pg_stat_archiver всегда будет иметь одну строку, содержащую данные о текущем
состоянии процесса архивации кластера.
Таблица 28.10. Представление pg_stat_bgwriter
Столбец Тип Описание
checkpoints_timed bigint Количество запланированных
контрольных точек, которые
уже были выполнены
checkpoints_req bigint Количество запрошенных кон-
трольных точек, которые уже
были выполнены
checkpoint_write_time double precision Общее время, которое было за-
трачено на этап обработки кон-
трольной точки, в котором фай-
лы записываются на диск, в
миллисекундах
checkpoint_sync_time double precision Общее время, которое было за-
трачено на этап обработки кон-
трольной точки, в котором фай-
лы синхронизируются с диском,
в миллисекундах
buffers_checkpoint bigint Количество буферов, записан-
ных при выполнении контроль-
ных точек
buffers_clean bigint Количество буферов, записан-
ных фоновым процессом записи
maxwritten_clean bigint Сколько раз фоновый про-
цесс записи останавливал сброс
грязных страниц на диск из-за
того, что записал слишком мно-
го буферов
buffers_backend bigint Количество буферов, записан-
ных самим серверным процес-
сом
buffers_backend_fsync bigint Сколько раз серверному про-
цессу
пришлось
выполнить
fsync самостоятельно (обычно
702Мониторинг работы СУБД
Столбец Тип Описание
фоновый процесс записи сам об-
рабатывает эти вызовы, даже
когда серверный процесс вы-
полняет запись самостоятель-
но)
buffers_alloc bigint Количество выделенных буфе-
ров
stats_reset timestamp with time zone Последнее время сброса этих
статистических данных
В представлении pg_stat_bgwriter всегда будет только одна строка, в которой будут представлены
общие данные по всему кластеру.
Таблица 28.11. Представление pg_stat_database
Столбец Тип Описание
datid oid OID базы данных
datname name Имя базы данных
numbackends integer Количество серверных процес-
сов, в настоящее время подклю-
чённых к этой базе данных. Это
единственный столбец в этом
представлении, значение в ко-
тором отражает текущее состо-
яние; все другие столбцы воз-
вращают суммарные значения
со времени последнего сброса
статистики.
xact_commit bigint Количество зафиксированных
транзакций в этой базе данных
xact_rollback bigint Количество транзакций в этой
базе данных, для которых был
выполнен откат транзакции
blks_read bigint Количество прочитанных дис-
ковых блоков в этой базе данных
blks_hit bigint Сколько раз дисковые блоки об-
наруживались в буферном ке-
ше, так что чтение с диска не
потребовалось (в значение вхо-
дят только случаи обнаружения
в буферном кеше PostgreSQL,
а не в кеше файловой системы
ОС)
tup_returned bigint Количество строк, возвращён-
ное запросами в этой базе дан-
ных
tup_fetched bigint Количество строк, извлечённое
запросами в этой базе данных
tup_inserted bigint Количество строк, вставленное
запросами в этой базе данных
tup_updated bigint Количество строк, изменённое
запросами в этой базе данных
703Мониторинг работы СУБД
Столбец Тип Описание
tup_deleted bigint Количество строк, удалённое
запросами в этой базе данных
conflicts bigint Количество запросов, отменён-
ных из-за конфликта с восста-
новлением в этой базе данных.
(Конфликты происходят толь-
ко на ведомых серверах; бо-
лее подробно смотрите pg_stat_
database_conflicts.)
temp_files bigint Количество временных файлов,
созданных запросами в этой ба-
зе данных. Подсчитываются все
временные файлы независимо
от причины их создания (напри-
мер, для сортировки или для
хеширования) и независимо от
установленного значения log_
temp_files
temp_bytes bigint Общий объём данных, записан-
ных во временные файлы запро-
сами в этой базе данных. Учиты-
ваются все временные файлы,
вне зависимости от того, по ка-
кой причине они созданы и вне
зависимости от значения log_
temp_files.
deadlocks bigint Количество взаимных блокиро-
вок, зафиксированное в этой ба-
зе данных
blk_read_time double precision Время, затраченное серверны-
ми процессами в этой базе дан-
ных, на чтение блоков из фай-
лов данных, в миллисекундах
blk_write_time double precision Время, затраченное серверны-
ми процессами в этой базе дан-
ных, на запись блоков в файлы
данных, в миллисекундах
stats_reset timestamp with time zone Последнее время сброса этих
статистических данных
Представление pg_stat_database содержит одну строку со статистикой на каждую базу данных
кластера.
Таблица 28.12. Представление pg_stat_database_conflicts
Столбец Тип Описание
datid oid OID базы данных
datname name Имя базы данных
confl_tablespace bigint Количество запросов в этой ба-
зе данных, отменённых из-за то-
го, что табличные пространства
были удалены
704Мониторинг работы СУБД
Столбец Тип Описание
confl_lock bigint Количество запросов в этой ба-
зе данных, отменённых по исте-
чении времени ожидания бло-
кировки
confl_snapshot bigint Количество запросов в этой ба-
зе данных, отменённых из-за
устаревших снимков данных
confl_bufferpin bigint Количество запросов в этой ба-
зе данных, отменённых из-за
прикреплённых страниц буфера
confl_deadlock bigint Количество запросов в этой ба-
зе данных, отменённых из-за
взаимных блокировок
Представление pg_stat_database_conflicts для каждой базы данных будет содержать по одной
строке со статистикой на уровне базы по отменам запросов, произошедшим вследствие конфлик-
тов с процессами восстановления на ведомых серверах. В этом представлении будет содержаться
только информация по ведомым серверам, поскольку на главных серверах конфликты не возника-
ют.
Таблица 28.13. Представление pg_stat_all_tables
Столбец Тип Описание
relid oid OID таблицы
schemaname name Имя схемы, в которой располо-
жена эта таблица
relname name Имя таблицы
seq_scan bigint Количество последовательных
чтений, запущенных по этой
таблице
seq_tup_read bigint Количество “живых” строк, про-
читанных при последователь-
ных чтениях
idx_scan bigint Количество сканирований по
индексу, запущенных по этой
таблице
idx_tup_fetch bigint Количество “живых” строк, ото-
бранных при сканированиях по
индексу
n_tup_ins bigint Количество вставленных строк
n_tup_upd bigint Количество изменённых строк
(включая изменения по схеме
HOT)
n_tup_del bigint Количество удалённых строк
n_tup_hot_upd bigint Количество строк, обновлённых
в режиме HOT (т. е. без отдель-
ного изменения индекса)
n_live_tup bigint Оценочное количество “живых”
строк
n_dead_tup bigint Оценочное количество “мёрт-
вых” строк
705Мониторинг работы СУБД
Столбец Тип Описание
n_mod_since_analyze bigint Оценочное число строк, изме-
нённых в этой таблице, с момен-
та последнего сбора статистики
last_vacuum timestamp with time zone Время последней очистки этой
таблицы вручную (VACUUM FULL
не учитывается)
last_autovacuum timestamp with time zone Время последней очистки таб-
лицы фоновым процессом авто-
очистки
last_analyze timestamp with time zone Время последнего выполнения
сбора статистики для этой таб-
лицы вручную
last_autoanalyze timestamp with time zone Время последнего выполнения
сбора статистики для этой таб-
лицы фоновым процессом авто-
очистки
vacuum_count bigint Сколько раз очистка этой таб-
лицы была выполнена вручную
(VACUUM FULL не учитывается)
autovacuum_count bigint Сколько раз очистка этой таб-
лицы была выполнена фоновым
процессом автоочистки
analyze_count bigint Сколько раз сбор статистики
для этой таблицы был выполнен
вручную
autoanalyze_count bigint Сколько раз сбор статистики
для этой таблицы был выполнен
фоновым процессом автоочист-
ки
Представление pg_stat_all_tables будет содержать по одной строке на каждую таблицу в теку-
щей базе данных (включая таблицы TOAST) со статистикой по обращениям к этой таблице. Пред-
ставления pg_stat_user_tables и pg_stat_sys_tables содержат ту же самую информацию, но от-
фильтрованную так, чтобы показывать только пользовательские и системные таблицы соответ-
ственно.
Таблица 28.14. Представление pg_stat_all_indexes
Столбец Тип Описание
relid oid OID таблицы для индекса
indexrelid oid OID индекса
schemaname name Имя схемы, в которой располо-
жен индекс
relname name Имя таблицы для индекса
indexrelname name Имя индекса
idx_scan bigint Количество запущенных скани-
рований по этому индексу
idx_tup_read bigint Количество элементов индекса,
возвращённых при сканирова-
ниях по этому индексу
706Мониторинг работы СУБД
Столбец Тип Описание
idx_tup_fetch bigint Количество живых строк таб-
лицы, отобранных при простых
сканированиях по этому индек-
су
Представление pg_stat_all_indexes для каждого индекса в текущей базе данных будет со-
держать по одной строке со статистикой по обращениям к этому индексу. Представления
pg_stat_user_indexes и pg_stat_sys_indexes содержат ту же самую информацию, но отфильтро-
ванную так, чтобы показывать только пользовательские и системные индексы соответственно.
Индексы могут использоваться при простом сканировании по индексу, при сканировании «бито-
вой карты» индекса и в работе оптимизатора. Результаты сканирования битовых карт разных ин-
дексов могут объединяться логическим умножением или сложением, поэтому когда применяются
битовые карты, сложно связать выборки отдельных строк с определёнными индексами. Поэтому
при сканировании битовых карт увеличиваются счётчики pg_stat_all_indexes.idx_tup_read для
задействованных индексов и счётчик pg_stat_all_tables.idx_tup_fetch для каждой таблицы, а
pg_stat_all_indexes.idx_tup_fetch не меняется. Оптимизатор тоже обращается к индексам для
проверки переданных констант, значения которых оказываются вне диапазона, записанного в ста-
тистике оптимизатора, так как эта статистика может быть неактуальной.
Примечание
Значения счётчиков idx_tup_read и idx_tup_fetch могут различаться, даже если ска-
нирование с использованием битовой карты не используется, поскольку idx_tup_read
подсчитывает полученные из индекса элементы, а idx_tup_fetch — количество “жи-
вых” строк, выбранных из таблицы. Различие будет меньше, если “мёртвые” или ещё
незафиксированные строки будут извлекаться с использованием индекса или если для
получения строк таблицы будет использоваться сканирование только по индексу.
Таблица 28.15. Представление pg_statio_all_tables
Столбец Тип Описание
relid oid OID таблицы
schemaname name Имя схемы, в которой располо-
жена эта таблица
relname name Имя таблицы
heap_blks_read bigint Количество дисковых блоков,
прочитанных из этой таблицы
heap_blks_hit bigint Число попаданий в буфер для
этой таблицы
idx_blks_read bigint Количество дисковых блоков,
прочитанных из всех индексов
этой таблицы
idx_blks_hit bigint Число попаданий в буфер для
всех индексов по этой таблице
toast_blks_read bigint Количество прочитанных дис-
ковых блоков TOAST (если есть)
для этой таблицы
toast_blks_hit bigint Число попаданий в буфер в таб-
лице TOAST для этой таблицы (
если такие есть)
tidx_blks_read bigint Количество прочитанных дис-
ковых блоков из индекса по
707Мониторинг работы СУБД
Столбец Тип Описание
TOAST (если есть) для этой таб-
лицы
tidx_blks_hit bigint Число попаданий в буфер для
индекса по TOAST (если есть)
для этой таблицы
Представление pg_statio_all_tables для каждой таблицы (включая таблицы TOAST) в текущей
базе данных будет содержать по одной строке со статистикой по операциям ввода/вывода для этой
таблицы. Представления pg_statio_user_tables и pg_statio_sys_tables содержат ту же самую
информацию, но отфильтрованную так, чтобы показывать только пользовательские или системные
таблицы соответственно.
Таблица 28.16. Представление pg_statio_all_indexes
Столбец Тип Описание
relid oid OID таблицы для индекса
indexrelid oid OID индекса
schemaname name Имя схемы, в которой располо-
жен индекс
relname name Имя таблицы для индекса
indexrelname name Имя индекса
idx_blks_read bigint Количество дисковых блоков,
прочитанных из этого индекса
idx_blks_hit bigint Число попаданий в буфер для
этого индекса
Представление pg_statio_all_indexes для каждого индекса в текущей базе данных будет содер-
жать по одной строке со статистикой по операциям ввода/вывода для этого индекса. Представле-
ния pg_statio_user_indexes и pg_statio_sys_indexes содержат ту же самую информацию, но от-
фильтрованную так, чтобы показывать только пользовательские или системные индексы соответ-
ственно.
Таблица 28.17. Представление pg_statio_all_sequences
Столбец Тип Описание
relid oid OID последовательности
schemaname name Имя схемы, в которой располо-
жена эта последовательность
relname name Имя последовательности
blks_read bigint Количество дисковых блоков,
прочитанных из этой последо-
вательности
blks_hit bigint Число попаданий в буфер в этой
последовательности
Представление pg_statio_all_sequences для каждой последовательности в текущей базе данных
будет содержать по одной строке со статистикой по операциям ввода/вывода для этой последова-
тельности.
Таблица 28.18. Представление pg_stat_user_functions
Столбец Тип Описание
funcid oid OID функции
708Мониторинг работы СУБД
Столбец Тип Описание
schemaname name Имя схемы, в которой располо-
жена функция
funcname name Имя функции
calls bigint Сколько раз вызывалась функ-
ция
total_time double precision Общее время, потраченное на
выполнение этой функции и
всех других функций, вызван-
ных ею, в миллисекундах
self_time double precision Общее время, потраченное на
выполнение самой функции, без
учёта других функций, которые
были ею вызваны, в миллисе-
кундах
Представление pg_stat_user_functions для каждой отслеживаемой функции будет содержать по
одной строке со статистикой по выполнениям этой функции. Отслеживаемые функции определя-
ются параметром track_functions.
28.2.3. Статистические функции
Статистическую информацию можно просматривать и другими способами. Для этого можно напи-
сать запросы, использующие те же функции доступа к статистике, что лежат в основе описанных
выше стандартных представлений. За более подробной информацией, например, об именах этих
функций, обратитесь к определениям этих стандартных представлений. (Например, в psql мож-
но выполнить \d+ pg_stat_activity.) В качестве аргумента функции, предоставляющие доступ к
статистике на уровне базы, принимают OID базы данных, по которой должна быть выдана инфор-
мация. Функции, которые работают на уровне таблиц и индексов, принимают в качестве аргумен-
та OID таблицы или индекса. Аргументом для функции, предоставляющей статистику на уровне
функций, является OID функции. Обратите внимание, что с помощью этих функций можно полу-
чить информацию по таблицам, индексам и функциям исключительно в текущей базе данных.
Дополнительные функции, связанные со сбором статистики, перечислены в Таблице 28.19.
Таблица 28.19. Дополнительные статистические функции
Функция Тип результата Описание
pg_backend_pid() integer Идентификатор
серверного
процесса, выполняющего теку-
щую сессию
setof record Возвращает запись с информа-
цией о серверном процессе с за-
данным PID или по одной стро-
ке для каждого активного сер-
верного процесса в системе, ес-
ли был указан NULL. Возвраща-
емые поля являются подмноже-
ством столбцов представления
pg_stat_activity .
pg_stat_get_snapshot_
timestamp() timestamp with time zone Возвращает время снимка теку-
щей статистики
pg_stat_clear_snapshot() void Сбросить текущий снимок ста-
тистики
pg_stat_reset() void Сбросить в ноль все статисти-
ческие счётчики в текущей ба-
pg_stat_get_activity
integer)
(
709Мониторинг работы СУБД
Функция
Тип результата Описание
зе данных (по умолчанию раз-
решено только суперпользова-
телям, но право выполнения (
EXECUTE) этой функции можно
дать и другим)
void Сбросить в ноль некоторые ста-
тистические счётчики на уров-
не кластера, в зависимости
от заданного аргумента (по
умолчанию разрешено только
суперпользователям, но право
выполнения (EXECUTE) этой
функции можно дать и дру-
гим). Вызов pg_stat_reset_
shared(‘bgwriter’)
сбросит
в ноль все счётчики, которые
показываются в представле-
нии pg_stat_bgwriter , а вы-
зов pg_stat_reset_shared(
‘archiver’)
— все счётчи-
ки в представлении pg_stat_
archiver .
pg_stat_reset_single_
table_counters (oid) void Сбросить в ноль статистику по
отдельной таблице или индексу
в текущей базе данных (по умол-
чанию разрешено только супер-
пользователям, но право выпол-
нения (EXECUTE) этой функции
можно дать и другим)
pg_stat_reset_single_
function_counters (oid) void Сбросить в ноль статистику по
отдельной функции в текущей
базе данных (по умолчанию раз-
решено только суперпользова-
телям, но право выполнения (
EXECUTE) этой функции можно
дать и другим)
pg_stat_reset_shared
text)
(
Функция pg_stat_get_activity, на которой основано представление pg_stat_activity, возвраща-
ет набор строк, содержащих всю доступную информацию о каждом серверном процессе. Иногда
более удобным оказывается получение только части этой информации. В таких случаях можно
использовать набор более старых функций, дающих доступ к статистике на уровне серверных про-
цессов; эти функции описаны в Таблице 28.20. Эти функции используют идентификатор серверно-
го процесса, значение которого варьируется от единицы до числа активных в настоящий момент
серверных процессов. Функция pg_stat_get_backend_idset генерирует по одной строке для каж-
дого активного серверного процесса, что необходимо для вызова этих функций. Например, для то-
го, чтобы отобразить значения PID и текущие запросы всех серверных процессов:
SELECT pg_stat_get_backend_pid(s.backendid) AS pid,
pg_stat_get_backend_activity(s.backendid) AS query
FROM (SELECT pg_stat_get_backend_idset() AS backendid) AS s;
Таблица 28.20. Статистические функции на уровне серверных процессов
Функция Тип результата Описание
pg_stat_get_backend_
idset() setof integer Набор значений идентификато-
ров активных в настоящий мо-
710Мониторинг работы СУБД
Функция Тип результата Описание
мент серверных процессов (от
1 до числа активных серверных
процессов)
pg_stat_get_backend_
activity(integer) text Текст последнего запроса этого
серверного процесса
pg_stat_get_backend_
activity_start(integer) timestamp with time zone Время запуска последнего за-
проса
pg_stat_get_backend_
client_addr(integer) inet IP-адрес клиента, подключённо-
го к этому серверному процессу
pg_stat_get_backend_
client_port(integer) integer Номер TCP-порта, который кли-
ент использует для взаимодей-
ствия
pg_stat_get_backend_
dbid(integer) oid OID базы данных, к которой под-
ключён этот серверный процесс
pg_stat_get_backend_pid(
integer) integer Идентификатор процесса этого
серверного процесса
pg_stat_get_backend_
start(integer) timestamp with time zone Время запуска этого процесса
pg_stat_get_backend_
userid(integer) oid OID пользователя, подключён-
ного к этому серверному про-
цессу
pg_stat_get_backend_
wait_event_type(integer) text Имя типа ожидаемого события,
если обслуживающий процесс
находится в состоянии ожида-
ния, а в противном случае —
NULL. За подробностями обра-
титесь к Таблице 28.4.
pg_stat_get_backend_
wait_event(integer) text Имя ожидаемого события, ес-
ли обслуживающий процесс на-
ходится в состоянии ожидания,
а в противном случае — NULL.
За подробностями обратитесь к
Таблице 28.4.
pg_stat_get_backend_
xact_start(integer) timestamp with time zone Время начала текущей транзак-
ции
28.3. Просмотр информации о блокировках
Ещё одним удобным средством для отслеживания работы базы данных является системная таб-
лица pg_locks. Она позволяет администратору базы просматривать информацию об имеющихся
блокировках в менеджере блокировок. Например, это может использоваться для:
• просмотра всех имеющихся на данный момент блокировок, всех блокировок на отношения в
определённой базе данных, всех блокировок на определённое отношение или всех блокиро-
вок, которые удерживает определённая сессия PostgreSQL.
• определения отношения в текущей базе данных с наибольшим количеством неразрешённых
блокировок (оно может быть причиной конкуренции между клиентами базы данных).
• определения воздействия конкуренции за блокировку на производительность базы данных в
целом, а так же то, как меняется конкуренция в зависимости от загруженности базы.
Более детально представление pg_locks описано в Разделе 52.73. Более подробную информацию
о блокировках и управлению параллельным доступом в PostgreSQL можно получить в Главе 13.
711Мониторинг работы СУБД
28.4. Отслеживание выполнения
PostgreSQL имеет возможность отслеживать выполнение определённых команд. В настоящее вре-
мя такое отслеживание поддерживает только команда VACUUM, но в будущем сфера его применения
может быть расширена.
28.4.1. Отслеживание выполнения VACUUM
Во время выполнения VACUUM представление pg_stat_progress_vacuum будет содержать по одной
строке для каждого обслуживающего процесса (включая рабочие процессы автоочистки), произ-
водящего очистку. Таблицы ниже показывают, какая информация будет отслеживаться, и расска-
зывают, как её интерпретировать. В настоящее время отслеживание выполнения не поддержива-
ется для команды VACUUM FULL, так что процессы, выполняющие VACUUM FULL, не будут видны в
этом представлении.
Таблица 28.21. Представление pg_stat_progress_vacuum
Столбец Тип Описание
pid integer Идентификатор (PID) этого об-
служивающего процесса
datid oid OID базы данных, к которой под-
ключён этот обслуживающий
процесс.
datname name Имя базы данных, к которой
подключён этот обслуживаю-
щий процесс.
relid oid OID очищаемой таблицы.
phase text Текущая фаза очистки. См. Таб-
лицу 28.22.
heap_blks_total bigint Общее число блоков кучи в таб-
лице. Это число отражает со-
стояние в начале сканирова-
ния; блоки, добавленные позже,
не будут (и не должны) обра-
батываться текущей командой
VACUUM.
heap_blks_scanned bigint Число просканированных бло-
ков кучи. Так как для оптими-
зации сканирования применя-
ется карта видимости, некото-
рые блоки могут пропускаться
без осмотра; пропущенные бло-
ки входят в это общее число, так
что по завершении очистки это
число станет равно heap_blks_
total . Этот счётчик увеличи-
вается только в фазе scanning
heap.
heap_blks_vacuumed bigint Число очищенных блоков ку-
чи. Если в таблице нет индек-
сов, этот счётчик увеличива-
ется только в фазе vacuuming
heap (очистка кучи). Блоки, не
содержащие «мёртвых» корте-
жей, при этом пропускаются,
712Мониторинг работы СУБД
Столбец Тип Описание
так что этот счётчик иногда
может увеличиваться резкими
рывками.
index_vacuum_count bigint Количество завершённых цик-
лов очистки индекса.
max_dead_tuples bigint Число «мёртвых» кортежей, ко-
торое мы можем сохранить,
прежде чем потребуется вы-
полнить цикл очистки индекса,
в зависимости от maintenance_
work_mem.
num_dead_tuples bigint Число «мёртвых» кортежей, со-
бранных со времени последнего
цикла очистки индекса.
Таблица 28.22. Фазы VACUUM
Фаза Описание
initializing Инициализация — VACUUM готовится начать ска-
нирование кучи. Эта фаза должна быть очень
быстрой.
scanning heap Сканирование кучи — VACUUM в настоящее время
сканирует кучу. При этом будет очищена и, если
требуется, дефрагментирована каждая страни-
ца, а возможно, также будет произведена замо-
розка. Отслеживать процесс сканирования мож-
но, следя за содержимым столбца heap_blks_
scanned .
vacuuming indexes Очистка индексов — VACUUM в настоящее вре-
мя очищает индексы. Если у таблицы есть ка-
кие-либо индексы, эта фаза будет наблюдаться
минимум единожды в процессе очистки, после
того, как куча будет просканирована полностью.
Она может повторяться несколько раз в процес-
се очистки, если объёма maintenance_work_mem
оказывается недостаточно для сохранения всех
найденных «мёртвых» кортежей.
vacuuming heap Очистка кучи — VACUUM в настоящее время очи-
щает кучу. Очистка кучи отличается от скани-
рования, так как она происходит после каждой
операции очистки индексов. Если heap_blks_
scanned меньше чем heap_blks_total , систе-
ма вернётся к сканированию кучи после завер-
шения этой фазы; в противном случае она нач-
нёт уборку индексов.
cleaning up indexes Уборка индексов — VACUUM в настоящее время
производит уборку в индексах. Это происходит
после завершения полного сканирования кучи и
очистки индексов и кучи.
truncating heap Усечение кучи — VACUUM в настоящее время усе-
кает кучу, чтобы возвратить операционной си-
стеме объём пустых страниц в конце отношения.
Это происходит после уборки индексов.
713Мониторинг работы СУБД
Фаза Описание
performing final cleanup Выполнение окончательной очистки — VACUUM
выполняет окончательную очистку. На этой ста-
дии VACUUM очищает карту свободного простран-
ства, обновляет статистику в pg_class и пе-
редаёт статистику сборщику статистики, После
этой фазы VACUUM завершит свою работу.
28.5. Динамическая трассировка
PostgreSQL позволяет выполнять динамическую трассировку сервера базы данных. Имеющиеся
возможности позволяют вызывать внешнюю утилиту в определённых точках кода и таким образом
отслеживать его выполнение.
Несколько подобных точек сбора метрик, или точек трассировки, уже встроено в исходный код.
Предполагается, что эти точки будут использоваться разработчиками и администраторами базы
данных. По умолчанию точки трассировки не входят в сборку PostgreSQL; пользователь должен
явно указать конфигурационному скрипту необходимость включения этих макросов.
В настоящее время поддерживается только утилита DTrace, которая доступна для Solaris, macOS,
FreeBSD, NetBSD и Oracle Linux. Проект SystemTap для Linux представляет собой эквивалент
DTrace и также может быть использован. Теоретически возможна поддержка и других утилит
динамической трассировки, для этого необходимо изменить определения для макроса в src/
include/utils/probes.h.
28.5.1. Компиляция для включения динамической трассировки
По умолчанию точки трассировки недоступны, поэтому в конфигурационном скрипте PostgreSQL
требуется явно указать необходимость их подключения. Для поддержки утилиты DTrace укажите
–enable-dtrace в конфигурационном файле. Более подробно смотрите Раздел 16.4.
28.5.2. Встроенные точки трассировки
В исходный код входит несколько стандартных точек трассировки, которые представлены в Табли-
це 28.23; в Таблице 28.24 показаны типы данных, которые используются для этих точек. Конечно,
для более детального отслеживания работы PostgreSQL можно добавлять и другие точки трасси-
ровки.
Таблица 28.23. Встроенные точки трассировки DTrace
Имя Параметры Описание
transaction-start (LocalTransactionId) Срабатывает в начале новой
транзакции. arg0 задаёт иден-
тификатор транзакции.
transaction-commit (LocalTransactionId) Срабатывает при успешном за-
вершении транзакции. arg0 за-
даёт идентификатор транзак-
ции.
transaction-abort (LocalTransactionId) Срабатывает, когда транзакция
завершается с ошибкой. arg0
задаёт идентификатор транзак-
ции.
query-start (const char *) Срабатывает, когда начинается
обработка запроса. arg0 задаёт
текст запроса.
query-done (const char *) Срабатывает по завершении об-
работки запроса. arg0 задаёт
текст запроса.
714Мониторинг работы СУБД
Имя Параметры Описание
query-parse-start (const char *) Срабатывает, когда начинает-
ся разбор запроса. arg0 задаёт
текст запроса.
query-parse-done (const char *) Срабатывает по завершении
разбора (parsing) запроса. arg0
задаёт текст запроса.
query-rewrite-start (const char *) Срабатывает, когда начинается
модификация запроса. arg0 за-
даёт текст запроса.
query-rewrite-done (const char *) Срабатывает по завершении мо-
дификации запроса. arg0 задаёт
текст запроса.
query-plan-start () Срабатывает, когда начинает
работать планировщик выпол-
нения запроса.
query-plan-done () Срабатывает по завершении ра-
боты планировщика запроса.
query-execute-start () Срабатывает, когда начинается
выполнение запроса.
query-execute-done () Срабатывает по завершении вы-
полнения запроса.
statement-status (const char *) Срабатывает каждый раз, ко-
гда серверный процесс обнов-
ляет свой статус в pg_stat_
activity .status. arg0 задаёт
новую строку состояния.
checkpoint-start (int) Срабатывает в начале контроль-
ной точки. arg0 содержит би-
товые флаги, с помощью ко-
торых задаются разные типы
контрольных точек, такие как
shutdown, immediate или force.
checkpoint-done (int,
int) clog-checkpoint-start (bool) Срабатывает, когда начинает-
ся запись контрольной точки в
CLOG. arg0 = true для обыч-
ных контрольных точек и false
для контрольных точек типа
shutdown.
clog-checkpoint-done (bool) Срабатывает по завершении
записи контрольной точки в
int,
715
int,
int,
Срабатывает по завершении
контрольной точки. (Перечис-
ленные далее точки трассиров-
ки срабатывают последователь-
но при обработке контрольной
точки.) arg0 задаёт число запи-
санных буферов. arg1 — общее
число буферов. arg2, arg3 и arg4
задают число файлов WAL, ко-
торые были добавлены, удале-
ны или переработаны, соответ-
ственно.Мониторинг работы СУБД
Имя Параметры Описание
CLOG. Значение arg0 задаётся
аналогично значению для clog-
checkpoint-start.
subtrans-checkpoint-start (bool) Срабатывает, когда начинает-
ся запись контрольной точки
в SUBTRANS. arg0 = true для
обычных контрольных точек и
false для контрольных точек ти-
па shutdown.
subtrans-checkpoint-done (bool) Срабатывает по завершении
записи контрольной точки в
SUBTRANS. Значение arg0 зада-
ётся аналогично значению для
subtrans-checkpoint-start.
multixact-checkpoint-start (bool) Срабатывает, когда начинает-
ся запись контрольной точки
в MultiXact. arg0 = true для
обычных контрольных точек и
false для контрольных точек ти-
па shutdown.
multixact-checkpoint-done (bool) Срабатывает по завершении
записи контрольной точки в
MultiXact. Значение arg0 зада-
ётся аналогично значению для
multixact-checkpoint-start.
buffer-checkpoint-start (int) Срабатывает, когда начинает-
ся запись буферов контрольной
точки. arg0 содержит битовые
флаги, с помощью которых за-
даются разные типы контроль-
ных точек, такие как shutdown,
immediate или force.
buffer-sync-start (int, int) Срабатывает во время кон-
трольной точки, когда начина-
ется запись грязных буферов (
после нахождения буферов, ко-
торые должны быть записаны).
arg0 задаёт общее число буфе-
ров. arg1 задаёт число буферов,
которые в настоящий момент
являются грязными и должны
быть записаны.
buffer-sync-written (int) Срабатывает после записи каж-
дого буфера при выполнении
контрольной точки. arg0 задаёт
идентификатор буфера.
buffer-sync-done (int, int, int) Срабатывает после записи всех
грязных буферов. arg0 задаёт
общее число буферов. arg1 зада-
ёт число буферов, которые фак-
тически были записаны процес-
сом выполнения контрольной
точки. arg2 задаёт число буфе-
716Мониторинг работы СУБД
Имя
Параметры
Описание
ров, которое должно было быть
записано (arg1 из buffer-sync-
start); разные значения гово-
рят о том, что во время выпол-
нения этой контрольной точки
буферы сбрасывались другими
процессами.
buffer-checkpoint-sync-start () Срабатывает после записи гряз-
ных буферов в ядро и до начала
формирования запросов fsync.
buffer-checkpoint-done () Срабатывает по завершении
синхронизации буферов с дис-
ком.
twophase-checkpoint-start () Срабатывает, когда начинает-
ся двухфазный этап выполне-
ния контрольной точки.
twophase-checkpoint-done () Срабатывает по завершении
двухфазного этапа выполнения
контрольной точки.
buffer-read-start (ForkNumber,
Oid, Oid,
bool) BlockNumber,
Oid, int, Срабатывает, когда начинается
чтение из буфера. arg0 и arg1
содержат номер слоя и бло-
ка этой страницы (arg1 будет
иметь значение -1, если выпол-
няется запрос на расширение
места для таблицы). arg2, arg3
и arg4 содержат OID-ы таблич-
ного пространства, базы дан-
ных и отношения, которые од-
нозначно идентифицируют от-
ношение. arg5 для локального
буфера задаёт идентификатор
серверного процесса, создавше-
го временное отношение, или
InvalidBackendId (-1) — для
разделяемого буфера. arg6 =
true для запросов на расшире-
ние места для таблицы, false —
в случае обычного чтения.
buffer-read-done (ForkNumber,
Oid, Oid,
bool, bool) BlockNumber,
Oid, int, Срабатывает по завершении
чтения буфера. arg0 и arg1 со-
держат номер слоя и номер бло-
ка этой страницы (arg1 будет со-
держать номер только что до-
бавленного блока, если выпол-
няется запрос на расширение
места для таблицы). arg2, arg3
и arg4 содержат OID-ы таблич-
ного пространства, базы дан-
ных и отношения, которые од-
нозначно идентифицируют от-
ношение. arg5 для локального
буфера задаёт идентификатор
серверного процесса, создавше-
717Мониторинг работы СУБД
Имя Параметры Описание
го временное отношение, или
InvalidBackendId (-1) — для
разделяемого буфера. arg6 =
true для запросов на расшире-
ние места для таблицы, false — в
случае обычного чтения. arg7 =
true, если буфер был обнаружен
в пуле, false — если нет.
buffer-flush-start (ForkNumber, BlockNumber,
Oid, Oid, Oid) Срабатывает перед формирова-
нием любого запроса на за-
пись в разделяемый буфер. arg0
и arg1 содержат номер слоя
и номер блока этой страницы.
arg2, arg3 и arg4 содержат OID-
ы табличного пространства, ба-
зы данных и отношения, кото-
рые однозначно идентифициру-
ют отношение.
buffer-flush-done (ForkNumber, BlockNumber,
Oid, Oid, Oid) Срабатывает по завершении за-
проса на запись. (Учтите, что
это отражает только момент пе-
редачи данных в ядро; обычно
на диск они ещё не записаны.)
Аргументы аналогичны buffer-
flush-start.
buffer-write-dirty-start (ForkNumber, BlockNumber,
Oid, Oid, Oid) Срабатывает, когда серверный
процесс начинает запись гряз-
ного буфера. (Частое повторе-
ние такой пробы означает, что
значение shared_buffers слиш-
ком мало или что необходи-
мо откорректировать управляю-
щие параметры процесса фоно-
вой записи.) arg0 и arg1 содер-
жат номер слоя и блока этой
страницы. arg2, arg3 и arg4 со-
держат OID-ы табличного про-
странства, базы данных и от-
ношения, которые однозначно
идентифицируют отношение.
buffer-write-dirty-done (ForkNumber, BlockNumber,
Oid, Oid, Oid) Срабатывает по завершении за-
писи грязного буфера. Аргумен-
ты аналогичны buffer-write-
dirty-start.
wal-buffer-write-dirty-start () Срабатывает, когда серверный
процесс начинает запись гряз-
ного WAL буфера из-за того, что
свободные WAL буферы закон-
чились. (Частое повторение та-
кой ситуации означает, что зна-
чение wal_buffers слишком ма-
ло.)
wal-buffer-write-dirty-done Срабатывает по завершении за-
писи грязного WAL буфера.
()
718Мониторинг работы СУБД
Имя Параметры wal-insert (unsigned
char) wal-switch () Срабатывает при запросе на пе-
реключение сегмента WAL.
smgr-md-read-start (ForkNumber, BlockNumber,
Oid, Oid, Oid, int) Срабатывает, когда начинает-
ся чтение блока из отноше-
ния. arg0 and arg1 содержат
номер слоя и номер блока
этой страницы. arg2, arg3 и
arg4 содержат OID-ы таблич-
ного пространства, базы дан-
ных и отношения, которые од-
нозначно идентифицируют от-
ношение. arg5 для локального
буфера задаёт идентификатор
серверного процесса, создавше-
го временное отношение, или
InvalidBackendId (-1) для раз-
деляемого буфера.
smgr-md-read-done (ForkNumber, BlockNumber,
Oid, Oid, Oid, int, int,
int) Срабатывает по завершении
чтения блока. arg0 и arg1 со-
держат номер слоя и номер
блока страницы. arg2, arg3 и
arg4 содержат OID-ы таблич-
ного пространства, базы дан-
ных и отношения, которые од-
нозначно идентифицируют от-
ношение. arg5 для локально-
го буфера задаёт идентифика-
тор серверного процесса, со-
здавшего временное отноше-
ние, или InvalidBackendId (-1)
— для разделяемого буфера.
arg6 задаёт количество факти-
чески прочитанных байтов, то-
гда как arg7 задаёт количество
запрошенных байтов (различия
говорят о наличии проблемы).
smgr-md-write-start (ForkNumber, BlockNumber,
Oid, Oid, Oid, int) Срабатывает, когда начинается
запись блока в отношение. arg0
и arg1 содержат номер слоя
и номер блока этой страницы.
arg2, arg3 и arg4 содержат OID-
ы табличного пространства, ба-
зы данных и отношения, ко-
торые однозначно идентифици-
руют отношение. arg5 для ло-
кального буфера задаёт иденти-
фикатор серверного процесса,
создавшего временное отноше-
char,
719
Описание
unsigned
Срабатывает при добавлении
записи в WAL. arg0 задаёт иден-
тификатор менеджера ресурсов
(rmid) для этой записи. arg1 за-
даёт информационные флаги.Мониторинг работы СУБД
Имя Параметры Описание
ние, или InvalidBackendId (-1)
— для разделяемого буфера.
smgr-md-write-done (ForkNumber, BlockNumber,
Oid, Oid, Oid, int, int,
int) Срабатывает по завершении за-
писи блока. arg0 и arg1 содер-
жат номер слоя и номер бло-
ка этой страницы. arg2, arg3
и arg4 содержат OID-ы таблич-
ного пространства, базы дан-
ных и отношения, которые од-
нозначно идентифицируют от-
ношение. arg5 для локального
буфера задаёт идентификатор
серверного процесса, создавше-
го временное отношение, или
InvalidBackendId (-1) — для
разделяемого буфера. arg6 за-
даёт количество фактически за-
писанных байтов, тогда как arg7
задаёт количество запрошен-
ных байтов (различия говорят о
наличии проблемы).
sort-start (int, bool,
bool, int) Срабатывает, когда начинается
операция сортировки. arg0 за-
даёт сортировку таблицы, ин-
декса или элемента данных.
arg1 = true, если данные ожи-
даются уникальными. arg2 за-
даёт число ключевых столбцов.
arg3 задаёт объём доступной
рабочей памяти в килобайтах.
arg4 = true, если требуется про-
извольный доступ к результа-
ту сортировки. В arg5 значение
0 указывает на последователь-
ный процесс, 1 — на параллель-
ный, а 2 показывает, что это ве-
дущий процесс в параллельной
сортировке.
sort-done (bool, long) Срабатывает по завершении
сортировки. arg0 = true для
внешней сортировки, false —
для внутренней сортировки.
arg1 задаёт число дисковых бло-
ков, использованных для внеш-
ней сортировки, или объём па-
мяти, использованной для внут-
ренней сортировки, в килобай-
тах.
lwlock-acquire (char *, LWLockMode) Срабатывает, когда выдаётся
блокировка LWLock. В arg0 пе-
редаётся транш блокировки, в
arg1 запрошенный режим бло-
кировки (исключительная или
разделяемая).
720
int,
int,Мониторинг работы СУБД
Имя Параметры Описание
lwlock-release (char *) Срабатывает, когда блокиров-
ка LWLock освобождается (но
учтите, что никакие ждущие
процессы ещё не пробуждены).
В arg0 передаётся транш блоки-
ровки.
lwlock-wait-start (char *, LWLockMode) Срабатывает, когда блокировка
LWLock не доступна моменталь-
но, и серверный процесс начал
ожидать её доступности. В arg0
передаётся транш блокировки,
в arg1 запрошенный режим бло-
кировки (исключительная или
разделяемая).
lwlock-wait-done (char *, LWLockMode) Срабатывает, когда серверный
процесс прекращает ожидание
блокировки LWLock (но саму
блокировку он ещё не получил).
В arg0 передаётся транш блоки-
ровки, в arg1 запрошенный ре-
жим блокировки (исключитель-
ная или разделяемая).
lwlock-condacquire (char *, LWLockMode) Срабатывает, когда блокировка
LWLock была успешно получе-
на процессом, запросившим её
в режиме без ожидания. В arg0
передаётся транш блокировки,
в arg1 запрошенный режим бло-
кировки (исключительная или
разделяемая).
lwlock-condacquire-fail (char *, LWLockMode) Срабатывает, когда блокировка
LWLock не была успешно полу-
чена процессом, запросившим
её в режиме без ожидания. В
arg0 передаётся транш блоки-
ровки, в arg1 запрошенный ре-
жим блокировки (исключитель-
ная или разделяемая).
lock-wait-start (unsigned
int,
unsigned
int, unsigned int, unsigned
int,
unsigned
int,
LOCKMODE) Срабатывает, когда запрос на
тяжёлую блокировку (блоки-
ровку lmgr) переходит в состо-
яние ожидания, поскольку бло-
кировка недоступна. Аргумен-
ты с arg0 до arg3 задают атрибу-
ты, идентифицирующие объект,
на который накладывается бло-
кировка. arg4 задаёт тип объек-
та, на который накладывается
блокировка. arg5 задаёт тип за-
прошенной блокировки.
lock-wait-done (unsigned
int,
unsigned
int, unsigned int, unsigned
int,
unsigned
int,
LOCKMODE) Срабатывает, когда запрос на
тяжёлую блокировку (блоки-
ровку lmgr) выходит из состо-
яния ожидания (т. е. получает
721Мониторинг работы СУБД
Имя Параметры Описание
блокировку). Аргументы анало-
гичны lock-wait-start.
deadlock-found () Срабатывает, когда детектор
взаимных блокировок обнару-
живает такую взаимную блоки-
ровку
Таблица 28.24. Предопределённые типы, используемые в параметрах точек трассировки
Тип Определение
LocalTransactionId unsigned int
LWLockMode int
LOCKMODE int
BlockNumber unsigned int
Oid unsigned int
ForkNumber int
bool char
28.5.3. Использование точек трассировки
В приведённом ниже примере показан скрипт DTrace для анализа числа транзакций в системе,
который можно использовать в качестве альтернативы созданию снимка данных pg_stat_database
до и после выполнения теста производительности:
#!/usr/sbin/dtrace -qs
postgresql$1:::transaction-start
{
@start[“Start”] = count();
self-&gt;ts = timestamp;
}
postgresql$1:::transaction-abort
{
@abort[“Abort”] = count();
}
postgresql$1:::transaction-commit
/self-&gt;ts/
{
@commit[“Commit”] = count();
@time[“Total time (ns)”] = sum(timestamp - self-&gt;ts);
self-&gt;ts=0;
}
При выполнении этот D-скрипт возвращает результат вида:</p>
<h1 id="txn_countd-pgrep--n-postgres-or-txn_countd-">./txn_count.d <code class="highlighter-rouge">pgrep -n postgres</code> or ./txn_count.d <PID></PID></h1>
<p>^C
Start
Commit
Total time (ns)
71
70
2312105013
722Мониторинг работы СУБД
Примечание
SystemTap использует отличную от DTrace нотацию для скриптов трассировки, хотя
лежащие в их основе точки трассировки совместимы. Стоит отметить, что на момент
написания этой главы в скриптах SystemTap имена точек трассировки должны обрам-
ляться двойными подчёркиваниями, а не дефисами. Ожидается, что эта проблема бу-
дет решена в следующих версиях SystemTap.
Необходимо помнить, что скрипты DTrace должны быть аккуратно написаны и отлажены, в про-
тивном случае собранная трассировочная информация может оказаться бессмысленной. В боль-
шинстве случаев причиной обнаруженных проблем является инструментарий, а не сама система.
Отправляя на рассмотрение данные, полученные с использованием динамической трассировки,
обязательно прилагайте скрипт, с помощью которого они были получены, для того чтобы его также
проверить и обсудить.
28.5.4. Задание новых точек трассировки
Новые точки трассировки разработчик может определить в любом участке кода, однако это по-
требует перекомпиляции. Ниже приведены шаги, необходимые для добавления новых точек трас-
сировки:</p>
<ol>
  <li>Определить имена точек трассировки и данные, которые будут доступны в этих точках</li>
  <li>Добавить описание точек трассировки в src/backend/utils/probes.d</li>
  <li>Включить pg_trace.h, если его ещё не использовали в модуле (модулях), содержащих точки
трассировки, и вставить TRACE_POSTGRESQL отладочные макросы в нужные места исходного ко-
да</li>
  <li>Перекомпилировать и убедиться в доступности новых точек трассировки
Пример:  Вот пример того, как можно добавить точку для трассировки всех новых транзакций
по их идентификатору.</li>
  <li>Устанавливаем, что проба будет называться transaction-start и принимать параметр типа
LocalTransactionId</li>
  <li>Добавляем определение пробы в src/backend/utils/probes.d:
probe transaction__start(LocalTransactionId);
Обратите внимание на использование двойного подчёркивания в имени пробы. В скрипте
DTrace, использующем эту точку, двойное подчёркивание нужно будет заменить дефисом, по-
этому в документации для пользователей имя этой пробы — transaction-start.
3.
Во
время
компиляции
transaction__start
преобразуется
в
макрос
TRACE_POSTGRESQL_TRANSACTION_START (обратите внимание, что здесь используется одинарное
подчёркивание), который доступен в результате включения pg_trace.h. Добавим вызов мак-
роса в требуемую точку исходного кода. В данном случае это будет выглядеть приблизительно
так:
TRACE_POSTGRESQL_TRANSACTION_START(vxid.localTransactionId);
4.
После перекомпиляции и запуска нового бинарного файла используйте следующую команду
DTrace, чтобы проверить доступность только что добавленной пробы. Должен получиться ре-
зультат, подобный этому:
    <h1 id="dtrace--ln-transaction-start">dtrace -ln transaction-start</h1>
    <p>ID
PROVIDER
MODULE
18705 postgresql49878
postgres
18755 postgresql49877
postgres
18805 postgresql49876
postgres
FUNCTION NAME
StartTransactionCommand transaction-start
StartTransactionCommand transaction-start
StartTransactionCommand transaction-start
723Мониторинг работы СУБД
18855 postgresql49875
18986 postgresql49873
postgres
postgres
StartTransactionCommand transaction-start
StartTransactionCommand transaction-start
При добавлении макросов трассировки в код, написанный на языке C, необходимо позаботиться
о следующем:
• Нужно убедиться, что типы данных, определённые в параметрах пробы, совпадают с типами
данных переменных, которые используются в макросе. В противном случае компиляция за-
вершится с ошибками.
• В большинстве платформ в случае, если PostgreSQL собран с указанием –enable-dtrace, то
аргументы макроса трассировки вычисляются каждый раз, когда макрос получает управле-
ние, даже если трассировка не выполняется. Об этом не стоит беспокоиться, если вы просто
возвращаете значения небольшого числа локальных переменных. Однако избегайте использо-
вания ресурсоёмких вызовов функций в аргументах. Если это необходимо, то постарайтесь за-
щитить макрос проверкой, которая будет определять, действительно ли включена трассиров-
ка:
if (TRACE_POSTGRESQL_TRANSACTION_START_ENABLED())
TRACE_POSTGRESQL_TRANSACTION_START(some_function(…));
Каждый макрос трассировки имеет соответствующий макрос ENABLED.
724</p>
  </li>
</ol>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-027/" title="Глава 27. Конфигурация восстановления"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 27. Конфигурация восстановления"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-027/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~8 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-027/" rel="bookmark" title="Глава 27. Конфигурация восстановления" itemprop="url">Глава 27. Конфигурация восстановления</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 27. Конфигурация восстановления</p>

<p>Глава описывает параметры, задаваемые в файле recovery.conf. Они применяются лишь во время
восстановления и должны заново устанавливаться перед каждым последующим восстановлением.
После начала процесса они не могут быть изменены.
Параметры в файле recovery.conf указываются в формате name = ‘value’. Каждый параметр
должен располагаться на отдельной строке. Для строчного комментария используется хеш (#).
Чтобы включить апостроф в значение параметра, продублируйте его (‘’).
Пример файла share/recovery.conf.sample, поставляемый в рамках дистрибутива, размещён в
каталоге share/.
27.1. Параметры восстановления из архива
restore_command (string)
Это команда оболочки ОС, которая выполняется для извлечения архивного сегмента файлов
WAL. Этот параметр требуется для восстановления из архива, но необязателен для потоковой
репликации. Любое вхождение %f в строке заменяется именем извлекаемого из архива файла,
а %p заменяется на путь назначения при копировании на сервере. (Путь указывается относи-
тельно текущего рабочего каталога, т. е. относительно каталога хранения данных кластера.)
Любое вхождение %r заменяется на имя файла, в котором содержится последняя действитель-
ная точка восстановления. Это самый ранний файл, который необходимо хранить для возмож-
ности восстановления, и эту информацию можно использовать для усечения архива в целях его
минимизации. %r обычно используется при организации тёплого резерва (см. Раздел 26.2). Для
того чтобы указать символ %, продублируйте его (%%).
Обратите внимание, что команда должна возвращать ноль на выходе лишь в случае успешного
выполнения. У команды будет запрошен список имён файлов, которые отсутствуют в архиве;
в этом случае она должна возвращать ненулевой статус. Примеры:
restore_command = ‘cp /mnt/server/archivedir/%f “%p”’
restore_command = ‘copy “C:\server\archivedir\%f” “%p”’</p>
<h1 id="windows">Windows</h1>
<p>В случае прерывания команды сигналом (отличным от SIGTERM, который используется для
остановки сервера баз данных) или при возникновении ошибки оболочки (например, если ко-
манда не найдена), процесс восстановления будет остановлен и сервер не запустится.
archive_cleanup_command (string)
Этот необязательный параметр указывает команду оболочки ОС, которая будет вызываться
при каждой точке перезапуска. Назначение команды archive_cleanup_command в том, что-
бы предоставить механизм очистки от старых архивных файлов WAL, которые более не нуж-
ны на резервном сервере. Любое вхождение %r заменяется на имя файла, содержащего по-
следнюю действительную точку восстановления. Это самый ранний файл, который необхо-
димо хранить для возможности восстановления, а более старые файлы, чем %r, могут быть
безболезненно удалены. Эта информация может быть использована для усечения архива с
целью его минимизации при сохранении возможности последующего восстановления из за-
данной точки. Модуль pg_archivecleanup часто используется в качестве значения параметра
archive_cleanup_command в конфигурациях с одним резервным сервером, например:
archive_cleanup_command = ‘pg_archivecleanup /mnt/server/archivedir %r’
Стоит обратить внимание, что в конфигурациях с множеством резервных серверов, использую-
щих общий архивный каталог для восстановления, необходимо контролировать удаление фай-
лов WAL, так как для некоторых они ещё могут требоваться. Поэтому archive_cleanup_command
обычно используется при организации тёплого резерва (см. Раздел 26.2). Для того чтобы ука-
зать символ % в команде, он пишется дважды %%.
670Конфигурация восстановления
Если команда вернёт ненулевой статус завершения, то в журнал будет записано предупрежда-
ющее сообщение. В ситуации когда команда прерывается сигналом или в случае ошибки обо-
лочки ОС (например, команда не найдена), будет вызвана фатальная ошибка.
recovery_end_command (string)
Этот необязательный параметр указывает команду оболочки, которая будет выполнена едино-
жды в конце процесса восстановления. Назначение параметра recovery_end_command в предо-
ставлении механизма очистки, следующего за репликацией или восстановлением. Любое вхож-
дение %r заменяется именем файла, содержащим последнюю действительную точку восстанов-
ления, например, как в archive_cleanup_command.
Если команда вернёт ненулевой статус завершения, то в журнал будет записано предупрежда-
ющее сообщение, но при этом запуск сервера будет продолжен. За исключением случаев, когда
команда прервана сигналом или при возникновения ошибки оболочки ОС (например, команда
не найдена). В таких случаях база данных не будет запускаться.
27.2. Параметры управления восстановлением
По умолчанию процесс восстановления производится вплоть до окончания журнала WAL.
Нижеуказанные параметры могут использоваться, чтобы остановить процесс восстановления
в более ранней точке. Использоваться может только один из параметров recovery_target,
recovery_target_lsn, recovery_target_name, recovery_target_time и recovery_target_xid; если
в конфигурационном файле задано несколько параметров, будет использоваться последний.
recovery_target= ‘immediate’
Данный параметр указывает, что процесс восстановления должен завершиться, как только бу-
дет достигнуто целостное состояние, т. е. как можно раньше. При восстановлении из опера-
тивной резервной копии, это будет точкой, в которой завершился процесс резервного копиро-
вания.
Технически, это строковый параметр, но значение ‘immediate’ единственно допустимое в дан-
ный момент.
recovery_target_name (string)
Этот параметр указывает именованную точку восстановления (созданную с помощью
pg_create_restore_point()), до которой будет производиться восстановление.
recovery_target_time (timestamp)
Данный параметр указывает точку времени, вплоть до которой будет производиться восстанов-
ление. Точность этой точки останова также зависит от recovery_target_inclusive.
recovery_target_xid (string)
Параметр указывает идентификатор транзакции, вплоть до которой необходимо произвести
процедуру восстановления. Имейте в виду, что несмотря на то, что при старте идентификаторы
транзакций назначаются последовательно, завершаться они могут в ином порядке. Восстанав-
ливаемые транзакции это те, что были зафиксированы до указанной (и, возможно, включая её).
Точность точки останова также зависит от recovery_target_inclusive.
recovery_target_lsn (pg_lsn)
Данный параметр указывает LSN позиции в журнале предзаписи, до которой долж-
но выполняться восстановление. Точная позиция остановки зависит также от параметра
recovery_target_inclusive. Данный параметр принимает значение системного типа данных
pg_lsn.
Следующие параметры уточняют целевую точку восстановления и оказывают влияние на процесс
при её достижении:
671Конфигурация восстановления
recovery_target_inclusive (boolean)
Указывает на необходимость остановки сразу после (true) либо до (false) достижения
целевой точки. Применяется одновременно с recovery_target_lsn, recovery_target_time или
recovery_target_xid. Этот параметр определяет, нужно ли восстанавливать транзакции, у кото-
рых позиция в WAL (LSN), время фиксации либо идентификатор в точности совпадает с задан-
ным соответствующим значением. Значение по умолчанию — true.
recovery_target_timeline (string)
Указывает линию времени для восстановления. По умолчанию производится восстановление
той же линии времени, которая была текущей в момент создания базовой резервной копии.
Со значением latest восстанавливаться будет последняя линия времени, найденная в архиве,
что полезно для резервного сервера. Иное значение параметра может потребоваться в более
сложной ситуации повторного восстановления, когда необходимо вернуться к состоянию, ко-
торое само было достигнуто после восстановления на момент времени. Это обсуждается в Под-
разделе 25.3.5.
recovery_target_action (enum)
Указывает, какое действие должен предпринять сервер после достижения цели восстановле-
ния. Вариант по умолчанию — pause, что означает приостановку восстановления. Второй ва-
риант, promote, означает, что процесс восстановления завершится и сервер начнёт принимать
подключения. Наконец, с вариантом shutdown сервер остановится, как только цель восстанов-
ления будет достигнута.
Вариант pause позволяет выполнить запросы к базе данных и убедиться в том, что достиг-
нутая цель оказалась желаемой точкой восстановления. Для снятия с паузы нужно вызвать
pg_wal_replay_resume() (см. Таблицу 9.81), что в итоге приведёт к завершению восстановле-
ния. Если же окажется, что мы ещё не достигли желаемой точки восстановления, нужно оста-
новить сервер, установить более позднюю цель и перезапустить сервер для продолжения вос-
становления.
Вариант shutdown полезен для получения готового экземпляра сервера в желаемой точке. При
этом данный экземпляр сможет воспроизводить дополнительные записи WAL (и на самом деле
ему придётся воспроизводить записи WAL после последней контрольной точки при следующем
перезапуске).
Заметьте, что так как recovery.conf не переименовывается, когда в recovery_target_action
выбран вариант shutdown, при последующем запуске будет происходить немедленная останов-
ка, пока вы не измените конфигурацию или не удалите файл recovery.conf вручную.
Этот параметр не действует, если цель восстановления не установлена. Если не включён режим
hot_standby, значение pause действует так же, как и shutdown.
27.3. Параметры резервного сервера
standby_mode (boolean)
Указывает, является ли сервер PostgreSQL резервным или нет. Если параметр установлен в
on, то сервер не прекратит восстановление по окончании последнего архивного файла WAL, а
продолжит попытки извлечения новых сегментов WAL посредством команды restore_command
и/или через подключение к ведущему, как указано в параметре primary_conninfo.
primary_conninfo (string)
Указывает строку подключения ведомого сервера к ведущему. Строка описана в формате со-
гласно Подраздел 34.1.1. Вместо опущенных параметров подключения используются соответ-
ствующие переменные окружения (см. Раздел 34.14). Если же какие-то переменные не уста-
новлены, то используются значения по умолчанию.
672Конфигурация восстановления
Строка может содержать имя (или адрес) основного сервера и порт подключения. Также можно
указать необходимого пользователя на ведущем сервере с требуемыми привилегиями (см. Под-
раздел 26.2.5.1). Если настроена аутентификация по паролю, то его также необходимо указать.
Пароль можно указать как в строке подключения primary_conninfo, так и в файле ~/.pgpass
ведомого сервера (в качестве имени базы данных используйте replication). Не указывайте
имя базы данных среди параметров подключения primary_conninfo.
Этот параметр не действует, если standby_mode имеет значение off.
primary_slot_name (string)
Дополнительно указывает заранее созданный слот при потоковой репликации для контроля
очистки ресурсов подключённого узла (см. Подраздел 26.2.6). Этот параметр не действует, если
не указана строка подключения primary_conninfo.
trigger_file (string)
Указывает триггерный файл, наличие которого завершает работу в режиме резервирования.
Даже если это значение не установлено, существует возможность назначить резервный сервер
основным с помощью команды pg_ctl promote. Этот параметр не действует, если параметр
standby_mode имеет значение off.
recovery_min_apply_delay (integer)
По умолчанию ведомый сервер восстанавливает записи WAL ведущего настолько быстро, на-
сколько это возможно. Иногда полезно иметь возможность задать задержку при копировании
данных, например, для устранения ошибок, связанных с потерей данных. Параметр позволяет
задать эту задержку, указав период времени в миллисекундах (по умолчанию) или иных едини-
цах измерения. Например, если установить значение 5min, ведомый сервер будет воспроизво-
дить фиксацию транзакции не раньше, чем через 5 минут (судя по его системным часам) после
времени фиксации, сообщённого ведущим.
Возможна ситуация, когда задержка репликации между серверами превышает значение этого
параметра. В этом случае дополнительная задержка не добавляется. Заметьте, что задержка
вычисляется как разница между меткой времени, записанной в WAL на ведущем сервере, и
текущим временем на резервном. Запаздывание передачи, связанное с задержками в сети или
каскадной репликацией, может существенно сократить реальное время ожидания. Если время
на главном и резервном сервере не синхронизировано, это может приводить к применению
записей ранее ожидаемого, однако это не очень важно, потому что полезные значения этого
параметра намного превышают типичное расхождение во времени между двумя серверами.
Задержка применяется лишь для записей WAL, представляющих фиксацию транзакций.
Остальные записи проигрываются незамедлительно, так как их эффект не будет заметен до
применения соответствующей записи о фиксации транзакции, благодаря правилам видимости
MVCC.
Задержка добавляется, как только восстанавливаемая база данных достигает согласованного
состояния, и исключается, когда резервный сервер переключается в режим основного. С мо-
мента переключения резервный сервер завершает восстановление незамедлительно.
Данный параметр предназначен для применения в конфигурациях с потоковой репликацией;
однако, если он задан, он будет учитываться в любых случаях. Задержка, устанавливаемая этим
параметром, распространяется и на сообщения hot_standby_feedback, что может привести к
раздуванию базы на главном сервере; сочетание этих параметров требует осторожности.
Предупреждение
Этот параметр влияет на синхронную репликацию, когда synchronous_commit име-
ет значение remote_apply; каждый COMMIT будет ждать подтверждения примене-
ния.
673</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-026/" title="Глава 26. Отказоустойчивость,балансировка нагрузки и репликация"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 26. Отказоустойчивость,балансировка нагрузки и репликация"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-026/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~57 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-026/" rel="bookmark" title="Глава 26. Отказоустойчивость,балансировка нагрузки и репликация" itemprop="url">Глава 26. Отказоустойчивость,балансировка нагрузки и репликация</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 26. Отказоустойчивость,балансировка нагрузки и репликация</p>

<p>Серверы базы данных могут работать совместно для обеспечения возможности быстрого переклю-
чения на другой сервер в случае отказа первого (отказоустойчивость) или для обеспечения воз-
можности нескольким серверам БД обрабатывать один набор данных (балансировка нагрузки). В
идеале, серверы БД могут работать вместе прозрачно для клиента. Веб-серверы, обрабатывающие
статические страницы, можно совместить достаточно легко посредством простого распределения
запросов на несколько машин. Фактически серверы баз данных только для чтения тоже могут быть
совмещены достаточно легко. К сожалению, большинство серверов баз данных получают смешан-
ные запросы на чтение/запись, а серверы с доступом на чтение/запись совместить гораздо слож-
нее. Это объясняется тем, что данные только для чтения достаточно единожды разместить на каж-
дом сервере, а запись на любой из серверов должна распространиться на все остальные серверы,
чтобы будущие запросы на чтение возвращали согласованные результаты.
Проблема синхронизации является главным препятствием для совместной работы серверов. Так
как единственного решения, устраняющего проблему синхронизации во всех случаях, не суще-
ствует, предлагается несколько решений. Разные решения подходят к проблеме по-разному и ми-
нимизируют её влияние в разных рабочих условиях.
Некоторые решения применяют синхронизацию, позволяя только одному серверу изменять дан-
ные. Сервер, который может изменять данные, называется сервером чтения/записи, ведущим или
главным сервером. Сервер, который отслеживает изменения на ведущем, называется ведомым
или резервным сервером. Резервный сервер, к которому нельзя подключаться до тех пор, пока
он не будет повышен до главного, называется сервером тёплого резерва, а тот, который может
принимать соединения и обрабатывать запросы только на чтение, называется сервером горячего
резерва.
Некоторые решения являются синхронными, при которых транзакция, модифицирующая данные,
не считается подтверждённой, пока все серверы не подтвердят транзакцию. Это гарантирует, что
при отработке отказа не произойдёт потеря данных и что все балансирующие серверы возвращают
целостные данные вне зависимости от того, к какому серверу был запрос. Асинхронное решение,
напротив, допускает некоторую задержку между временем подтверждения транзакции и её пере-
дачей на другие серверы, допуская возможность, что некоторые транзакции могут быть потеряны
в момент переключения на резервный сервер и что балансирующие серверы могут вернуть слегка
устаревшие данные. Асинхронная передача используется, когда синхронная будет слишком мед-
ленной.
Решения могут так же разделяться по степени детализации. Некоторые решения работают только
на уровне всего сервера БД целиком, в то время как другие позволяют работать на уровне таблиц
или уровне БД.
В любом случае необходимо принимать во внимание быстродействие. Обычно выбирается компро-
мисс между функциональностью и производительностью. Например, полностью синхронное реше-
ние в медленной сети может снизить производительность больше чем наполовину, в то время как
асинхронное решение будет оказывать минимальное воздействие.
В продолжении этого раздела рассматриваются различные решения по организации отказоустой-
чивости, репликации и балансировки нагрузки.
26.1. Сравнение различных решений
Отказоустойчивость на разделяемых дисках
Отказоустойчивость на разделяемых дисках позволяет избежать избыточности синхронизации
путём задействования только одной копии базы данных. Она использует единственный диско-
вый массив, который разделяется между несколькими серверами. Если основной сервер БД
откажет, резервный сервер может подключиться и запустить базу данных, что позволит вос-
становить БД после аварии. Это обеспечивает быстрое переключение без потери данных.
646Отказоустойчивость, баланси-
ровка нагрузки и репликация
Функциональность разделяемого оборудования обычно реализована в сетевых устройствах хра-
нения. Так же возможно применение сетевой файловой системы; особое внимание следует уде-
лить тому, чтобы поведение системы полностью соответствовало POSIX (см. Подраздел 18.2.2).
Существенное ограничение этого метода состоит в том, что в случае отказа или порчи разде-
ляемого дискового массива оба сервера: главный и резервный — станут нерабочими. Другая
особенность — резервный сервер никогда не получает доступ к разделяемым дискам во время
работы главного.
Репликация на уровне файловой системы (блочного устройства)
Видоизменённая версия функциональности разделяемого оборудования представлена в виде
репликации на уровне файловой системы, когда все изменения в файловой системе отражают-
ся в файловой системе другого компьютера. Единственное ограничение: синхронизация долж-
на выполняться методом, гарантирующим целостность копии файловой системы на резервном
сервере — в частности, запись на резервном сервере должна происходить в том же порядке,
что и на главном. DRBD является популярным решением на основе репликации файловой си-
стемы для Linux.
Трансляция журнала предзаписи
Серверы тёплого и горячего резерва могут так же поддерживаться актуальными путём чтения
потока записей из журнала изменений (WAL). Если основной сервер отказывает, резервный
содержит почти все данные с него и может быть быстро преобразован в новый главный сервер
БД. Это можно сделать синхронно или асинхронно, но может быть выполнено только на уровне
сервера БД целиком.
Резервный сервер может быть реализован с применением трансляции файлов журналов (см.
Раздел  26.2), или потоковой репликации (см. Подраздел  26.2.5), или их комбинацией. За ин-
формацией о горячем резерве обратитесь к Разделу 26.5.
Логическая репликация
В схеме с логической репликацией сервер баз данных может передавать поток изменений дан-
ных на другой сервер. Механизм логической репликации в PostgreSQL формирует поток логи-
ческих изменений данных, обрабатывая WAL. Логическая репликация позволяет переносить
изменения, происходящие только в отдельных таблицах. Для логической репликации не требу-
ется, чтобы за определённым сервером закреплялась роль главного или реплицирующего; на-
против, данные могут передаваться в разных направлениях. За дополнительными сведениями
о логической репликации обратитесь к Главе 31. Используя интерфейс логического декодиро-
вания (Глава 49), подобную функциональность могут предоставлять и сторонние расширения.
Репликация главный-резервный на основе триггеров
При репликации главный-резервный все запросы, изменяющие данные, пересылаются главно-
му серверу. Главный сервер, в свою очередь, асинхронно пересылает изменённые данные ре-
зервному. Резервный сервер может обрабатывать запросы только на чтение при работающем
главном. Такой резервный сервер идеален для обработки запросов к хранилищам данных.
Slony-I является примером подобного типа репликации, действующей на уровне таблиц, и под-
держивает множество резервных серверов. Так как обновления на резервных серверах проис-
ходят асинхронно (в пакетах), возможна потеря данных во время отказа.
Репликация запросов в среднем слое
В схеме с репликацией запросов в среднем слое, средний слой перехватывает каждый SQL-за-
прос и пересылает его на один или все серверы. Каждый сервер работает независимо. Модифи-
цирующие запросы должны быть направлены всем серверам, чтобы каждый из них получал все
изменения. Но читающие запросы могут быть посланы только на один сервер, что позволяет
перераспределить читающую нагрузку между всеми серверами.
Если запросы просто перенаправлять без изменений, функции подобные random(),
CURRENT_TIMESTAMP и последовательности могут получить различные значения на разных сер-
верах. Это происходит потому что каждый сервер работает независимо, а эти запросы неиз-
бирательные (и действительно не изменяют строки). Если такая ситуация недопустима, или
647Отказоустойчивость, баланси-
ровка нагрузки и репликация
средний слой, или приложение должно запросить подобные значения с одного сервера, затем
использовать его в других пишущих запросах. Другим способом является применения этого
вида репликации совместно с другим традиционным набором репликации главный-резервный,
то есть изменяющие данные запросы посылаются только на главный сервер, а затем применя-
ются на резервном в процессе этой репликации, но не с помощью реплицирующего среднего
слоя. Следует иметь в виду, что все транзакции фиксируются или прерываются на всех серве-
рах, возможно с применением двухфазной фиксации (см. PREPARE TRANSACTION и COMMIT
PREPARED). Репликацию такого типа реализуют, например Pgpool-II и Continuent Tungsten.
Асинхронная репликация с несколькими главными серверами
Если серверы не находятся постоянно в единой сети, как например, ноутбуки или удалённые
серверы, обеспечение согласованности данных между ними представляет проблему. Когда ис-
пользуется асинхронная репликация с несколькими главными серверами, каждый из них ра-
ботает независимо и периодически связывается с другими серверами для определения кон-
фликтующих транзакций. Конфликты могут урегулироваться пользователем или по правилам
их разрешения. Примером такого типа репликации является Bucardo.
Синхронная репликация с несколькими главными серверами
При синхронной репликации с несколькими главными серверами каждый сервер может прини-
мать запросы на запись, а изменённые данные передаются с начального сервера всем осталь-
ным, прежде чем транзакция будет подтверждена. Если запись производится интенсивно, это
может провоцировать избыточные блокировки, что приводит к снижению производительности.
На самом деле производительность при записи часто бывает хуже, чем с одним сервером. За-
просы на чтение также могут быть обработаны любым сервером. В некоторых конфигурациях
для более эффективного взаимодействия серверов применяются разделяемые диски. Синхрон-
ная репликация с несколькими главными серверами лучше всего работает, когда преобладают
операции чтения, хотя её большой плюс в том, что любой сервер может принимать запросы на
запись — нет необходимости искусственно разделять нагрузку между главным и резервными
серверами, а так как изменения передаются от одного сервера другим, не возникает проблем
с недетерминированными функциями вроде random().
PostgreSQL не предоставляет данный тип репликации, но так как PostgreSQL поддерживает
двухфазное подтверждение транзакции (PREPARE TRANSACTION и COMMIT PREPARED) такое
поведение может быть реализовано в коде приложения или среднего слоя.
Коммерческие решения
Так как PostgreSQL обладает открытым кодом и легко расширяется, некоторые компании взяли
за основу PostgreSQL и создали коммерческие решения с закрытым кодом со своими реализа-
циями свойств отказоустойчивости, репликации и балансировки нагрузки.
Таблица 26.1 итоговая таблица возможностей различных решений приведена ниже.
Таблица 26.1. Таблица свойств отказоустойчивости, балансировки нагрузки и репликации
Тип
Наиболее
типичные
реализа-
ции
Отказо-
устойчи-
вость че-
рез раз-
деляе-
мые дис-
ки Реплика-
ция фай-
ловой
системы
NAS DRBD
Трансля-
ция жур-
нала
предза-
писи
Логиче-
ская ре-
плика-
ция
Реплика-
ция
глав-
ный-ре-
зервный
на осно-
ве триг-
геров
встроен- встроен- Londiste,
ная пото- ная логи-
Slony
ковая ре-
ческая
пликация репли-
кация,
pglogical
648
Реплика-
ция за-
просов в
среднем
слое Асин-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами Син-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами
pgpool-II Bucardo  Отказоустойчивость, баланси-
ровка нагрузки и репликация
Тип
Отказо-
устойчи-
вость че-
рез раз-
деляе-
мые дис-
ки Реплика-
ция фай-
ловой
системы Трансля-
ция жур-
нала
предза-
писи Логиче-
ская ре-
плика-
ция Реплика-
ция
глав-
ный-ре-
зервный
на осно-
ве триг-
геров Реплика-
ция за-
просов в
среднем
слое Асин-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами Син-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами
Метод
взаимо-
действия разде-
ляемые
диски дисковые
блоки WAL логиче-
ское де-
кодиро-
вание Строки
таблицы SQL Строки
таблицы Строки
табли-
цы и бло-
киров-
ки строк
Не требу-
ется спе-
циально-
го обору-
дования   • • • • • • •
Допуска-
ется
несколь-
ко глав-
ных сер-
веров       •   • • •
Нет избы-
точности
главного
сервера •   • •   •  <br />
Нет
за-
держки
при
несколь-
ких серве-
рах •   без
синхр. без
синхр. •   •<br />
Отказ
главного
сервера
не
мо-
жет при-
вести
к
потере
данных • • с синхр. с синхр.   •   •
Сервер
реплики
принима-
ет чита-
ющие за-
просы     с горя-
чим ре-
зервом • • • • •
Реплика-
ция
на
уровне
таблиц       • •   • •
649Отказоустойчивость, баланси-
ровка нагрузки и репликация
Тип
Не требу-
ется раз-
решение
конфлик-
тов
Отказо-
устойчи-
вость че-
рез раз-
деляе-
мые дис-
ки Реплика-
ция фай-
ловой
системы Трансля-
ция жур-
нала
предза-
писи Логиче-
ская ре-
плика-
ция Реплика-
ция
глав-
ный-ре-
зервный
на осно-
ве триг-
геров Реплика-
ция за-
просов в
среднем
слое Асин-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами Син-
хронная
реплика-
ция
с
несколь-
кими
главны-
ми сер-
верами
• • •   •     •
Несколько решений, которые не подпадают под указанные выше категории:
Секционирование данных
При секционировании таблицы расщепляются на наборы данных. Каждый из наборов может
быть изменён только на одном сервере. Например, данные могут быть секционированы по офи-
сам, например, Лондон и Париж, с сервером в каждом офисе. В случае необходимости обра-
щения одновременно к данным Лондона и Парижа, приложение может запросить оба сервера,
или может быть применена репликация главный-резервный для предоставления копии только
для чтения в другом офисе для каждого из серверов.
Выполнение параллельных запросов на нескольких серверах
Многие из указанных выше решений позволяют обрабатывать несколько запросов на несколь-
ких серверах, но ни один из них не может обрабатывать один запрос с применением нескольких
серверов для уменьшения общего времени выполнения. Подобное решение позволяет несколь-
ким серверам обрабатывать один запрос одновременно. Такое обычно достигается путём раз-
деления данных между серверами, обработкой на сервере своей части запроса с возвратом ре-
зультата на центральный сервер. Там данные проходят окончательную обработку и возвраща-
ются пользователю. Pgpool-II предоставляет такую возможность. Так же это может быть реа-
лизовано с применением набора средств PL/Proxy.
26.2. Трансляция журналов на резервные серверы
Постоянная архивация может использоваться для создания кластерной конфигурации высокой
степени доступности (HA) с одним или несколькими резервными серверами, способными заме-
нить ведущий сервер в случае выхода его из строя. Такую реализацию отказоустойчивости часто
называют тёплый резерв или трансляция журналов.
Ведущий и резервный серверы работают совместно для обеспечения этой возможности, при этом
они связаны опосредованно. Ведущий сервер работает в режиме постоянной архивации измене-
ний, в то время как каждый резервный сервер работает в режиме постоянного приема архивных
изменений, зачитывая WAL-файлы с ведущего. Для обеспечения этой возможности не требуется
вносить изменения в таблицы БД, что требует существенно меньших административных издержек
в сравнении с некоторыми другими решениями репликации. Так же такая конфигурация относи-
тельно слабо влияет на производительность ведущего сервера.
Непосредственную передачу записей WAL с одного сервера БД на другой обычно называют транс-
ляцией журналов (или доставкой журналов). PostgreSQL реализует трансляцию журналов на уров-
не файлов, передавая записи WAL по одному файлу (сегменту WAL) единовременно. Файлы WAL
(размером 16 МБ) можно легко и эффективно передать на любое расстояние, будь то соседний
сервер, другая система в местной сети или сервер на другом краю света. Требуемая пропускная
способность при таком подходе определяется скоростью записи транзакций на ведущем сервере.
Трансляция журналов на уровне записей более фрагментарная операция, при которой изменения
WAL передаются последовательно через сетевое соединение (см. Подраздел 26.2.5).
650Отказоустойчивость, баланси-
ровка нагрузки и репликация
Следует отметить, что трансляция журналов асинхронна, то есть записи WAL доставляются после
завершения транзакции. В результате образуется окно, когда возможна потеря данных при отказе
сервера: будут утеряны ещё не переданные транзакции. Размер этого окна при трансляции файлов
журналов может быть ограничен параметром archive_timeout, который может принимать значе-
ние меньше нескольких секунд. Тем не менее подобные заниженные значения могут потребовать
существенного увеличения пропускной способности, необходимой для трансляции файлов. При
потоковой репликации (см. Подраздел 26.2.5) окно возможности потери данных гораздо меньше.
Скорость восстановления достаточно высока, обычно резервный сервер становится полностью до-
ступным через мгновение после активации. В результате такое решение называется тёплым ре-
зервом, что обеспечивает отличную отказоустойчивость. Восстановление сервера из архивной ко-
пии базы и применение изменений обычно происходит существенно дольше. Поэтому такие дей-
ствия обычно требуются при восстановлении после аварии, не для отказоустойчивости. Так же
резервный сервер может обрабатывать читающие запросы. В этом случае он называется сервером
горячего резерва. См. Раздел 26.5 для подробной информации.
26.2.1. Планирование
Обычно разумно подбирать ведущий и резервный серверы так, чтобы они были максимально по-
хожи, как минимум с точки зрения базы данных. Тогда в частности, пути, связанные с табличны-
ми пространствами, могут передаваться без изменений. Таким образом, как на ведущем, так и на
резервных серверах должны быть одинаковые пути монтирования для табличных пространств при
использовании этой возможности БД. Учитывайте, что если CREATE TABLESPACE выполнена на
ведущем сервере, новая точка монтирования для этой команды уже должна существовать на ре-
зервных серверах до её выполнения. Аппаратная часть не должна быть в точности одинаковой, но
опыт показывает, что сопровождать идентичные системы легче, чем две различные на протяже-
нии жизненного цикла приложения и системы. В любом случае архитектура оборудования должна
быть одинаковой — например, трансляция журналов с 32-битной на 64-битную систему не будет
работать.
В общем случае трансляция журналов между серверами с различными основными версиями
PostgreSQL невозможна. Политика главной группы разработки PostgreSQL состоит в том, чтобы
не вносить изменения в дисковые форматы при обновлениях корректирующей версии, таким об-
разом, ведущий и резервный серверы, имеющие разные корректирующие версии, могут работать
успешно. Тем не менее, формально такая возможность не поддерживается и рекомендуется под-
держивать одинаковую версию ведущего и резервных серверов, насколько это возможно. При об-
новлении корректирующей версии безопаснее будет в первую очередь обновить резервные серве-
ры — новая корректирующая версия с большей вероятностью прочитает файл WAL предыдущей
корректирующей версии, чем наоборот.
26.2.2. Работа резервного сервера
Сервер, работающий в режиме резервного, последовательно применяет файлы WAL, полученные
от главного. Резервный сервер может читать файлы WAL из архива WAL (см. restore_command)
или напрямую с главного сервера по соединению TCP (потоковая репликация). Резервный сервер
также будет пытаться восстановить любой файл WAL, найденный в кластере резервного в каталоге
pg_wal. Это обычно происходит после перезапуска сервера, когда он применяет заново файлы WAL,
полученные от главного сервера перед перезапуском. Но можно и вручную скопировать файлы в
каталог pg_wal, чтобы применить их в любой момент времени.
В момент запуска резервный сервер начинает восстанавливать все доступные файлы WAL, раз-
мещённые в архивном каталоге, указанном в команде restore_command. По достижении конца до-
ступных файлов WAL или при сбое команды restore_command сервер пытается восстановить все
файлы WAL, доступные в каталоге pg_wal. Если это не удаётся и потоковая репликация настрое-
на, резервный сервер пытается присоединиться к ведущему и начать закачивать поток WAL с по-
следней подтверждённой записи, найденной в архиве или pg_wal. Если это действие закончилось
неудачей, или потоковая репликация не настроена, или соединение позднее разорвалось, резерв-
ный сервер возвращается к шагу 1 и пытается восстановить файлы из архива вновь. Цикл обраще-
651Отказоустойчивость, баланси-
ровка нагрузки и репликация
ния за файлами WAL к архиву, pg_wal, и через потоковую репликацию продолжается до остановки
сервера или переключения его роли, вызванного файлом-триггером.
Режим резерва завершается и сервер переключается в обычный рабочий режим при получении
команды pg_ctl promote или при обнаружении файла-триггера (trigger_file). Перед переклю-
чением сервер восстановит все файлы WAL, непосредственно доступные из архива или pg_wal, но
пытаться подключиться к главному серверу он больше не будет.
26.2.3. Подготовка главного сервера для работы с резервными
Настройка постоянного архивирования на ведущем сервере в архивный каталог, доступный с ре-
зервного, описана в Разделе 25.3. Расположение архива должно быть доступно с резервного сер-
вера даже при отключении главного, то есть его следует разместить на резервном или другом до-
веренном, но не на главном сервере.
При использовании потоковой репликации следует настроить режим аутентификации на ведущем
сервере, чтобы разрешить соединения с резервных. Для этого создать роль и обеспечить подходя-
щую запись в файле pg_hba.conf в разделе доступа к БД replication. Так же следует убедиться,
что для параметра max_wal_senders задаётся достаточно большое значение в конфигурационном
файле ведущего сервера. При использовании слотов для репликации также достаточно большое
значение нужно задать для max_replication_slots.
Создание базовой резервной копии, необходимой для запуска резервного сервера, описано в Под-
разделе 25.3.2.
26.2.4. Настройка резервного сервера
Для запуска резервного сервера нужно восстановить резервную копию, снятую с ведущего (см.
Подраздел 25.3.4). Затем нужно создать файл команд восстановления recovery.conf в каталоге
данных кластера резервного сервера и включить режим standby_mode. Задайте в restore_command
обычную команду копирования файлов из архива WAL. Если планируется несколько резервных
серверов в целях отказоустойчивости, установите для recovery_target_timeline значение latest,
чтобы резервный сервер переходил на новую линию времени, образуемую при отработке отказа
и переключении на другой сервер.
Примечание
Не используйте pg_standby или подобные средства со встроенным режимом резервно-
го сервера, описанным здесь. restore_command должна немедленно прекратиться при
отсутствии файла; сервер повторит команду вновь при необходимости. Использование
средств, подобных pg_standby, описано в Разделе 26.4.
При необходимости потоковой репликации заполните primary_conninfo параметрами строки со-
единения для libpq, включая имя (или IP-адрес) сервера и все остальные необходимые данные для
соединения с ведущим сервером. Если ведущий требует пароль для аутентификации, пароль мо-
жет быть так же передан в primary_conninfo.
Если резервный сервер настраивается в целях отказоустойчивости, на нём следует настроить ар-
хивацию WAL, соединения и аутентификацию, как на ведущем сервере, потому что резервный сер-
вер станет ведущим после отработки отказа.
При использовании архива WAL его размер может быть уменьшен с помощью команды в па-
раметре archive_cleanup_command, которая удаляет файлы уже не нужные для дальнейшей ра-
боты резервного сервера. Утилита pg_archivecleanup разработана специально для использова-
ния в archive_cleanup_command при типичной конфигурации с одним резервным сервером (см.
pg_archivecleanup). Следует отметить, что если архив используется в целях резервирования, сле-
дует сохранять все файлы необходимые для восстановления как минимум с последней базовой ре-
зервной копии, даже если они не нужны для резервного сервера.
652Отказоустойчивость, баланси-
ровка нагрузки и репликация
Простой пример recovery.conf:
standby_mode = ‘on’
primary_conninfo = ‘host=192.168.1.50 port=5432 user=foo password=foopass’
restore_command = ‘cp /path/to/archive/%f %p’
archive_cleanup_command = ‘pg_archivecleanup /path/to/archive %r’
Можно поддерживать любое количество резервных серверов, но при применении потоковой ре-
пликации необходимо убедиться, что значение max_wal_senders на ведущем достаточно большое,
чтобы все они могли подключиться одновременно.
26.2.5. Потоковая репликация
При потоковой репликации резервный сервер может работать с меньшей задержкой, чем при
трансляции файлов. Резервный сервер подключается к ведущему, который передаёт поток запи-
сей WAL резервному в момент их добавления, не дожидаясь окончания заполнения файла WAL.
Потоковая репликация асинхронна по умолчанию (см. Подраздел 26.2.8), то есть имеется неболь-
шая задержка между подтверждением транзакции на ведущем сервере и появлением этих изме-
нений на резервном. Тем не менее, эта задержка гораздо меньше, чем при трансляции файлов
журналов, обычно в пределах одной секунды, если резервный сервер достаточно мощный и справ-
ляется с нагрузкой. При потоковой репликации настраивать archive_timeout для уменьшения ок-
на потенциальной потери данных не требуется.
При потоковой репликации без постоянной архивации на уровне файлов, сервер может избавить-
ся от старых сегментов WAL до того, как резервный получит их. В этом случае резервный сервер
потребует повторной инициализации из новой базовой резервной копии. Этого можно избежать,
установив для wal_keep_segments достаточно большое значение, при котором сегменты WAL бу-
дут защищены от ранней очистки, либо настроив слот репликации для резервного сервера. Если
с резервного сервера доступен архив WAL, этого не требуется, так как резервный может всегда
обратиться к архиву для восполнения пропущенных сегментов.
Чтобы включить потоковую репликацию, сначала настройте резервный сервер на приём трансля-
ции журналов, как описано в Разделе  26.2. Затем сделайте следующий шаг — переключите ре-
зервный сервер в режим репликации, установив в primary_conninfo в файле recovery.conf стро-
ку подключения, указывающую на ведущий. Настройте listen_addresses и параметры аутентифи-
кации (см. pg_hba.conf) на ведущем сервере таким образом, чтобы резервный смог подключиться
к псевдобазе replication на ведущем (см. Подраздел 26.2.5.1).
В
системах,
поддерживающих
параметр
сокета
keepalive,
подходящие
значения
tcp_keepalives_idle, tcp_keepalives_interval и tcp_keepalives_count помогут ведущему вовремя заме-
тить разрыв соединения.
Установите максимальное количество одновременных соединений с резервных серверов (см. опи-
сание max_wal_senders.
При запуске резервного сервера с правильно установленным primary_conninfo резервный под-
ключится к ведущему после воспроизведения всех файлов WAL, доступных из архива. При успеш-
ном установлении соединения можно увидеть процесс walreceiver на резервном сервере и соот-
ветствующий процесс walsender на ведущем.
26.2.5.1. Аутентификация
Право использования репликации очень важно ограничить так, чтобы только доверенные поль-
зователи могли читать поток WAL, так как из него можно извлечь конфиденциальную информа-
цию. Резервный сервер должен аутентифицироваться на ведущем от имени суперпользователя или
пользователя с правом REPLICATION. Настоятельно рекомендуется создавать выделенного пользо-
вателя с правами REPLICATION и LOGIN специально для репликации. Хотя право REPLICATION даёт
очень широкие полномочия, оно не позволяет модифицировать данные в ведущей системе, тогда
как с правом SUPERUSER это можно делать.
653Отказоустойчивость, баланси-
ровка нагрузки и репликация
Список аутентификации клиентов для репликации содержится в pg_hba.conf в записях с установ-
ленным значением replication в поле database. Например, если резервный сервер запущен на
компьютере с IP-адресом 192.168.1.100 и учётная запись для репликации foo, администратор мо-
жет добавить следующую строку в файл pg_hba.conf ведущего:</p>
<h1 id="Разрешить-пользователю-foo-с-компьютера-1921681100-подключаться-к-этому">Разрешить пользователю “foo” с компьютера 192.168.1.100 подключаться к этому</h1>
<h1 id="серверу-в-качестве-партнёра-репликации-если-был-передан-правильный-пароль">серверу в качестве партнёра репликации, если был передан правильный пароль.</h1>
<p>#</p>
<h1 id="type-database">TYPE DATABASE</h1>
<p>USER
ADDRESS
METHOD
host
replication
foo
192.168.1.100/32
md5
Имя компьютера и номер порта для ведущего, имя пользователя для соединения и пароль указы-
ваются в файле recovery.conf. Пароль так же может быть задан через файл ~/.pgpass на резерв-
ном сервере (указанном в определении с replication в поле database). Например, если ведущий
принимает подключения по IP-адресу 192.168.1.50, в порту 5432, пользователя для репликации
foo с паролем foopass, то администратор может добавить следующую строку в файл recovery.conf
на резервном сервере:</p>
<h1 id="Резервный-сервер-подключается-к-ведущему-работающему-на-компьютере-192168150">Резервный сервер подключается к ведущему, работающему на компьютере 192.168.1.50</h1>
<h1 id="порт-5432-от-имени-пользователя-foo-с-паролем-foopass">(порт 5432), от имени пользователя “foo” с паролем “foopass”.</h1>
<p>primary_conninfo = ‘host=192.168.1.50 port=5432 user=foo password=foopass’
26.2.5.2. Наблюдение
Важным индикатором стабильности работы потоковой репликации является количество запи-
сей WAL, созданных на ведущем, но ещё не применённых на резервном сервере. Задержку мож-
но подсчитать, сравнив текущую позиции записи WAL на ведущем с последней позицией WAL,
полученной на резервном сервере. Эти позиции можно узнать, воспользовавшись функциями
pg_current_wal_lsn на ведущем и pg_last_wal_receive_lsn на резервном, соответственно (за по-
дробностями обратитесь к Таблице 9.79 и Таблице 9.80). Последняя полученная позиция WAL на
резервном сервере также выводится в состоянии процесса-приёмника WAL, которое показывает
команда ps (подробнее об этом в Разделе 28.1).
Список процессов-передатчиков WAL можно получить через представление pg_stat_replication.
Значительная разница между pg_current_wal_lsn и полем sent_lsn этого представления может
указывать на то, что главный сервер работает с большой нагрузкой, тогда как разница между
sent_lsn и pg_last_wal_receive_lsn на резервном может быть признаком задержек в сети или
большой нагрузки резервного сервера.
На сервере горячего резерва состояние процесса-приёмника WAL можно получить через
представление pg_stat_wal_receiver. Большая разница между pg_last_wal_replay_lsn и полем
received_lsn свидетельствует о том, что WAL поступает быстрее, чем удаётся его воспроизвести.
26.2.6. Слоты репликации
Слоты репликации автоматически обеспечивают механизм сохранения сегментов WAL, пока они
не будут получены всеми резервными и главный сервер не будет удалять строки, находящиеся в
статусе recovery conflict даже при отключении резервного.
Вместо использования слотов репликации для предотвращения удаления старых сегментов WAL
можно применять wal_keep_segments, или сохранять сегменты в архиве с помощью команды
archive_command. Тем не менее, эти методы часто приводят к тому, что хранится больше сегмен-
тов WAL, чем необходимо, в то время как слоты репликации оставляют только то количество сег-
ментов, которое необходимо. Преимущество этих методов состоит в том, что они чётко задают
объёмы места, необходимого для pg_wal; в то время как текущая реализация слотов репликации
не предоставляет такой возможности.
Подобным образом, параметры hot_standby_feedback и vacuum_defer_cleanup_age позволяют защи-
тить востребованные строки от удаления при очистке, но первый параметр не защищает в тот про-
межуток времени, когда резервный сервер не подключён, а для последнего часто нужно задавать
большое значение, чтобы обеспечить должную защиту. Слоты репликации решают эти проблемы.
654Отказоустойчивость, баланси-
ровка нагрузки и репликация
26.2.6.1. Запросы и действия слотов репликации
Каждый слот репликации обладает именем, состоящим из строчных букв, цифр и символов под-
чёркивания.
Имеющиеся слоты репликации
pg_replication_slots.
и
их
статус
можно
просмотреть
в
представлении
Слоты могут быть созданы и удалены как с помощью протокола потоковой репликации (см. Раз-
дел 53.4), так и посредством функций SQL (см. Подраздел 9.26.6).
26.2.6.2. Пример конфигурации
Для создания слота репликации выполните:
postgres=# SELECT * FROM pg_create_physical_replication_slot(‘node_a_slot’);
slot_name | lsn
————-+—–
node_a_slot |
postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots;
slot_name | slot_type | active
————-+———–+——–
node_a_slot | physical | f
(1 row)
Для настройки резервного сервера на использование этого слота primary_slot_name должно быть
настроено в конфигурации recovery.conf резервного. Вот простейший пример:
standby_mode = ‘on’
primary_conninfo = ‘host=192.168.1.50 port=5432 user=foo password=foopass’
primary_slot_name = ‘node_a_slot’
26.2.7. Каскадная репликация
Свойство каскадной репликации позволяет резервному серверу принимать соединения реплика-
ции и потоки WAL от других резервных, выступающих посредниками. Это может быть полезно для
уменьшения числа непосредственных подключений к главному серверу, а также для уменьшения
накладных расходов при передаче данных в интрасети.
Резервный сервер, выступающий как получатель и отправитель, называется каскадным резерв-
ным сервером. Резервные серверы, стоящие ближе к главному, называются серверами верхнего
уровня, а более отдалённые — серверами нижнего уровня. Каскадная репликация не накладыва-
ет ограничений на количество или организацию последующих уровней, а каждый резервный со-
единяется только с одним сервером вышестоящего уровня, который в конце концов соединяется
с единственным главным/ведущим сервером.
Резервный сервер каскадной репликации не только получает записи WAL от главного, но так же
восстанавливает их из архива. Таким образом, даже если соединение с сервером более высокого
уровня разорвётся, потоковая репликация для последующих уровней будет продолжаться до ис-
черпания доступных записей WAL.
Каскадная репликация в текущей реализации асинхронна. Параметры синхронной репликации
(см. Подраздел 26.2.8) в настоящее время не оказывают влияние на каскадную репликацию.
Распространение обратной связи горячего резерва работает от нижестоящего уровня к вышесто-
ящему уровню вне зависимости от способа организации связи.
Если резервный сервер вышестоящего уровня будет преобразован в новый главный, серве-
ры нижестоящего уровня продолжат получать поток с нового главного при условии, что
recovery_target_timeline установлен в значение ‘latest’.
655Отказоустойчивость, баланси-
ровка нагрузки и репликация
Для использования каскадной репликации необходимо настроить резервный каскадный сервер
на прием соединений репликации (то есть установить max_wal_senders и hot_standby, настроить
host-based authentication). Так же может быть необходимо настроить на нижестоящем резервном
значение primary_conninfo на каскадный резервный сервер.
26.2.8. Синхронная репликация
По умолчанию в PostgreSQL потоковая репликация асинхронна. Если ведущий сервер выходит из
строя, некоторые транзакции, которые были подтверждены, но не переданы на резервный, могут
быть потеряны. Объём потерянных данных пропорционален задержке репликации на момент от-
работки отказа.
Синхронная репликация предоставляет возможность гарантировать, что все изменения, внесён-
ные в транзакции, были переданы одному или нескольким синхронным резервным серверам. Это
увеличивает стандартный уровень надёжности, гарантируемый при фиксации транзакции. Этот
уровень защиты соответствует второму уровню безопасности репликации из теории вычислитель-
ной техники, или групповой безопасности первого уровня (безопасности групповой и уровня 1),
когда выбран режим synchronous_commit remote_write.
При синхронной репликации каждая фиксация пишущей транзакции ожидает подтверждения то-
го, что запись фиксации помещена в журнал предзаписи на диске на обоих серверах: ведущем и
резервном. При таком варианте потеря данных может произойти только в случае одновременного
выхода из строя ведущего и резервного серверов. Это обеспечивает более высокий уровень надёж-
ности, при условии продуманного подхода системного администратора к вопросам размещения и
управления этими серверами. Ожидание подтверждения увеличивает уверенность в том, что дан-
ные не будут потеряны во время сбоя сервера, но при этом увеличивает время отклика для обра-
ботки транзакции. Минимальное время ожидания равно времени передачи данных от ведущего к
резервному и обратно.
Транзакции только для чтения и откат транзакции не требуют ожидания для ответа с резервного
сервера. Промежуточные подтверждения не ожидают ответа от резервного сервера, только под-
тверждение верхнего уровня. Долгие операции вида загрузки данных или построения индекса
не ожидают финального подтверждения. Но все двухфазные подтверждения требуют ожидания,
включая подготовку и непосредственно подтверждение.
Синхронным резервным сервером может быть резервный сервер при физической репликации или
подписчик при логической репликации. Это также может быть другой потребитель потока логи-
ческой или физической репликации, способный отправлять в ответ требуемые сообщения. Поми-
мо встроенных систем логической и физической репликации, к таким потребителям относятся
специальные программы, pg_receivewal и pg_recvlogical, а также некоторые сторонние систе-
мы репликации и внешние программы. Подробнее об организации синхронной репликации с их
использованием можно узнать в соответствующей документации.
26.2.8.1. Базовая настройка
При настроенной потоковой репликации установка синхронной репликации требует только допол-
нительной настройки: необходимо выставить synchronous_standby_names в непустое значение. Так
же необходимо установить synchronous_commit в значение on, но так как это значение по умолча-
нию, обычно действий не требуется. (См. Подраздел 19.5.1 и Подраздел 19.6.2.) В такой конфигу-
рации каждая транзакция будет ожидать подтверждение того, что на резервном сервере произо-
шла запись транзакции в надёжное хранилище. Значение synchronous_commit может быть выстав-
лено для отдельного пользователя, может быть прописано в файле конфигурации, для конкретного
пользователя или БД или динамически изменено приложением для управления степенью надёж-
ности на уровне отдельных транзакций.
После сохранения записи о фиксации транзакции на диске ведущего сервера эта запись WAL пере-
даётся резервному серверу. Резервный сервер отвечает подтверждающим сообщением после со-
хранения каждого нового блока данных WAL на диске, если только wal_receiver_status_interval
на нём не равен нулю. В случае, когда выбран режим synchronous_commit remote_apply, резерв-
ный сервер передаёт подтверждение после воспроизведения записи фиксации, когда транзакция
656Отказоустойчивость, баланси-
ровка нагрузки и репликация
становится видимой. Если резервный сервер выбран на роль синхронного резервного в соответ-
ствии со значением synchronous_standby_names на ведущем, подтверждающие сообщения с этого
сервера, в совокупности с сообщениями с других синхронных серверов, будут сигналом к завер-
шению ожидания при фиксировании транзакций, требующих подтверждения сохранения записи
фиксации. Эти параметры позволяют администратору определить, какие резервные серверы будут
синхронными резервными. Заметьте, что настройка синхронной репликации в основном осуществ-
ляется на главном сервере. Перечисленные в списке резервных серверы должны быть подключе-
ны к нему непосредственно; он ничего не знает о резервных серверах, подключённых каскадно,
через промежуточные серверы.
Если synchronous_commit имеет значение remote_write, то в случае подтверждения транзакции
ответ от резервного сервера об успешном подтверждении будет передан, когда данные запишутся
в операционной системе, но не когда данные будет реально сохранены на диске. При таком зна-
чении уровень надёжности снижается по сравнению со значением on. Резервный сервер может
потерять данные в случае падения операционной системы, но не в случае падения PostgreSQL.
Тем не менее, этот вариант полезен на практике, так как позволяет сократить время отклика для
транзакции. Потеря данных может произойти только в случае одновременного сбоя ведущего и
резервного, осложнённого повреждением БД на ведущем.
Если synchronous_commit имеет значение remote_apply, то для завершения фиксирования тран-
закции потребуется дождаться, чтобы текущие синхронные резервные серверы сообщили, что они
воспроизвели транзакцию и её могут видеть запросы пользователей. В простых случаях это позво-
ляет обеспечить обычный уровень согласованности и распределение нагрузки.
Пользователи прекратят ожидание в случае запроса на быструю остановку сервера. В то время
как при использовании асинхронной репликации сервер не будет полностью остановлен, пока все
исходящие записи WAL не переместятся на текущий присоединённый резервный сервер.
26.2.8.2. Несколько синхронных резервных серверов
Синхронная репликация поддерживает применение одного или нескольких синхронных резерв-
ных серверов; транзакции будут ждать, пока все резервные серверы, считающиеся синхронными,
не подтвердят получение своих данных. Число синхронных резервных серверов, от которых тран-
закции должны ждать подтверждения, задаётся в параметре synchronous_standby_names. В этом
параметре также задаётся список имён резервных серверов и метод (FIRST или ANY) выбора син-
хронных из заданного списка.
С методом FIRST производится синхронная репликация на основе приоритетов, когда транзакции
фиксируются только после того, как их записи в WAL реплицируются на заданное число синхрон-
ных резервных серверов, выбираемых согласно приоритетам. Серверы, имена которых идут в на-
чале списка, имеют больший приоритет и выбираются на роль синхронных. Другие резервные сер-
веры, идущие в этом списке за ними, считаются потенциальными синхронными. Если один из те-
кущих синхронных резервных серверов по какой-либо причине отключается, он будет немедленно
заменён следующим по порядку резервным сервером.
Пример значения synchronous_standby_names для нескольких синхронных резервных серверов,
выбираемых по приоритетам:
synchronous_standby_names = ‘FIRST 2 (s1, s2, s3)’
В данном примере, если работают четыре резервных сервера s1, s2, s3 и s4, два сервера s1 и s2
будут выбраны на роль синхронных резервных, так как их имена идут в начале этого списка. Сервер
s3 будет потенциальным резервным и возьмёт на себя роль синхронного резервного при отказе s1
или s2. Сервер s4 будет асинхронным резервным, так как его имя в этом списке отсутствует.
С методом ANY производится синхронная репликация на основе кворума, когда транзакции фикси-
руются только после того, как их записи в WAL реплицируются на как минимум заданное число
синхронных серверов в списке.
Пример значения synchronous_standby_names для нескольких синхронных резервных серверов,
образующих кворум:
657Отказоустойчивость, баланси-
ровка нагрузки и репликация
synchronous_standby_names = ‘ANY 2 (s1, s2, s3)’
В данном примере, если работают четыре резервных сервера s1, s2, s3 и s4, транзакции будут
фиксироваться только после получения ответов как минимум от двух резервных серверов из s1, s2
и s3. Сервер s4 будет асинхронным резервным, так как его имя в этом списке отсутствует.
Состояние
синхронности
pg_stat_replication.
резервных
серверов
можно
увидеть
в
представлении
26.2.8.3. Планирование производительности
Организуя синхронную репликацию, обычно нужно обстоятельно обдумать конфигурацию и раз-
мещение резервных серверов, чтобы обеспечить приемлемую производительность приложений.
Ожидание не потребляет системные ресурсы, но блокировки транзакций будут сохраняться до
подтверждения передачи. Как следствие, непродуманное использование синхронной репликации
приведёт к снижению производительности БД из-за увеличения времени отклика и числа кон-
фликтов.
PostgreSQL позволяет разработчикам выбрать требуемый уровень надёжности, обеспечиваемый
при репликации. Он может быть установлен для системы в целом, для отдельного пользователя
или соединения или даже для отдельной транзакции.
Например, в рабочей нагрузке приложения 10% изменений могут относиться к важным данным
клиентов, а 90% — к менее критичным данным, потеряв которые, бизнес вполне сможет выжить
(например, это могут быть текущие разговоры пользователей между собой).
При настройке уровня синхронности репликации на уровне приложения (на ведущем) можно за-
дать синхронную репликацию для большинства важных изменений без замедления общего рабо-
чего ритма. Возможность настройки на уровне приложения является важным и практичным сред-
ством для получения выгод синхронной репликации при высоком быстродействии.
Следует иметь в виду, что пропускная способность сети должна быть больше скорости генериро-
вания данных WAL.
26.2.8.4. Планирование отказоустойчивости
В synchronous_standby_names задаётся количество и имена синхронных резервных серверов,
от которых будет ожидаться подтверждение при фиксировании транзакции, когда параметру
synchronous_commit присвоено значение on, remote_apply или remote_write. Фиксирование тран-
закции в таком режиме может не завершиться никогда, если один из синхронных резервных сер-
веров выйдет из строя.
Поэтому для высокой степени доступности лучше всего обеспечить наличие синхронных резерв-
ных серверов в должном количестве. Для этого можно перечислить несколько потенциальных ре-
зервных серверов в строке synchronous_standby_names.
При синхронной репликации на основе приоритетов синхронными резервными серверами станут
серверы, имена которых стоят в этом списке первыми. Следующие за ними серверы будут стано-
виться синхронными резервными при отказе одного из текущих.
При синхронной репликации на основе кворума кандидатами на роль синхронных резервных будут
все серверы в списке. И если один из них откажет, другие серверы будут продолжать исполнять
эту роль.
Когда к ведущему серверу впервые присоединяется резервный, он ещё не будет полностью синхро-
низированным. Это называется состоянием навёрстывания. Как только отставание резервного от
ведущего сервера сократится до нуля в первый раз, система перейдет в состояние потоковой пе-
редачи в реальном времени. Сразу после создания резервного сервера навёрстывание может быть
длительным. В случае выключения резервного сервера длительность этого процесса увеличится
соответственно продолжительности простоя. Резервный сервер может стать синхронным только
658Отказоустойчивость, баланси-
ровка нагрузки и репликация
по достижении состояния потоковой передачи. Это состояние можно проследить в представлении
pg_stat_replication.
Если ведущий сервер перезапускается при наличии зафиксированных транзакций, ожидающих
подтверждения, эти транзакции будут помечены как полностью зафиксированные после восста-
новления ведущего. При этом нельзя гарантировать, что все резервные серверы успели получить
все текущие данные WAL к моменту падения ведущего. Таким образом, некоторые транзакции мо-
гут считаться незафиксированными на резервном сервере, даже если они считаются зафиксиро-
ванными на ведущем. Гарантия, которую мы можем дать, состоит в том, что приложение не полу-
чит явного подтверждения успешной фиксации, пока не будет уверенности, что данные WAL по-
лучены всеми синхронными резервными серверами.
Если запустить синхронные резервные серверы в указанном количестве не удаётся, вам следует
уменьшить число синхронных серверов, подтверждения которых требуются для завершения фик-
сации транзакций, в параметре synchronous_standby_names (или вовсе отключить его) и переза-
грузить файл конфигурации на ведущем сервере.
В случае если ведущий сервер стал недоступным для оставшихся резервных, следует переклю-
читься на наиболее подходящий из имеющихся резервных серверов.
Если необходимо пересоздать резервный сервер при наличии ожидающей подтверждения тран-
закции необходимо убедиться, что команды pg_start_backup() и pg_stop_backup() запускаются в
сессии с установленным synchronous_commit = off, в противном случае эти запросы на подтвер-
ждение будут бесконечными для вновь возникшего резервного сервера.
26.2.9. Непрерывное архивирование на резервном сервере
Когда на резервном сервере применяется последовательное архивирование WAL, возможны два
различных сценария: архив WAL может быть общим для ведущего и резервного сервера, либо ре-
зервный сервер может иметь собственный архив WAL. Когда резервный работает с собственным
архивом WAL, установите в archive_mode значение always, и он будет вызывать команду архива-
ции для каждого сегмента WAL, который он получает при восстановлении из архива или потоко-
вой репликации. В случае с общим архивом можно поступить аналогично, но archive_command
должна проверять, нет ли в архиве файла, идентичного архивируемому. Таким образом, команда
archive_command должна позаботиться о том, чтобы существующий файл не был заменён файлом
с другим содержимым, а в случае попытки повторного архивирования должна сообщать об успеш-
ном выполнении. При этом все эти действия должны быть рассчитаны на условия гонки, возмож-
ные, если два сервера попытаются архивировать один и тот же файл одновременно.
Если в archive_mode установлено значение on, архивация в режиме восстановления или резерва не
производится. В случае повышения резервного сервера, он начнёт архивацию после повышения,
но в архив не попадут те файлы WAL, которые генерировал не он сам. Поэтому, чтобы в архиве
оказался полный набор файлов WAL, необходимо обеспечить архивацию всех файлов WAL до того,
как они попадут на резервный сервер. Это естественным образом происходит при трансляции фай-
лов журналов, так как резервный сервер может восстановить только файлы, которые находятся в
архиве, однако при потоковой репликации это не так. Когда сервер работает не в режиме резерва,
различий между режимами on и always нет.
26.3. Отработка отказа
Если ведущий сервер отказывает, резервный должен начать процедуры отработки отказа.
Если отказывает резервный сервер, никакие действия по отработке отказа не требуются. Если ре-
зервный сервер будет перезапущен, даже через некоторое время, немедленно начнётся операция
восстановления, благодаря возможности возобновляемого восстановления. Если вернуть резерв-
ный сервер в строй невозможно, необходимо создать полностью новый экземпляр резервного сер-
вера.
Когда ведущий сервер отказывает и резервный сервер становится новым ведущим, а затем старый
ведущий включается снова, необходим механизм для предотвращения возврата старого к роли
659Отказоустойчивость, баланси-
ровка нагрузки и репликация
ведущего. Иногда его называют STONITH (Shoot The Other Node In The Head, «Выстрелите в голову
другому узлу»), что позволяет избежать ситуации, когда обе системы считают себя ведущими, и
в результате возникают конфликты и потеря данных.
Во многих отказоустойчивых конструкциях используются всего две системы: ведущая и резервная,
с некоторым контрольным механизмом, который постоянно проверяет соединение между ними
и работоспособность ведущей. Также возможно применение третьей системы (называемой следя-
щим сервером) для исключения некоторых вариантов нежелательной отработки отказа, но эта до-
полнительная сложность оправдана, только если вся схема достаточно хорошо продумана и тща-
тельно протестирована.
PostgreSQL не предоставляет системного программного обеспечения, необходимого для опреде-
ления сбоя на ведущем и уведомления резервного сервера баз данных. Имеется множество подоб-
ных инструментов, которые хорошо интегрируются со средствами операционной системы, требу-
емыми для успешной отработки отказа, например, для миграции IP-адреса.
Когда происходит переключение на резервный сервер, только один сервер продолжает работу. Это
состояние называется ущербным. Бывший резервный сервер теперь является ведущим, а бывший
ведущий отключён и может оставаться отключённым. Для возвращения к нормальному состоянию
необходимо запустить новый резервный сервер, либо на бывшем ведущем, либо в третьей, возмож-
но, новой системе. Ускорить этот процесс в больших кластерах позволяет утилита pg_rewind. По
завершении этого процесса можно считать, что ведущий и резервный сервер поменялись ролями.
Некоторые используют третий сервер в качестве запасного для нового ведущего, пока не будет
воссоздан новый резервный сервер, хотя это, очевидно, усложняет конфигурацию системы и ра-
бочие процедуры.
Таким образом, переключение с ведущего сервера на резервный может быть быстрым, но требу-
ет некоторого времени для повторной подготовки отказоустойчивого кластера. Регулярные пере-
ключения с ведущего сервера на резервный полезны, так как при этом появляется плановое время
для отключения и проведения обслуживания. Это также позволяет убедиться в работоспособности
механизма отработки отказа и гарантировать, что он действительно будет работать, когда потре-
буется. Эти административные процедуры рекомендуется документировать письменно.
Чтобы сделать ведущим резервный сервер, принимающий журналы, выполните команду pg_ctl
promote или создайте файл-триггер с именем и путём, заданным в параметре trigger_file в фай-
ле recovery.conf. Если для переключения планируется использовать команду pg_ctl promote,
указывать trigger_file не требуется. Если резервный сервер применяется для анализа данных,
чтобы только разгрузить ведущий, выполняя запросы на чтение, а не обеспечивать отказоустой-
чивость, повышать его до ведущего не понадобится.
26.4. Другие методы трансляции журнала
Встроенному режиму резерва, описанному в предыдущем разделе, есть альтернатива — задать в
restore_command команду, следящую за содержимым архива. Эта возможность доступна только
для версии 8.4 и выше. В такой конфигурации режим standby_mode выключается, так как реали-
зуется отдельный механизм слежения за данными, требующихся для резервного сервера. См. мо-
дуль pg_standby для примера реализации такой возможности.
Необходимо отметить, что в этом режиме сервер будет применять только один файл WAL одновре-
менно, то есть если использовать резервный сервер для запросов (см. сервер горячего резерва),
будет задержка между операциями на главном и моментом видимости этой операции резервным,
соответствующей времени заполнения файла WAL. archive_timeout можно использовать для сни-
жения этой задержки. Так же необходимо отметить, что нельзя совмещать этот метод с потоковой
репликацией.
В процессе работы на ведущем сервере и резервном будет происходить обычное формирование
архивов и их восстановление. Единственной точкой соприкосновения двух серверов будут только
архивы файлов WAL на обеих сторонах: на ведущем архивы формируются, на резервном происходит
чтение данных из архивов. Следует внимательно следить за тем, чтобы архивы WAL от разных
660Отказоустойчивость, баланси-
ровка нагрузки и репликация
ведущих серверов не смешивались или не перепутывались. Архив не должен быть больше, чем это
необходимо для работы резерва.
Магия, заставляющая работать вместе два слабо связанных сервера, проста: restore_command,
выполняющаяся на резервном при запросе следующего файла WAL, ожидает его доступности
на ведущем. Команда restore_command задаётся в файле recovery.conf на резервном сервере.
Обычно процесс восстановления запрашивает файл из архива WAL, сообщая об ошибке в слу-
чае его недоступности. Для работы резервного сервера недоступность очередного файла WAL яв-
ляется обычной ситуацией, резервный просто ожидает его появления. Для файлов, оканчиваю-
щихся на .history, ожидание не требуется, поэтому возвращается ненулевой код. Ожидающая
restore_command может быть написана как пользовательский скрипт, который в цикле опрашива-
ет, не появился ли очередной файл WAL. Также должен быть способ инициировать переключение
роли, при котором цикл в restore_command должен прерваться, а резервный сервер должен полу-
чить ошибку «файл не найден». При этом восстановление завершится, и резервный сервер сможет
станет обычным.
Псевдокод для подходящей restore_command:
triggered = false;
while (!NextWALFileReady() &amp;&amp; !triggered)
{
sleep(100000L);
/* ждать ~0.1 сек*/
if (CheckForExternalTrigger())
triggered = true;
}
if (!triggered)
CopyWALFileForRecovery();
Рабочий пример ожидающей restore_command представлен в модуле pg_standby. К нему следует
обратится за примером правильной реализации логики, описанной выше. Он так же может быть
расширен для поддержки особых конфигураций и окружений.
Метод вызова переключения является важной частью планирования и архитектуры. Один из воз-
можных вариантов — команда restore_command. Она исполняется единожды для каждого файла
WAL, но процесс, запускаемый restore_command, создаётся и завершается для каждого файла, так
что это не служба и не серверный процесс, и применить сигналы и реализовать их обработчик
в нём нельзя. Поэтому restore_command не подходит для отработки отказа. Можно организовать
переключение по тайм-ауту, в частности, связав его с известным значением archive_timeout на
ведущем. Однако это не очень надёжно, так как переключение может произойти и из-за проблем
в сети или загруженности ведущего сервера. В идеале для этого следует использовать механизм
уведомлений, например явно создавать файл-триггер, если это возможно.
26.4.1. Реализация
Сокращённая процедура настройки для резервного сервера с применением альтернативного ме-
тода указана ниже. Для подробностей по каждому шагу следует обратиться к указанному разделу.</p>
<ol>
  <li>Разверните ведущую и резервную системы, сделав их максимально одинаковыми, включая две
одинаковые копии PostgreSQL одного выпуска.</li>
  <li>Настройте постоянную архивацию с ведущего сервера в каталог архивов WAL на резервном. Убе-
дитесь, что archive_mode, archive_command и archive_timeout установлены в соответствующие
значения на ведущем (см. Подраздел 25.3.1).</li>
  <li>Создайте базовую копию данных ведущего сервера (см. Подраздел 25.3.2) и восстановите её на
резервном.</li>
  <li>Запустите восстановление на резервном сервере из локального архива WAL с помощью команды
restore_command из файла recovery.conf как описано выше (см. Подраздел 25.3.4).
Поток восстановления только читает архив WAL, поэтому, как только файл WAL скопирован на
резервную систему, его можно копировать на ленту в то время, как его читает резервный сервер.
661Отказоустойчивость, баланси-
ровка нагрузки и репликация
Таким образом, работа резервного сервера в целях отказоустойчивости может быть совмещена с
долговременным сохранением файлов для восстановления после катастрофических сбоев.
Для целей тестирования возможен запуск ведущего и резервного сервера в одной системе. Это не
обеспечивает надёжность серверов, так же как и не подходит под описание высокой доступности.
26.4.2. Построчная трансляция журнала
Так же возможна реализация построчной трансляции журналов с применением альтернативного
метода, хотя это требует дополнительных доработок, а изменения будут видны для запросов на
сервере горячего резерва только после передачи полного файла WAL.
Внешняя программа может вызвать функцию pg_walfile_name_offset() (см. Раздел 9.26) для по-
иска имени файла и точного смещения в нём от текущего конца WAL. Можно получить доступ
к файлу WAL напрямую и скопировать данные из последнего известного окончания WAL до теку-
щего окончания на резервном сервере. При таком подходе интервал возможной потери данных
определяется временем цикла работы программы копирования, что может составлять очень ма-
лую величину. Так же не потребуется напрасно использовать широкую полосу пропускания для
принудительного архивирования частично заполненного файла сегмента. Следует отметить, что
на резервном сервере скрипт команды restore_command работает только с файлом WAL целиком,
таким образом, копирование данных нарастающим итогом не может быть выполнено на резерв-
ном обычными средствами. Это используется только в случае отказа ведущего — когда послед-
ний частично сформированный файл WAL предоставляется резервному непосредственно перед пе-
реключением. Корректная реализация этого процесса требует взаимодействия скрипта команды
restore_command с данными из программы копирования.
Начиная с PostgreSQL версии 9.0 можно использовать потоковую репликацию (см. Подраз-
дел 26.2.5) для получения этих же преимуществ меньшими усилиями.
26.5. Горячий резерв
Термин «горячий резерв» используется для описания возможности подключаться к серверу и вы-
полнять запросы на чтение, в то время как сервер находится в режиме резерва или восстановле-
ния архива. Это полезно и для целей репликации, и для восстановления желаемого состояния из
резервной копии с высокой точностью. Так же термин «горячий резерв» описывает способность
сервера переходить из режима восстановления к обычной работе, в то время как пользователи
продолжают выполнять запросы и/или их соединения остаются открытыми.
В режиме горячего резерва запросы выполняются примерно так же, как и в обычном режиме, с
некоторыми отличиями в использовании и администрировании, описанными ниже.
26.5.1. Обзор на уровне пользователя
Когда параметр hot_standby на резервном сервере установлен в true, то он начинает принимать
соединения сразу как только система придёт в согласованное состояние в процессе восстановле-
ния. Для таких соединений будет разрешено только чтение, запись невозможна даже во времен-
ные таблицы.
Для того, чтобы данные с ведущего сервера были получены на резервном, требуется некоторое
время. Таким образом, имеется измеряемая задержка между ведущим и резервным серверами.
Поэтому запуск одинаковых запросов примерно в одно время на ведущем и резервном серверах
может вернуть разный результат. Можно сказать, что данные на резервном сервере в конечном
счёте согласуются с ведущим. После того как запись о зафиксированной транзакции воспроиз-
водится на резервном сервере, изменения, совершённые в этой транзакции, становится видны в
любых последующих снимках данных на резервном сервере. Снимок может быть сделан в начале
каждого запроса или в начале каждой транзакции в зависимости от уровня изоляции транзакции.
Более подробно см. Раздел 13.2.
Транзакции, запущенные в режиме горячего резерва, могут выполнять следующие команды:
662Отказоустойчивость, баланси-
ровка нагрузки и репликация
• Доступ к данным — SELECT, COPY TO
• Команды для работы с курсором — DECLARE, FETCH, CLOSE
• Параметры — SHOW, SET, RESET
• Команды явного управления транзакциями
• BEGIN, END, ABORT, START TRANSACTION
• SAVEPOINT, RELEASE, ROLLBACK TO SAVEPOINT
• Блок EXCEPTION и другие внутренние подчиненные транзакции
• LOCK TABLE, только когда исполняется в явном виде в следующем режиме: ACCESS SHARE, ROW
SHARE или ROW EXCLUSIVE.
• Планы и ресурсы — PREPARE, EXECUTE, DEALLOCATE, DISCARD
• Дополнения и расширения — LOAD
Транзакции, запущенные в режиме горячего резерва, никогда не получают ID транзакции и не
могут быть записаны в журнал предзаписи. Поэтому при попытке выполнить следующие действия
возникнут ошибки:
• Команды манипуляции данными (DML) — INSERT, UPDATE, DELETE, COPY FROM, TRUNCATE. Следу-
ет отметить, что нет разрешённых действий, которые приводили бы к срабатыванию тригге-
ра во время исполнения на резервном сервере. Это ограничение так же касается и временных
таблиц, так как строки таблицы не могут быть прочитаны или записаны без обращения к ID
транзакции, что в настоящее время не возможно в среде горячего резерва.
• Команды определения данных (DDL) — CREATE, DROP, ALTER, COMMENT. Эти ограничения так же
относятся и к временным таблицам, так как операции могут потребовать обновления таблиц
системных каталогов.
• SELECT … FOR SHARE | UPDATE, так как блокировка строки не может быть проведена без об-
новления соответствующих файлов данных.
• Правила для выражений SELECT, которые приводят к выполнению команд DML.
• LOCK которая явно требует режим более строгий чем ROW EXCLUSIVE MODE.
• LOCK в короткой форме с умолчаниями, так как требует ACCESS EXCLUSIVE MODE.
• Команды управления транзакциями, которые в явном виде требуют режим не только для чте-
ния
• BEGIN READ WRITE, START TRANSACTION READ WRITE
• SET TRANSACTION READ WRITE, SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE
• SET transaction_read_only = off
• Команды двухфазной фиксации — PREPARE TRANSACTION, COMMIT PREPARED, ROLLBACK PREPARED,
так как даже транзакции только для чтения нуждаются в записи в WAL на подготовительной
фазе (первая фаза двухфазной фиксации).
• Обновление последовательностей — nextval(), setval()
• LISTEN, UNLISTEN, NOTIFY
При обычной работе транзакции «только для чтения» могут использовать команды LISTEN,
UNLISTEN и NOTIFY; таким образом, сеансы горячего резерва работают с несколько большими огра-
ничениями, чем обычные только читающие сеансы. Возможно, что некоторые из этих ограниче-
ний будут ослаблены в следующих выпуска.
В режиме горячего резерва параметр transaction_read_only всегда имеет значение true и изме-
нить его нельзя. Но если не пытаться модифицировать содержимое БД, подключение к серверу в
663Отказоустойчивость, баланси-
ровка нагрузки и репликация
этом режиме не отличается от подключений к обычным базам данных. При отработке отказа или
переключении ролей база данных переходит в обычный режим работы. Когда сервер меняет ре-
жим работы, установленные сеансы остаются подключёнными. После выхода из режима горячего
резерва становится возможным запускать пишущие транзакции (даже в сеансах, начатых ещё в
режиме горячего резерва).
Пользователи могут узнать о нахождении сессии в режиме только для чтения с помощью команды
SHOW transaction_read_only. Кроме того, набор функций (Таблица 9.80) позволяет пользователям
получить доступ к информации о резервном сервере. Это позволяет создавать программы, учиты-
вающие текущий статус базы данных. Такой режим может быть полезен для мониторинга процес-
са восстановления или для написания комплексного восстановления для особенных случаев.
26.5.2. Обработка конфликтов запросов
Ведущий и резервный серверы связаны между собой многими слабыми связями. События на веду-
щем сервере оказывают влияние на резервный. В результате имеется потенциальная возможность
отрицательного влияния или конфликта между ними. Наиболее простой для понимания конфликт
— быстродействие: если на ведущем происходит загрузка очень большого объёма данных, то про-
исходит создание соответствующего потока записей WAL на резервный сервер. Таким образом,
запросы на резервном конкурируют за системные ресурсы, например, ввод-вывод.
Так же может возникнуть дополнительный тип конфликта на сервере горячего резерва. Этот кон-
фликт называется жёстким конфликтом, оказывает влияние на запросы, приводя к их отмене, а
в некоторых случаях и к обрыву сессии для разрешения конфликтов. Пользователям предоставлен
набор средств для обработки подобных конфликтов. Случаи конфликтов включают:
• Установка эксклюзивной блокировки на ведущем сервере, как с помощью явной команды
LOCK, так и при различных DDL, что приводит к конфликту доступа к таблицам на резервном.
• Удаление табличного пространства на ведущем сервере приводит к конфликту на резервном
когда запросы используют это пространство для хранения временных рабочих файлов.
• Удаление базы данных на ведущем сервере конфликтует с сессиями, подключёнными к этой
БД на резервном.
• Приложение очистки устаревших транзакций из WAL конфликтует с транзакциями на резерв-
ном сервере, которые используют снимок данных, который всё ещё видит какие-то из очищен-
ных на ведущем строк.
• Приложение очистки устаревших транзакций из WAL конфликтует с запросами к целевой
странице на резервном сервере вне зависимости от того, являются ли данные удалёнными
или видимыми.
В этих случаях на ведущем сервере просто происходит ожидание; пользователю следует выбрать
какую их конфликтующих сторон отменить. Тем не менее, на резервном нет выбора: действия из
WAL уже произошли на ведущем, поэтому резервный обязан применить их. Более того, позволять
обработчику WAL ожидать неограниченно долго может быть крайне нежелательно, так как отста-
вание резервного сервера от ведущего может всё возрастать. Таким образом, механизм обеспечи-
вает принудительную отмену запросов на резервном сервере, которые конфликтуют с применяе-
мыми записями WAL.
Примером такой проблемы может быть ситуация: администратор на ведущем сервере выполнил
команду DROP TABLE для таблицы, которая сейчас участвует в запросе на резервном. Понятно, что
этот запрос нельзя будет выполнять дальше, если команда DROP TABLE применится на резервном.
Если бы этот запрос выполнялся на ведущем, команда DROP TABLE ждала бы его окончания. Но ко-
гда на ведущем выполняется только команда DROP TABLE, ведущий сервер не знает, какие запросы
выполняются на резервном, поэтому он не может ждать завершения подобных запросов. Поэтому
если записи WAL с изменением прибудут на резервный сервер, когда запрос будет продолжать вы-
полняться, возникнет конфликт. В этом случае резервный сервер должен либо задержать приме-
нение этих записей WAL (и всех остальных, следующих за ними), либо отменить конфликтующий
запрос, чтобы можно было применить DROP TABLE.
664Отказоустойчивость, баланси-
ровка нагрузки и репликация
Если конфликтный запрос короткий, обычно желательно разрешить ему завершиться, нена-
долго задержав применение записей WAL, но слишком большая задержка в применении WAL
обычно нежелательна. Поэтому механизм отмены имеет параметры max_standby_archive_delay и
max_standby_streaming_delay, которые определяют максимально допустимое время задержки при-
менения WAL. Конфликтующие запросы будут отменены, если они длятся дольше допустимого
времени задержки применения очередных записей WAL. Два параметра существуют для того, что-
бы можно было задать разные значения для чтения записей WAL из архива (то есть при начальном
восстановлении из базовой копии либо при «навёрстывании» ведущего сервера в случае большого
отставания) и для получения записей WAL при потоковой репликации.
На резервном сервере, созданном преимущественно для отказоустойчивости, лучше выставлять
параметры задержек относительно небольшими, чтобы он не мог сильно отстать от ведущего из-
за задержек, связанных с ожиданием запросов горячего резерва. Однако если резервный сервер
предназначен для выполнения длительных запросов, то высокое значение или даже бесконечное
ожидание могут быть предпочтительнее. Тем не менее, следует иметь в виду, что длительные за-
просы могут оказать влияние на другие сессии на резервном сервере в виде отсутствия последних
изменений от ведущего из-за задержки применения записей WAL.
В
случае,
если
задержка,
определённая
max_standby_archive_delay
или
max_standby_streaming_delay будет превышена, конфликтующий запрос будет отменён. Обычно
это выражается в виде ошибки отмены, но в случае проигрывания команды DROP DATABASE обры-
вается вся конфликтная сессия. Так же, если конфликт произошел при блокировке, вызванной
транзакцией в состоянии IDLE, конфликтная сессия разрывается (это поведение может изменить
в будущем).
Отменённые запросы могут быть немедленно повторены (конечно после старта новой транзакции).
Так как причина отмены зависит от природы проигрываемых записей WAL, запрос, который был
отменён, может быть успешно выполнен вновь.
Следует учесть, что параметры задержки отсчитываются от времени получения резервным сер-
вером данных WAL. Таким образом, период дозволенной работы для запроса на резервном серве-
ре никогда не может быть длиннее параметра задержки и может быть существенно короче, если
резервный уже находится в режиме задержки в результате ожидания предыдущего запроса или
результат не доступен из-за высокой нагрузки обновлений.
Наиболее частой причиной конфликтов между запросами на резервном сервере и проигрыванием
WAL является преждевременная очистка. Обычно PostgreSQL допускает очистку старых версий
записей при условии что ни одна из транзакций их не видит согласно правилам видимости данных
для MVCC. Тем не менее, эти правила применяются только для транзакций, выполняемых на глав-
ном сервере. Таким образом, допустима ситуация, когда на главном запись уже очищена, но эта
же запись всё ещё видна для транзакций на резервном сервере.
Для опытных пользователей следует отметить, что как очистка старых версий строк, так и замо-
розка версии строки могут потенциально вызвать конфликт с запросами на резервном сервере.
Ручной запуск команды VACUUM FREEZE может привести к конфликту, даже в таблице без обнов-
ленных и удалённых строк.
Пользователи должны понимать, что регулярное и активное изменение данных в таблицах на ве-
дущем сервере чревато отменой длительных запросов на резервном. В таком случае установка
конечного значения для max_standby_archive_delay или max_standby_streaming_delay действует
подобно ограничению statement_timeout.
В случае, если количество отменённых запросов на резервном сервере получается неприемле-
мым, существует ряд дополнительных возможностей. Первая возможность — установить параметр
hot_standby_feedback, который не даёт команде VACUUM удалять записи, ставшие недействитель-
ными недавно, что предотвращает конфликты очистки. При этом следует учесть, что это вызывает
задержку очистки мёртвых строк на ведущем, что может привести к нежелательному распуханию
таблицы. Тем не менее, в итоге ситуация будет не хуже, чем если бы запросы к резервному серверу
исполнялись непосредственно на ведущем, но при этом сохранится положительный эффект от раз-
665Отказоустойчивость, баланси-
ровка нагрузки и репликация
деления нагрузки. В случае, когда соединение резервных серверов с ведущим часто разрывается,
следует скорректировать период, в течение которого обратная связь через hot_standby_feedback
не обеспечивается. Например, следует подумать об увеличении max_standby_archive_delay, что-
бы запросы отменялись не сразу при конфликтах с архивом WAL в период разъединения. Также
может иметь смысл увеличить max_standby_streaming_delay для предотвращения быстрой отме-
ны запросов из-за полученных записей WAL после восстановления соединения.
Другая возможность — увеличение vacuum_defer_cleanup_age на ведущем сервере таким об-
разом, чтобы мёртвые записи не очищались бы так быстро, как при обычном режиме рабо-
ты. Это даёт запросам на резервном сервере больше времени на выполнение, прежде чем они
могут быть отменены, без увеличения задержки max_standby_streaming_delay. Тем не менее
при таком подходе очень трудно обеспечить какое-то определённое окно по времени, так как
vacuum_defer_cleanup_age измеряется в количестве транзакций, выполняемых на ведущем серве-
ре.
Количество отменённых запросов и причины отмены можно просмотреть через системное
представление pg_stat_database_conflicts на резервном сервере. Системное представление
pg_stat_database так же содержит итоговую информацию.
26.5.3. Обзор административной части
Если в файле postgresql.conf для параметра hot_standby задано значение on (по умолчанию)
и существует файл recovery.conf, сервер запустится в режиме горячего резерва. Однако может
пройти некоторое время, прежде чем к нему можно будет подключиться, так как он не будет при-
нимать подключения, пока не произведёт восстановление до согласованного состояния, подходя-
щего для выполнения запросов. (Информация о согласованности состояния записывается на веду-
щем сервере в контрольной точке.) В течение этого периода клиенты при попытке подключения
будут получать сообщение об ошибке. Убедиться, что сервер включился в работу, можно либо по-
вторяя попытки подключения из приложения до успешного подключения, либо дождавшись по-
явления в журналах сервера этих сообщений:
LOG:
entering standby mode
… then some time later …
LOG:
LOG:
consistent recovery state reached
database system is ready to accept read only connections
Включить горячий резерв нельзя, если WAL был записан в период, когда на ведущем сервере па-
раметр wal_level имел значение не replica и не logical. Достижение согласованного состояния
также может быть отсрочено, если имеют место оба этих условия:
• Пишущая транзакция имеет более 64 подтранзакций
• Очень длительные пишущие транзакции
Если вы применяете файловую репликацию журналов («тёплый резерв»), возможно, придётся
ожидать прибытия следующего файла WAL (максимальное время ожидания задаётся параметром
archive_timeout на ведущем сервере).
Значения некоторых параметров на резервном сервере необходимо изменить при модификации
их на ведущем. Для таких параметров значения на резервном сервере должны быть не меньше
значений на ведущем. Таким образом, если вы хотите увеличить их, вы сначала должны сделать
это на резервных серверах, а затем применить изменения на ведущем. И наоборот, если вы хотите
их уменьшить, сначала сделайте это на ведущем сервере, а потом примените изменения на всех
резервных. Если параметры имеют недостаточно большие значения, резервный сервер не сможет
начать работу. В этом случае можно увеличить их и повторить попытку запуска сервера, чтобы он
возобновил восстановление. Это касается следующих параметров:
• max_connections
• max_prepared_transactions
666Отказоустойчивость, баланси-
ровка нагрузки и репликация
• max_locks_per_transaction
• max_worker_processes
Очень важно для администратора выбрать подходящие значения для max_standby_archive_delay
и max_standby_streaming_delay. Оптимальное значение зависит от приоритетов. Например, если
основное назначение сервера — обеспечение высокой степени доступности, то следует установить
короткий период, возможно даже нулевой, хотя это очень жёсткий вариант. Если резервный сер-
вер планируется как дополнительный сервер для аналитических запросов, то приемлемой будет
максимальная задержка в несколько часов или даже -1, что означает бесконечное ожидание окон-
чания запроса.
Вспомогательные биты статуса транзакций, записанные на ведущем, не попадают в WAL, так что
они, скорее всего, будут перезаписаны на нём при работе с данными. Таким образом, резервный
сервер будет производить запись на диск, даже если все пользователи только читают данные, ни-
чего не меняя. Кроме того, пользователи будут записывать временные файлы при сортировке боль-
ших объёмов и обновлять файлы кеша. Поэтому в режиме горячего резерва ни одна часть базы
данных фактически не работает в режиме «только чтение». Следует отметить, что также возможно
выполнить запись в удалённую базу данных с помощью модуля dblink и другие операции вне базы
данных с применением PL-функций, несмотря на то, что транзакции по-прежнему смогут только
читать данные.
Следующие типы административных команд недоступны в течение режима восстановления:
• Команды определения данных (DDL) — например: CREATE INDEX
• Команды выдачи привилегий и назначения владельца — GRANT, REVOKE, REASSIGN
• Команды обслуживания — ANALYZE, VACUUM, CLUSTER, REINDEX
Ещё раз следует отметить, что некоторые из этих команд фактически доступны на ведущем сер-
вере для транзакций в режиме только для чтения.
В результате нельзя создать дополнительные индексы или статистику, чтобы они существовали
только на резервном. Если подобные административные команды нужны, то их следует выполнить
на ведущем сервере, затем эти изменения будут распространены на резервные серверы.
Функции pg_cancel_backend() и pg_terminate_backend() работают на стороне пользовате-
ля, но не для процесса запуска, который обеспечивает восстановление. Представление
pg_stat_activity не показывает восстанавливаемые транзакции как активные. Поэтому представ-
ление pg_prepared_xacts всегда пусто в ходе восстановления. Если требуется разобрать сомни-
тельные подготовленные транзакции, следует обратиться к pg_prepared_xacts на ведущем и вы-
полнить команды для разбора транзакций там либо разобрать их по окончании восстановления.
pg_locks отображает блокировки, происходящие в процессе работы сервера как обычно. pg_locks
так же показывает виртуальные транзакции, обработанные процессом запуска, которому принад-
лежат все AccessExclusiveLocks, наложенные транзакциями в режиме восстановления. Следует
отметить, что процесс запуска не запрашивает блокировки, чтобы внести изменения в базу дан-
ных, поэтому блокировки, отличные от AccessExclusiveLocks не показываются в pg_locks для
процесса запуска, подразумевается их существование.
Модуль check_pgsql для Nagios будет работать, так как сервер выдаёт простую информацию, нали-
чие которой он проверяет. Скрипт мониторинга check_postgres так же работает, хотя для некото-
рых выдаваемых показателей результаты могут различаться или вводить в заблуждение. Напри-
мер, нельзя отследить время последней очистки, так как очистка не производится на резервном
сервере. Очистка запускается на ведущем сервере и результаты её работы передаются резервно-
му.
Команды управления файлами WAL, например pg_start_backup, pg_switch_wal и т. д. не будут
работать во время восстановления.
Динамически загружаемые модули работать будут, включая pg_stat_statements.
667Отказоустойчивость, баланси-
ровка нагрузки и репликация
Рекомендательная блокировка работает обычно при восстановлении, включая обнаружение вза-
имных блокировок. Следует отметить, что рекомендательная блокировка никогда не попадает в
WAL, таким образом для рекомендательной блокировки как на ведущем сервере, так и на резерв-
ном, невозможен конфликт с проигрыванием WAL. Но возможно получение рекомендательной бло-
кировки на ведущем сервере, а затем получение подобной рекомендательной блокировки на ре-
зервном. Рекомендательная блокировка относится только к серверу, на котором она получена.
Системы репликации на базе триггеров, подобные Slony, Londiste и Bucardo не могут запускаться
на резервном сервере вовсе, хотя они превосходно работают на ведущем до тех пор, пока не будет
подана команда не пересылать изменения на резервный. Проигрывание WAL не основано на триг-
герах, поэтому поток WAL нельзя транслировать с резервного сервера в другую систему, которая
требует дополнительной записи в БД или работает на основе триггеров.
Новые OID не могут быть выданы, хотя, например генераторы UUID смогут работать, если они не
пытаются записывать новое состояние в базу данных.
В настоящий момент создание временных таблиц недопустимо при транзакции только для чтения,
в некоторых случаях существующий скрипт будет работать неверно. Это ограничение может быть
ослаблено в следующих выпусках. Это одновременно требование SQL стандарта и техническое
требование.
Команда DROP TABLESPACE может быть выполнена только если табличное пространство пусто. Неко-
торые пользователи резервного сервера могут активно использовать табличное пространство че-
рез параметр temp_tablespaces. Если имеются временные файлы в табличных пространствах, все
активные запросы отменяются для обеспечения удаления временных файлов, затем табличное
пространство может быть удалено и продолжено проигрывание WAL.
Выполнение команды DROP DATABASE или ALTER DATABASE … SET TABLESPACE на ведущем сервере
приводит к созданию записи в WAL, которая вызывает принудительное отключение всех пользова-
телей, подключённых к этой базе данных на резервном. Это происходит немедленно, вне зависимо-
сти от значения max_standby_streaming_delay. Следует отметить, что команда ALTER DATABASE …
RENAME не приводит к отключению пользователей, так что обычно она действует незаметно, хотя
в некоторых случаях возможны сбои программ, которые зависят от имени базы данных.
Если вы в обычном режиме (не в режиме восстановления) выполните DROP USER или DROP ROLE
для роли с возможностью подключения, в момент, когда этот пользователь подключён, на данном
пользователе это никак не отразится — он останется подключённым. Однако переподключиться
он уже не сможет. Это же поведение действует в режиме восстановления — если выполнить DROP
USER на ведущем сервере, пользователь не будет отключён от резервного.
Сборщик статистики работает во время восстановления. Все операции сканирования, чтения, бло-
ки, использование индексов и т. п. будут записаны обычным образом на резервном сервере. Дей-
ствия, происходящие при проигрывании, не будут дублировать действия на ведущем сервере,
то есть проигрывание команды вставки не увеличит значение столбца Inserts в представлении
pg_stat_user_tables. Файлы статистики удаляются с началом восстановления, таким образом, ста-
тистика на ведущем сервере и резервном будет разной. Это является особенностью, не ошибкой.
Автоматическая очистка не работает во время восстановления. Она запустится в обычном режиме
после завершения восстановления.
Во время восстановления активен фоновый процесс записи, он обрабатывает точки перезапуска
(подобно контрольным точкам на ведущем сервере) и выполняет обычную очистку блоков. В том
числе он может обновлять вспомогательные биты, сохранённые на резервном. Во время восста-
новления принимается команда CHECKPOINT, но она производит точку перезапуска, а не создаёт
новую точку восстановления.
26.5.4. Ссылки на параметры горячего резерва
Различные параметры были упомянуты выше в Подразделе 26.5.2 и Подразделе 26.5.3.
668Отказоустойчивость, баланси-
ровка нагрузки и репликация
На ведущем могут применяться параметры wal_level и vacuum_defer_cleanup_age. Параметры
max_standby_archive_delay и max_standby_streaming_delay на ведущем не действуют.
На резервном сервере могут применяться параметры hot_standby, max_standby_archive_delay и
max_standby_streaming_delay. Параметр vacuum_defer_cleanup_age на нём не действует, пока сер-
вер остаётся в режиме резервного сервера. Но если он станет ведущим, его значение вступит в
силу.
26.5.5. Ограничения
Имеются следующие ограничения горячего резерва. Они могут и скорее всего будут исправлены
в следующих выпусках:
• Требуется информация о всех запущенных транзакциях перед тем как будет создан снимок
данных. Транзакции, использующие большое количество подтранзакций (в настоящий момент
больше 64), будут задерживать начало соединения только для чтения до завершения самой
длинной пишущей транзакции. При возникновении этой ситуации поясняющее сообщение бу-
дет записано в журнал сервера.
• Подходящие стартовые точки для запросов на резервном сервере создаются при каждой кон-
трольной точке на главном. Если резервный сервер отключается, в то время как главный был
в отключённом состоянии, может оказаться невозможным возобновить его работу в режиме
горячего резерва, до того, как запустится ведущий и добавит следующие стартовые точки в
журналы WAL. Подобная ситуация не является проблемой для большинства случаев, в кото-
рых она может произойти. Обычно, если ведущий сервер выключен и больше не доступен, это
является следствием серьёзного сбоя и в любом случае требует преобразования резервного в
новый ведущий. Так же в ситуации, когда ведущий отключён намеренно, проверка готовности
резервного к преобразованию в ведущий тоже является обычной процедурой.
• В конце восстановления блокировки AccessExclusiveLocks, вызванные подготовленными
транзакциями, требуют удвоенное, в сравнении с нормальным, количество блокировок за-
писей таблицы. Если планируется использовать либо большое количество конкурирующих
подготовленных транзакций, обычно вызывающие AccessExclusiveLocks, либо большие
транзакции с применением большого количества AccessExclusiveLocks, то рекомендует-
ся выбрать большое значение параметра max_locks_per_transaction, возможно в два ра-
за большее, чем значение параметра на ведущем сервере. Всё это не имеет значения, когда
max_prepared_transactions равно 0.
• Уровень изоляции транзакции Serializable в настоящее время недоступен в горячем резерве.
(За подробностями обратитесь к Подразделу 13.2.3 и Подразделу 13.4.1) Попытка выставить
для транзакции такой уровень изоляции в режиме горячего резерва вызовет ошибку.
669</li>
</ol>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    
      
        <li><a href="http://localhost:4000/page17/" class="btn">Previous</a></li>
      
    

    
    
      <li><a href="http://localhost:4000">1</a></li>
    

    
    
      
      
      <li>…</li>
    

    
    
    

    
      
        
        
        
        <li><a href="http://localhost:4000/page16/">16</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page17/">17</a></li>
      
    
      
        <li><strong class="current-page">18</strong></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page19/">19</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page20/">20</a></li>
      
    

    
    
      <li>…</li>
    

    
      <li><a href="http://localhost:4000/page36/">36</a></li>
    

    
    
      <li><a href="http://localhost:4000/page19/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Sergey Khatsiola. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-130427752-1', 'auto');  
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>


          

</body>
</html>