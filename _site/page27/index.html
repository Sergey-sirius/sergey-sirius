<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Последние посты &#8211; Sirius Blog</title>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130427752-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130427752-1');
</script>

</head>
<meta name="description" content="Describtion ..">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/abstract-1.jpg">

<meta name="twitter:title" content="Последние посты">
<meta name="twitter:description" content="Describtion ..">
<meta name="twitter:creator" content="@2hotab2">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Последние посты">
<meta property="og:description" content="Describtion ..">
<meta property="og:url" content="http://localhost:4000/page27/">
<meta property="og:site_name" content="Sirius Blog">





<link rel="canonical" href="http://localhost:4000/page27/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Sirius Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.jpg">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.jpg">
<!-- 114x72 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x72" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.jpg">
<!-- 144x72 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x72" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.jpg">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Sergey Khatsiola photo" class="author-photo">
					<h4>Sergey Khatsiola</h4>
					<p>Кратко обо мне ...</p>
				</li>
				<li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:2hotab2@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				<li>
					<a href="https://twitter.com/2hotab2"><i class="fa fa-fw fa-twitter"></i> Twitter</a>
				</li>
				<li>
					<a href="https://facebook.com/sergej.ha1"><i class="fa fa-fw fa-facebook"></i> Facebook</a>
				</li>
				
				
				<li>
					<a href="https://github.com/Sergey-sirius"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	    
	    <li><a href="http://localhost:4000/handbook/" >HandBook</a></li>
	  
	    
	    <li><a href="https://github.com/Sergey-sirius" target="_blank">Main Link</a></li>
	  
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/abstract-1.jpg" alt="Последние посты">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Sirius Blog</h1>
      <h2>Последние посты</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" title="Глава 14. Оптимизация производительности"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 14. Оптимизация производительности"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~45 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-014/" rel="bookmark" title="Глава 14. Оптимизация производительности" itemprop="url">Глава 14. Оптимизация производительности</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 14. Оптимизация производительности</p>

<p>Быстродействие запросов зависит от многих факторов. На некоторые из них могут воздейство-
вать пользователи, а другие являются фундаментальными особенностями системы. В этой главе
приводятся полезные советы, которые помогут понять их и оптимизировать производительность
PostgreSQL.
14.1. Использование EXPLAIN
Выполняя любой полученный запрос, PostgreSQL разрабатывает для него план запроса. Выбор
правильного плана, соответствующего структуре запроса и характеристикам данным, крайне ва-
жен для хорошей производительности, поэтому в системе работает сложный планировщик, зада-
ча которого — подобрать хороший план. Узнать, какой план был выбран для какого-либо запроса,
можно с помощью команды EXPLAIN. Понимание плана — это искусство, и чтобы овладеть им,
нужен определённый опыт, но этот раздел расскажет о самых простых вещах.
Приведённые ниже примеры показаны на тестовой базе данных, которая создаётся для выявления
регрессий в исходных кодах PostgreSQL текущей версии. Для неё предварительно выполняется
VACUUM ANALYZE. Вы должны получить похожие результаты, если возьмёте ту же базу данных и
проделаете следующие действия, но примерная стоимость и ожидаемое число строк у вас может
немного отличаться из-за того, что статистика команды ANALYZE рассчитывается по случайной
выборке, а оценки стоимости зависят от конкретной платформы.
В этих примерах используется текстовый формат вывода EXPLAIN, принятый по умолчанию, как
более компактный и удобный для восприятия человеком. Если вывод EXPLAIN нужно передать ка-
кой-либо программе для дальнейшего анализа, лучше использовать один из машинно-ориентиро-
ванных форматов (XML, JSON или YAML).
14.1.1. Азы EXPLAIN
Структура плана запроса представляет собой дерево узлов плана. Узлы на нижнем уровне дере-
ва — это узлы сканирования, которые возвращают необработанные данные таблицы. Разным ти-
пам доступа к таблице соответствуют разные узлы: последовательное сканирование, сканирование
индекса и сканирование битовой карты. Источниками строк могут быть не только таблицы, но и
например, предложения VALUES и функции, возвращающие множества во FROM, и они представля-
ются отдельными типами узлов сканирования. Если запрос требует объединения, агрегатных вы-
числений, сортировки или других операций с исходными строками, над узлами сканирования по-
являются узлы, обозначающие эти операции. И так как обычно операции могут выполняться раз-
ными способами, на этом уровне тоже могут быть узлы разных типов. В выводе команды EXPLAIN
для каждого узла в дереве плана отводится одна строка, где показывается базовый тип узла плюс
оценка стоимости выполнения данного узла, которую сделал для него планировщик. Если для уз-
ла выводятся дополнительные свойства, в вывод могут добавляться дополнительные строки, с от-
ступом от основной информации узла. В самой первой строке (основной строке самого верхнего
узла) выводится общая стоимость выполнения для всего плана; именно это значение планировщик
старается минимизировать.
Взгляните на следующий простейший пример, просто иллюстрирующий формат вывода:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Этот запрос не содержит предложения WHERE, поэтому он должен просканировать все строки таб-
лицы, так что планировщик выбрал план простого последовательного сканирования. Числа, пере-
численные в скобках (слева направо), имеют следующий смысл:
422Оптимизация производительности
• Приблизительная стоимость запуска. Это время, которое проходит, прежде чем начнётся этап
вывода данных, например для сортирующего узла это время сортировки.
• Приблизительная общая стоимость. Она вычисляется в предположении, что узел плана вы-
полняется до конца, то есть возвращает все доступные строки. На практике родительский
узел может досрочно прекратить чтение строк дочернего (см. приведённый ниже пример с
LIMIT).
• Ожидаемое число строк, которое должен вывести этот узел плана. При этом так же предпола-
гается, что узел выполняется до конца.
• Ожидаемый средний размер строк, выводимых этим узлом плана (в байтах).
Стоимость может измеряться в произвольных единицах, определяемых параметрами планировщи-
ка (см. Подраздел 19.7.2). Традиционно единицей стоимости считается операция чтения страницы
с диска; то есть seq_page_cost обычно равен 1.0, а другие параметры задаётся относительно него.
Примеры в этом разделе выполняются со стандартными параметрами стоимости.
Важно понимать, что стоимость узла верхнего уровня включает стоимость всех его потомков.
Также важно осознавать, что эта стоимость отражает только те факторы, которые учитывает пла-
нировщик. В частности, она не зависит от времени, необходимого для передачи результирующих
строк клиенту, хотя оно может составлять значительную часть общего времени выполнения за-
проса. Тем не менее планировщик игнорирует эту величину, так как он всё равно не сможет из-
менить её, выбрав другой план. (Мы верим в то, что любой правильный план запроса выдаёт один
и тот же набор строк.)
Значение rows здесь имеет особенность — оно выражает не число строк, обработанных или про-
сканированных узлом плана, а число строк, выданных этим узлом. Часто оно окажется меньше
числа просканированных строк в результате применённой к узлу фильтрации по условиям WHERE.
В идеале, на верхнем уровне это значение будет приблизительно равно числу строк, которое фак-
тически возвращает, изменяет или удаляет запрос.
Возвращаясь к нашему примеру:
EXPLAIN SELECT * FROM tenk1;
QUERY PLAN
————————————————————-
Seq Scan on tenk1 (cost=0.00..458.00 rows=10000 width=244)
Эти числа получаются очень просто. Выполните:
SELECT relpages, reltuples FROM pg_class WHERE relname = ‘tenk1’;
и вы увидите, что tenk1 содержит 358 страниц диска и 10000 строк. Общая стоимость вычисляется
как (число_чтений_диска * seq_page_cost) + (число_просканированных_строк * cpu_tuple_cost). По
умолчанию, seq_page_cost равно 1.0, а cpu_tuple_cost — 0.01, так что приблизительная стоимость
запроса равна (358 * 1.0) + (10000 * 0.01) = 458.
Теперь давайте изменим запрос, добавив в него предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;
QUERY PLAN
————————————————————
Seq Scan on tenk1 (cost=0.00..483.00 rows=7001 width=244)
Filter: (unique1 &lt; 7000)
Заметьте, что в выводе EXPLAIN показано, что условие WHERE применено как «фильтр» к узлу плана
Seq Scan (Последовательное сканирование). Это означает, что узел плана проверяет это условие
для каждого просканированного им узла и выводит только те строки, которые удовлетворяют ему.
Предложение WHERE повлияло на оценку числа выходных строк. Однако при сканировании потре-
423Оптимизация производительности
буется прочитать все 10000 строк, поэтому общая стоимость не уменьшилась. На деле она даже
немного увеличилась (на 10000 * cpu_operator_cost, если быть точными), отражая дополнительное
время, которое потребуется процессору на проверку условия WHERE.
Фактическое число строк результата этого запроса будет равно 7000, но значение rows даёт толь-
ко приблизительное значение. Если вы попытаетесь повторить этот эксперимент, вы можете по-
лучить немного другую оценку; более того, она может меняться после каждой команды ANALYZE,
так как ANALYZE получает статистику по случайной выборке таблицы.
Теперь давайте сделаем ограничение более избирательным:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.01 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
В данном случае планировщик решил использовать план из двух этапов: сначала дочерний узел
плана просматривает индекс и находит в нём адреса строк, соответствующих условию индекса, а
затем верхний узел собственно выбирает эти строки из таблицы. Выбирать строки по отдельности
гораздо дороже, чем просто читать их последовательно, но так как читать придётся не все стра-
ницы таблицы, это всё равно будет дешевле, чем сканировать всю таблицу. (Использование двух
уровней плана объясняется тем, что верхний узел сортирует адреса строк, выбранных из индек-
са, в физическом порядке, прежде чем читать, чтобы снизить стоимость отдельных чтений. Слово
«bitmap» (битовая карта) в имени узла обозначает механизм, выполняющий сортировку.)
Теперь давайте добавим ещё одно условие в предложение WHERE:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = ‘xxx’;
QUERY PLAN
————————————————————————–
Bitmap Heap Scan on tenk1 (cost=5.01..229.40 rows=1 width=244)
Recheck Cond: (unique1 &lt; 100)
Filter: (stringu1 = ‘xxx’::name)
-&gt; Bitmap Index Scan on tenk1_unique1
(cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
Добавленное условие stringu1 = ‘xxx’ уменьшает оценку числа результирующих строк, но не
стоимость запроса, так как просматриваться будет тот же набор строк, что и раньше. Заметьте, что
условие на stringu1 не добавляется в качестве условия индекса, так как индекс построен только
по столбцу unique1. Вместо этого оно применяется как фильтр к строкам, полученным по индексу.
В результате стоимость даже немного увеличилась, отражая добавление этой проверки.
В некоторых случаях планировщик предпочтёт «простой» план сканирования индекса:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
QUERY PLAN
—————————————————————————
Index Scan using tenk1_unique1 on tenk1 (cost=0.29..8.30 rows=1 width=244)
Index Cond: (unique1 = 42)
В плане такого типа строки таблицы выбираются в порядке индекса, в результате чего чтение их
обходится дороже, но так как их немного, дополнительно сортировать положения строк не стоит.
Вы часто будете встречать этот тип плана в запросах, которые выбирают всего одну строку. Также
424Оптимизация производительности
он часто задействуется там, где условие ORDER BY соответствует порядку индекса, так как в этих
случаях для выполнения ORDER BY не требуется дополнительный шаг сортировки.
Если в таблице есть отдельные индексы по разным столбцам, фигурирующим в WHERE, планировщик
может выбрать сочетание этих индексов (с AND и OR):
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
————————————————————————————-
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
Index Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
Index Cond: (unique2 &gt; 9000)
Но для этого потребуется обойти оба индекса, так что это не обязательно будет выгоднее, чем
просто просмотреть один индекс, а второе условие обработать как фильтр. Измените диапазон и
вы увидите, как это повлияет на план.
Следующий пример иллюстрирует эффекты LIMIT:
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
————————————————————————————-
Limit (cost=0.29..14.48 rows=2 width=244)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..71.27 rows=10 width=244)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Это тот же запрос, что и раньше, но добавили мы в него LIMIT, чтобы возвращались не все стро-
ки, и планировщик решает выполнять запрос по-другому. Заметьте, что общая стоимость и число
строк для узла Index Scan рассчитываются в предположении, что он будет выполняться полностью.
Однако узел Limit должен остановиться, получив только пятую часть всех строк, так что его сто-
имость будет составлять одну пятую от вычисленной ранее, и это и будет итоговой оценкой стои-
мости запроса. С другой стороны, планировщик мог бы просто добавить в предыдущий план узел
Limit, но это не избавило бы от затрат на запуск сканирования битовой карты, а значит, общая
стоимость была бы выше 25 единиц.
Давайте попробуем соединить две таблицы по столбцам, которые мы уже использовали:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
Index Cond: (unique2 = t1.unique2)
В этом плане появляется узел соединения с вложенным циклом, на вход которому поступают дан-
ные от двух его потомков, узлов сканирования. Эту структуру плана отражает отступ основных
425Оптимизация производительности
строк его узлов. Первый, или «внешний», потомок соединения — узел сканирования битовой кар-
ты, похожий на те, что мы видели раньше. Его стоимость и число строк те же, что мы получили
бы для запроса SELECT … WHERE unique1 &lt; 10, так как к этому узлу добавлено предложение
WHERE unique1 &lt; 10. Условие t1.unique2 = t2.unique2 ещё не учитывается, поэтому оно не влияет
на число строк узла внешнего сканирования. Узел соединения с вложенным циклом будет выпол-
нять узел «внутреннего» потомка для каждой строки, полученной из внешнего потомка. Значения
столбцов из текущей внешней строки могут использоваться во внутреннем сканировании (в дан-
ном случае это значение t1.unique2), поэтому мы получаем план и стоимость примерно такие,
как и раньше для простого запроса SELECT … WHERE t2.unique2 = константа. (На самом деле
оценочная стоимость немного меньше, в предположении, что при неоднократном сканировании
индекса по t2 положительную роль сыграет кеширование.) В результате стоимость узла цикла
складывается из стоимости внешнего сканирования, цены внутреннего сканирования, умножен-
ной на число строк (здесь 10 * 7.91), и небольшой наценки за обработку соединения.
В этом примере число выходных строк соединения равно произведению чисел строк двух узлов
сканирования, но это не всегда будет так, потому что в дополнительных условиях WHERE могут
упоминаться обе таблицы, так что применить их можно будет только в точке соединения, а не в
одном из узлов сканирования. Например:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t2.unique2 &lt; 10 AND t1.hundred &lt; t2.hundred;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..49.46 rows=33 width=488)
Join Filter: (t1.hundred &lt; t2.hundred)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
Index Cond: (unique1 &lt; 10)
-&gt; Materialize (cost=0.29..8.51 rows=10 width=244)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..8.46 rows=10
width=244)
Index Cond: (unique2 &lt; 10)
Условие t1.hundred &lt; t2.hundred не может быть проверено в индексе tenk2_unique2, поэтому оно
применяется в узле соединения. Это уменьшает оценку числа выходных строк, тогда как число
строк в узлах сканирования не меняется.
Заметьте, что здесь планировщик решил «материализовать» внутреннее отношение соединения,
поместив поверх него узел плана Materialize (Материализовать). Это значит, что сканирование
индекса t2 будет выполняться только единожды, при том, что узлу вложенного цикла соединения
потребуется прочитать данные десять раз, по числу строк во внешнем соединении. Узел Materialize
сохраняет считанные данные в памяти, чтобы затем выдать их из памяти на следующих проходах.
Выполняя внешние соединения, вы можете встретить узлы плана с присоединёнными условиями,
как обычными «Filter», так и «Join Filter» (Фильтр соединения). Условия Join Filter формируются
из предложения ON для внешнего соединения, так что если строка не удовлетворяет условию Join
Filter, она всё же выдаётся как строка, дополненная значениями NULL. Обычное же условие Filter
применяется после правил внешнего соединения и поэтому полностью исключает строки. Во внут-
реннем соединении оба этих фильтра работают одинаково.
Если немного изменить избирательность запроса, мы можем получить совсем другой план соеди-
нения:
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
426Оптимизация производительности
QUERY PLAN
——————————————————————————————
Hash Join (cost=230.47..713.98 rows=101 width=488)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0)
Index Cond: (unique1 &lt; 100)
Здесь планировщик выбирает соединение по хешу, при котором строки одной таблицы записыва-
ются в хеш-таблицу в памяти, после чего сканируется другая таблица и для каждой её строки про-
веряется соответствие по хеш-таблице. Обратите внимание, что и здесь отступы отражают струк-
туру плана: результат сканирования битовой карты по tenk1 подаётся на вход узлу Hash, который
конструирует хеш-таблицу. Затем она передаётся узлу Hash Join, который читает строки из узла
внешнего потомка и проверяет их по этой хеш-таблице.
Ещё один возможный тип соединения — соединение слиянием:
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=198.11..268.19 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Sort (cost=197.83..200.33 rows=1000 width=244)
Sort Key: t2.unique2
-&gt; Seq Scan on onek t2 (cost=0.00..148.00 rows=1000 width=244)
Соединение слиянием требует, чтобы входные данные для него были отсортированы по ключам
соединения. В этом плане данные tenk1 сортируются после сканирования индекса, при котором
все строки просматриваются в правильном порядке, но таблицу onek выгоднее оказывается после-
довательно просканировать и отсортировать, так как в этой таблице нужно обработать гораздо
больше строк. (Последовательное сканирование и сортировка часто бывает быстрее сканирования
индекса, когда нужно отсортировать много строк, так как при сканировании по индексу обраще-
ния к диску не упорядочены.)
Один из способов посмотреть различные планы — принудить планировщик не считать выбранную
им стратегию самой выгодной, используя флаги, описанные в Подразделе 19.7.1. (Это полезный,
хотя и грубый инструмент. См. также Раздел 14.3.) Например, если мы убеждены, что последова-
тельное сканирование и сортировка — не лучший способ обработать таблицу onek в предыдущем
примере, мы можем попробовать
SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————
Merge Join (cost=0.56..292.65 rows=10 width=488)
Merge Cond: (t1.unique2 = t2.unique2)
427Оптимизация производительности
-&gt; Index Scan using tenk1_unique2 on tenk1 t1 (cost=0.29..656.28 rows=101
width=244)
Filter: (unique1 &lt; 100)
-&gt; Index Scan using onek_unique2 on onek t2 (cost=0.28..224.79 rows=1000
width=244)
Видно, что планировщик считает сортировку onek со сканированием индекса примерно на 12%
дороже, чем последовательное сканирование и сортировку. Конечно, может возникнуть вопрос —
а правильно ли это? Мы можем ответить на него, используя описанную ниже команду EXPLAIN
ANALYZE.
14.1.2. EXPLAIN ANALYZE
Точность оценок планировщика можно проверить, используя команду EXPLAIN с параметром
ANALYZE. С этим параметром EXPLAIN на самом деле выполняет запрос, а затем выводит фактиче-
ское число строк и время выполнения, накопленное в каждом узле плана, вместе с теми же оцен-
ками, что выдаёт обычная команда EXPLAIN. Например, мы можем получить примерно такой ре-
зультат:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
QUERY PLAN
——————————————————————————————–
Nested Loop (cost=4.65..118.62 rows=10 width=488) (actual time=0.128..0.377 rows=10
loops=1)
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=4.36..39.47 rows=10 width=244) (actual
time=0.057..0.121 rows=10 loops=1)
Recheck Cond: (unique1 &lt; 10)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..4.36 rows=10 width=0)
(actual time=0.024..0.024 rows=10 loops=1)
Index Cond: (unique1 &lt; 10)
-&gt; Index Scan using tenk2_unique2 on tenk2 t2 (cost=0.29..7.91 rows=1 width=244)
(actual time=0.021..0.022 rows=1 loops=10)
Index Cond: (unique2 = t1.unique2)
Planning time: 0.181 ms
Execution time: 0.501 ms
Заметьте, что значения «actual time» (фактическое время) приводятся в миллисекундах, тогда как
оценки cost (стоимость) выражаются в произвольных единицах, так что они вряд ли совпадут.
Обычно важнее определить, насколько приблизительная оценка числа строк близка к действи-
тельности. В этом примере они в точности совпали, но на практике так бывает редко.
В некоторых планах запросов некоторый внутренний узел может выполняться неоднократно. На-
пример, внутреннее сканирование индекса будет выполняться для каждой внешней строки во вло-
женном цикле верхнего уровня. В таких случаях значение loops (циклы) показывает, сколько все-
го раз выполнялся этот узел, а фактическое время и число строк вычисляется как среднее по всем
итерациям. Это делается для того, чтобы полученные значения можно было сравнить с выводимы-
ми приблизительными оценками. Чтобы получить общее время, затраченное на выполнение узла,
время одной итерации нужно умножить на значение loops. В показанном выше примере мы по-
тратили в общей сложности 0.220 мс на сканирование индекса в tenk2.
В ряде случаев EXPLAIN ANALYZE выводит дополнительную статистику по выполнению, включаю-
щую не только время выполнения узлов и число строк. Для узлов Sort и Hash, например выводится
следующая информация:
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;
428Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Sort (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100
loops=1)
Sort Key: t1.fivethous
Sort Method: quicksort Memory: 77kB
-&gt; Hash Join (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427
rows=100 loops=1)
Hash Cond: (t2.unique2 = t1.unique2)
-&gt; Seq Scan on tenk2 t2 (cost=0.00..445.00 rows=10000 width=244) (actual
time=0.007..2.583 rows=10000 loops=1)
-&gt; Hash (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659
rows=100 loops=1)
Buckets: 1024 Batches: 1 Memory Usage: 28kB
-&gt; Bitmap Heap Scan on tenk1 t1 (cost=5.07..229.20 rows=101 width=244)
(actual time=0.080..0.526 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101
width=0) (actual time=0.049..0.049 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.194 ms
Execution time: 8.008 ms
Для узла Sort показывается использованный метод и место сортировки (в памяти или на диске),
а также задействованный объём памяти. Для узла Hash выводится число групп и пакетов хеша, а
также максимальный объём, который заняла в памяти хеш-таблица. (Если число пакетов больше
одного, часть хеш-таблицы будет выгружаться на диск и занимать какое-то пространство, но его
объём здесь не показывается.)
Другая полезная дополнительная информация — число строк, удалённых условием фильтра:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;
QUERY PLAN
——————————————————————————————–
Seq Scan on tenk1 (cost=0.00..483.00 rows=7000 width=244) (actual time=0.016..5.107
rows=7000 loops=1)
Filter: (ten &lt; 7)
Rows Removed by Filter: 3000
Planning time: 0.083 ms
Execution time: 5.905 ms
Эти значения могут быть особенно ценны для условий фильтра, применённых к узлам соединения.
Строка «Rows Removed» выводится, только когда условие фильтра отбрасывает минимум одну про-
сканированную строку или потенциальную пару соединения, если это узел соединения.
Похожую ситуацию можно наблюдать при сканировании «неточного» индекса. Например, рас-
смотрим этот план поиска многоугольников, содержащих указанную точку:
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Seq Scan on polygon_tbl (cost=0.00..1.05 rows=1 width=32) (actual time=0.044..0.044
rows=0 loops=1)
Filter: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Filter: 4
Planning time: 0.040 ms
Execution time: 0.083 ms
429Оптимизация производительности
Планировщик полагает (и вполне справедливо), что таблица слишком мала для сканирования по
индексу, поэтому он выбирает последовательное сканирование, при котором все строки отбрасы-
ваются условием фильтра. Но если мы принудим его выбрать сканирование по индексу, мы полу-
чим:
SET enable_seqscan TO off;
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon ‘(0.5,2.0)’;
QUERY PLAN
——————————————————————————————–
Index Scan using gpolygonind on polygon_tbl (cost=0.13..8.15 rows=1 width=32) (actual
time=0.062..0.062 rows=0 loops=1)
Index Cond: (f1 @&gt; ‘((0.5,2))’::polygon)
Rows Removed by Index Recheck: 1
Planning time: 0.034 ms
Execution time: 0.144 ms
Здесь мы видим, что индекс вернул одну потенциально подходящую строку, но затем она была
отброшена при перепроверке условия индекса. Это объясняется тем, что индекс GiST является
«неточным» для проверок включений многоугольников: фактически он возвращает строки с мно-
гоугольниками, перекрывающими точку по координатам, а затем для этих строк нужно выполнять
точную проверку.
EXPLAIN принимает параметр BUFFERS (который также можно применять с ANALYZE), включающий
ещё более подробную статистику выполнения запроса:
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
QUERY PLAN
——————————————————————————————–
Bitmap Heap Scan on tenk1 (cost=25.08..60.21 rows=10 width=244) (actual
time=0.323..0.342 rows=10 loops=1)
Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
Buffers: shared hit=15
-&gt; BitmapAnd (cost=25.08..25.08 rows=10 width=0) (actual time=0.309..0.309 rows=0
loops=1)
Buffers: shared hit=7
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Buffers: shared hit=2
-&gt; Bitmap Index Scan on tenk1_unique2 (cost=0.00..19.78 rows=999 width=0)
(actual time=0.227..0.227 rows=999 loops=1)
Index Cond: (unique2 &gt; 9000)
Buffers: shared hit=5
Planning time: 0.088 ms
Execution time: 0.423 ms
Значения, которые выводятся с параметром BUFFERS, помогают понять, на какие части запроса
приходится большинство операций ввода-вывода.
Не забывайте, что EXPLAIN ANALYZE действительно выполняет запрос, хотя его результаты могут
не показываться, а заменяться выводом команды EXPLAIN. Поэтому при таком анализе возможны
побочные эффекты. Если вы хотите проанализировать запрос, изменяющий данные, но при этом
сохранить прежние данные таблицы, вы можете откатить транзакцию после запроса:
BEGIN;
EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;
430Оптимизация производительности
QUERY PLAN
——————————————————————————————–
Update on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual time=14.628..14.628
rows=0 loops=1)
-&gt; Bitmap Heap Scan on tenk1 (cost=5.07..229.46 rows=101 width=250) (actual
time=0.101..0.439 rows=100 loops=1)
Recheck Cond: (unique1 &lt; 100)
-&gt; Bitmap Index Scan on tenk1_unique1 (cost=0.00..5.04 rows=101 width=0)
(actual time=0.043..0.043 rows=100 loops=1)
Index Cond: (unique1 &lt; 100)
Planning time: 0.079 ms
Execution time: 14.727 ms
ROLLBACK;
Как показано в этом примере, когда выполняется команда INSERT, UPDATE или DELETE, собственно
изменение данных в таблице происходит в узле верхнего уровня Insert, Update или Delete. Узлы
плана более низких уровней выполняют работу по нахождению старых строк и/или вычислению
новых данных. Поэтому вверху мы видим тот же тип сканирования битовой карты, что и раньше,
только теперь его вывод подаётся узлу Update, который сохраняет изменённые строки. Стоит от-
метить, что узел, изменяющий данные, может выполняться значительное время (в данном случае
это составляет львиную часть всего времени), но планировщик не учитывает эту работу в оценке
общей стоимости. Это связано с тем, что эта работа будет одинаковой при любом правильном пла-
не запроса, и поэтому на выбор плана она не влияет.
Когда команда UPDATE или DELETE имеет дело с иерархией наследования, вывод может быть таким:
EXPLAIN UPDATE parent SET f2 = f2 + 1 WHERE f1 = 101;
QUERY PLAN
———————————————————————————–
Update on parent (cost=0.00..24.53 rows=4 width=14)
Update on parent
Update on child1
Update on child2
Update on child3
-&gt; Seq Scan on parent (cost=0.00..0.00 rows=1 width=14)
Filter: (f1 = 101)
-&gt; Index Scan using child1_f1_key on child1 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child2_f1_key on child2 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
-&gt; Index Scan using child3_f1_key on child3 (cost=0.15..8.17 rows=1 width=14)
Index Cond: (f1 = 101)
В этом примере узлу Update помимо изначально упомянутой в запросе родительской таблицы нуж-
но обработать ещё три дочерние таблицы. Поэтому формируются четыре плана сканирования, по
одному для каждой таблицы. Ясности ради для узла Update добавляется примечание, показываю-
щее, какие именно таблицы будут изменяться, в том же порядке, в каком они идут в соответствую-
щих внутренних планах. (Эти примечания появились в PostgreSQL 9.5; до этого о целевых таблицах
приходилось догадываться, изучая внутренние планы узла.)
Под заголовком Planning time (Время планирования) команда EXPLAIN ANALYZE выводит время,
затраченное на построение плана запроса из разобранного запроса и его оптимизацию. Время
собственно разбора или перезаписи запроса в него не включается.
Значение Execution time (Время выполнения), выводимое командой EXPLAIN ANALYZE, включает
продолжительность запуска и остановки исполнителя запроса, а также время выполнения всех
сработавших триггеров, но не включает время разбора, перезаписи и планирования запроса. Вре-
мя, потраченное на выполнение триггеров BEFORE (если такие имеются) включается во время соот-
431Оптимизация производительности
ветствующих узлов Insert, Update или Delete node; но время выполнения триггеров AFTER не учиты-
вается, так как триггеры AFTER срабатывают после выполнения всего плана. Общее время, прове-
дённое в каждом триггере (BEFORE или AFTER), также выводится отдельно. Заметьте, что триггеры
отложенных ограничений выполняются только в конце транзакции, так что время их выполнения
EXPLAIN ANALYZE не учитывает.
14.1.3. Ограничения
Время выполнения, измеренное командой EXPLAIN ANALYZE, может значительно отличаться от
времени выполнения того же запроса в обычном режиме. Тому есть две основных причины. Во-
первых, так как при анализе никакие строки результата не передаются клиенту, время ввода/вы-
вода и передачи по сети не учитывается. Во-вторых, может быть существенной дополнительная
нагрузка, связанная с функциями измерений EXPLAIN ANALYZE, особенно в системах, где вызов
gettimeofday() выполняется медленно. Для измерения этой нагрузки вы можете воспользоваться
утилитой pg_test_timing.
Результаты EXPLAIN не следует распространять на ситуации, значительно отличающиеся от тех, в
которых вы проводите тестирование. В частности, не следует полагать, что выводы, полученные
для игрушечной таблицы, будут применимы и для настоящих больших таблиц. Оценки стоимости
нелинейны и планировщик может выбирать разные планы в зависимости от размера таблицы. На-
пример, в крайнем случае вся таблица может уместиться в одну страницу диска, и тогда вы почти
наверняка получите план последовательного сканирования, независимо от того, есть у неё и ин-
дексы или нет. Планировщик понимает, что для обработки таблицы ему в любом случае потребу-
ется прочитать одну страницу, так что нет никакого смысла обращаться к ещё одной странице за
индексом. (Мы наблюдали это в показанном выше примере с polygon_tbl.)
Бывает, что фактическое и приближённо оценённое значения не совпадают, но в этом нет ничего
плохого. Например, это возможно, когда выполнение плана узла прекращается преждевременно
из-за указания LIMIT или подобного эффекта. Например, для запроса с LIMIT, который мы пробо-
вали раньше:
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;
QUERY PLAN
——————————————————————————————–
Limit (cost=0.29..14.71 rows=2 width=244) (actual time=0.177..0.249 rows=2 loops=1)
-&gt; Index Scan using tenk1_unique2 on tenk1 (cost=0.29..72.42 rows=10 width=244)
(actual time=0.174..0.244 rows=2 loops=1)
Index Cond: (unique2 &gt; 9000)
Filter: (unique1 &lt; 100)
Rows Removed by Filter: 287
Planning time: 0.096 ms
Execution time: 0.336 ms
Оценки стоимости и числа строк для узла Index Scan показываются в предположении, что этот узел
будет выполняться до конца. Но в действительности узел Limit прекратил запрашивать строки,
как только получил первые две, так что фактическое число строк равно 2 и время выполнения
запроса будет меньше, чем рассчитал планировщик. Но это не ошибка, а просто следствие того,
что оценённые и фактические значения выводятся по-разному.
Соединения слиянием также имеют свои особенности, которые могут ввести в заблуждение. Со-
единение слиянием прекратит читать один источник данных, если второй будет прочитан до кон-
ца, а следующее значение ключа в первом больше последнего значения во втором. В этом случае
пар строк больше не будет, так что сканировать первый источник дальше нет смысла. В результате
будут прочитаны не все строки одного потомка и вы получите тот же эффект, что и с LIMIT. Кро-
ме того, если внешний (первый) потомок содержит строки с повторяющимися значениями клю-
ча, внутренний (второй) потомок сдвинется назад и повторно выдаст строки для этого значения
ключа. EXPLAIN ANALYZE считает эти повторяющиеся строки, как если бы это действительно были
дополнительные строки внутреннего источника. Когда во внешнем узле много таких повторений
432Оптимизация производительности
ключей, фактическое число строк, подсчитанное для внутреннего узла, может значительно пре-
вышать число строк в соответствующей таблице.
Для узлов BitmapAnd (Логическое произведение битовых карт) и BitmapOr (Логическое сложение
битовых карт) фактическое число строк всегда равно 0 из-за ограничений реализации.
Обычно EXPLAIN выводит подробности для каждого узла плана, сгенерированного планировщиком.
Однако бывают ситуации, когда исполнитель может определить, что некоторые узлы не требуют-
ся, и не выполнять их; в настоящее время это поддерживает только узел Append. Узел этого типа
может отбросить подчинённые узлы, определив, что они не выдадут ни одной записи, нужной для
запроса. Понять, что узлы были удалены таким образом, можно по наличию свойства «Subplans
Removed» (Подпланов удалено) в выводе EXPLAIN.
14.2. Статистика, используемая планировщиком
14.2.1. Статистика по одному столбцу
Как было показано в предыдущем разделе, планировщик запросов должен оценить число строк,
возвращаемых запросов, чтобы сделать правильный выбор в отношении плана запроса. В этом
разделе кратко описывается статистика, которую использует система для этих оценок.
В частности, статистика включает общее число записей в каждой таблице и индексе, а также
число дисковых блоков, которые они занимают. Эта информация содержится в таблице pg_class,
в столбцах reltuples и relpages. Получить её можно, например так:
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE ‘tenk1%’;
relname
| relkind | reltuples | relpages
———————-+———+———–+———-
tenk1
| r
|
10000 |
358
tenk1_hundred
| i
|
10000 |
30
tenk1_thous_tenthous | i
|
10000 |
30
tenk1_unique1
| i
|
10000 |
30
tenk1_unique2
| i
|
10000 |
30
(5 rows)
Здесь мы видим, что tenk1 содержит 10000 строк данных и столько же строк в индексах (что неуди-
вительно), но объём индексов гораздо меньше таблицы.
Для большей эффективности reltuples и relpages не пересчитываются «на лету», так что они
обычно содержат несколько устаревшие значения. Их обновляют команды VACUUM, ANALYZE и
несколько команд DDL, такие как CREATE INDEX. VACUUM и ANALYZE могут не сканировать всю таб-
лицу (и обычно так и делают), а только вычислить приращение reltuples по части таблицы, так
что результат остаётся приблизительным. В любом случае планировщик пересчитывает значения,
полученные из pg_class, в пропорции к текущему физическому размеру таблицы и таким образом
уточняет приближение.
Большинство запросов возвращают не все строки таблицы, а только немногие из них, ограничен-
ные условиями WHERE. Поэтому планировщику нужно оценить избирательность условий WHERE,
то есть определить, какой процент строк будет соответствовать каждому условию в предложении
WHERE. Нужная для этого информация хранится в системном каталоге pg_statistic. Значения в
pg_statistic обновляются командами ANALYZE и VACUUM ANALYZE и никогда не бывают точными,
даже сразу после обновления.
Для исследования статистики лучше обращаться не непосредственно к таблице pg_statistic, а к
представлению pg_stats, предназначенному для облегчения восприятия этой информации. Кроме
того, представление pg_stats доступно для чтения всем, тогда как pg_statistic — только супер-
433Оптимизация производительности
пользователям. (Это сделано для того, чтобы непривилегированные пользователи не могли ничего
узнать о содержимом таблиц других людей из статистики. Представление pg_stats устроено так,
что оно показывает строки только для тех таблиц, которые может читать данный пользователь.)
Например, мы можем выполнить:
SELECT attname, inherited, n_distinct,
array_to_string(most_common_vals, E’\n’) as most_common_vals
FROM pg_stats
WHERE tablename = ‘road’;
attname | inherited | n_distinct |
most_common_vals
———+———–+————+————————————
name
| f
| -0.363388 | I- 580
Ramp+
|
|
| I- 880
Ramp+
|
|
| Sp Railroad
+
|
|
| I- 580
+
|
|
| I- 680
Ramp
name
| t
| -0.284859 | I- 880
Ramp+
|
|
| I- 580
Ramp+
|
|
| I- 680
Ramp+
|
|
| I- 580
+
|
|
| State Hwy 13
Ramp
(2 rows)
Заметьте, что для одного столбца показываются две строки: одна соответствует полной иерархии
наследования, построенной для таблицы road (inherited=t), и другая относится непосредственно
к таблице road (inherited=f).
Объём информации, сохраняемой в pg_statistic командой ANALYZE, в частности максимальное
число записей в массивах most_common_vals (самые популярные значения) и histogram_bounds
(границы гистограмм) для каждого столбца, можно ограничить на уровне столбцов с помо-
щью команды ALTER TABLE SET STATISTICS или глобально, установив параметр конфигурации
default_statistics_target. В настоящее время ограничение по умолчанию равно 100 записям. Уве-
личивая этот предел, можно увеличить точность оценок планировщика, особенно для столбцов
с нерегулярным распределением данных, ценой большего объёма pg_statistic и, возможно, уве-
личения времени расчёта этой статистики. И напротив, для столбцов с простым распределением
данных может быть достаточно меньшего предела.
Подробнее использование статистики планировщиком описывается в Главе 70.
14.2.2. Расширенная статистика
Часто наблюдается картина, когда медленное выполнение запросов объясняется плохим выбором
плана из-за того, что несколько столбцов, фигурирующих в условиях запроса, оказываются свя-
занными. Обычно планировщик полагает, что несколько условий не зависят друг от друга, а это
предположение оказывается неверным, когда значения этих столбцов коррелируют. Обычная ста-
тистика, которая по природе своей строится по отдельным столбцам, не может выявить корреля-
ции между столбцами. Однако PostgreSQL имеет возможность вычислять многовариантную ста-
тистику, которая может собирать необходимую для этого информацию.
Так как число возможных комбинаций столбцов очень велико, автоматически вычислять много-
вариантную статистику непрактично. Вместо этого можно создать объекты расширенной стати-
стики, чаще называемые просто объектами статистики, чтобы сервер собирал статистику по
некоторым наборам столбцов, представляющим интерес.
Объекты статистики создаются командой CREATE STATISTICS (за подробностями обратитесь к
её описанию). При создании такого объекта просто создаётся запись в каталоге, выражающая
востребованность этой статистики. Собственно сбор данных выполняется командой ANALYZE (при
запуске вручную или фоновом автоанализе). Изучить собранные значения можно в каталоге
pg_statistic_ext.
434Оптимизация производительности
Команда ANALYZE вычисляет расширенную статистику по той же выборке строк таблицы, которая
используется и для вычисления обычной статистики по отдельным столбцам. Так как размер вы-
борки увеличивается с увеличением целевого ограничения статистики для таблицы или любых её
столбцов (как описано в предыдущем разделе), при большем целевом ограничении обычно полу-
чается более точная расширенная статистика, но и времени на её вычисление требуется больше.
В следующих подразделах описываются виды расширенной статистики, поддерживаемые в насто-
ящее время.
14.2.2.1. Функциональные зависимости
Простейший вид расширенной статистики отслеживает функциональные зависимости (это поня-
тие используется в определении нормальных форм баз данных). Мы называем столбец b функцио-
нально зависимым от столбца a, если знания значения a достаточно для определения значения b,
то есть не существует двух строк с одинаковыми значениями a, но разными значениями b. В пол-
ностью нормализованной базе данных функциональные зависимости должны существовать только
в первичных ключах и суперключах. Однако на практике многие наборы данных не нормализуют-
ся полностью по разным причинам; например, денормализация часто производится намеренно по
соображениям производительности.
Существование функциональных зависимостей напрямую влияет на точность оценок в определён-
ных запросах. Если запрос содержит условия как по независимым, так и по зависимым столбцам,
условия по зависимым столбцам дополнительно не сокращают размер результата. Однако без зна-
ния о функциональной зависимости планировщик запросов будет полагать, что все условия неза-
висимы, и недооценит размер результата.
Для информирования планировщика о функциональных зависимостях команда ANALYZE может со-
бирать показатели зависимостей между столбцами. Оценить степень зависимости между всеми
наборами столбцов обошлось бы непозволительно дорого, поэтому сбор данных ограничивается
только теми группами столбцов, которые фигурируют вместе в объекте статистики, определённом
со свойством dependencies. Во избежание ненужных издержек при выполнении ANALYZE и после-
дующем планировании запросов статистику с dependencies рекомендуется создавать только для
групп сильно коррелирующих столбцов.
Взгляните на пример сбора статистики функциональной зависимости:
CREATE STATISTICS stts (dependencies) ON zip, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxname, stxkeys, stxdependencies
FROM pg_statistic_ext
WHERE stxname = ‘stts’;
stxname | stxkeys |
stxdependencies
———+———+——————————————
stts
| 1 5
| {“1 =&gt; 5”: 1.000000, “5 =&gt; 1”: 0.423130}
(1 row)
В показанном случае столбец 1 (код zip) полностью определяет столбец 5 (city), так что коэффи-
циент равен 1.0, тогда как город (столбец city) определяет код ZIP только в 42% всех случаев, что
означает, что многие города (58%) представлены несколькими кодами ZIP.
При вычислении избирательности запроса, в котором задействованы функционально зависимые
столбцы, планировщик корректирует оценки избирательности по условиям, используя коэффици-
енты зависимостей, чтобы не допустить недооценки размера результата.
14.2.2.1.1. Ограничения функциональных зависимостей
Функциональные зависимости в настоящее время применяются только при рассмотрении простых
условий с равенствами, сравнивающих значения столбцов с константами. Они не используются для
улучшения оценок при проверке равенства двух столбцов или сравнении столбца с выражением,
а также в условиях с диапазоном, условиях LIKE или любых других видах условий.
435Оптимизация производительности
Рассматривая функциональные зависимости, планировщик предполагает, что условия по задей-
ствованным столбцам совместимы и таким образом избыточны. Если условия несовместимы, пра-
вильной оценкой должен быть ноль строк, но эта возможность не рассматривается. Например, с
таким запросом
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘94105’;
планировщик отбросит условие с city, так как оно не влияет на избирательность, что верно. Од-
нако он сделает то же предположение и в таком случае:
SELECT * FROM zipcodes WHERE city = ‘San Francisco’ AND zip = ‘90210’;
хотя на самом деле этому запросу будет удовлетворять ноль строк. Но статистика функциональной
зависимости не даёт достаточно информации, чтобы прийти к такому заключению.
Во многих практических ситуациях это предположение обычно удовлетворяется; например, гра-
фический интерфейс приложения для последующего формирования запроса может не допускать
выбор несовместимого сочетания города и кода ZIP. Но когда это не так, статистика функциональ-
ной зависимости может не подойти.
14.2.2.2. Многовариантное число различных значений
Статистика по одному столбцу содержит число различных значений в каждом отдельном столбце.
Оценки числа различных значений в сочетании нескольких столбцов (например, в GROUP BY a,
b) часто оказываются ошибочными, когда планировщик имеет статистические данные только по
отдельным столбцам, что приводит к выбору плохих планов.
Для улучшения таких оценок операция ANALYZE может собирать статистику по различным значе-
ниям для группы столбцов. Как и ранее, это непрактично делать для каждой возможной группы
столбцов, так что данные собираются только по тем группам столбцов, которые указаны в опре-
делении объекта статистики, создаваемого со свойством ndistinct. Данные будут собираться по
всем возможным сочетаниям из двух или нескольких столбцов из перечисленных в определении.
В продолжение предыдущего примера, количества различных значений в таблице ZIP-кодов могут
выглядеть так:
CREATE STATISTICS stts2 (ndistinct) ON zip, state, city FROM zipcodes;
ANALYZE zipcodes;
SELECT stxkeys AS k, stxndistinct AS nd
FROM pg_statistic_ext
WHERE stxname = ‘stts2’;
-[ RECORD 1 ]——————————————————–
k | 1 2 5
nd | {“1, 2”: 33178, “1, 5”: 33178, “2, 5”: 27435, “1, 2, 5”: 33178}
(1 row)
Как видно, есть три комбинации столбцов, имеющих 33178 различных значений: код ZIP и штат;
код ZIP и город; код ZIP, город и штат (то, что все эти числа равны, ожидаемый факт, так как сам
по себе код ZIP в этой таблице уникален). С другой стороны, сочетание города и штата даёт только
27435 различных значений.
Объект статистики ndistinct рекомендуется создавать только для тех сочетаний столбцов, кото-
рые действительно используются при группировке, и только когда неправильная оценка числа
групп может привести к выбору плохих планов. В противном случае усилия, потраченные на вы-
полнение ANALYZE, будут напрасными.
14.3. Управление планировщиком с помощью явных
предложений JOIN
436Оптимизация производительности
Поведением планировщика в некоторой степени можно управлять, используя явный синтаксис
JOIN. Понять, когда и почему это бывает нужно, поможет небольшое введение.
В простом запросе с соединением, например таком:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
планировщик может соединять данные таблицы в любом порядке. Например, он может разрабо-
тать план, в котором сначала A соединяется с B по условию WHERE a.id = b.id, а затем C соединя-
ется с получившейся таблицей по другому условию WHERE. Либо он может соединить B с C, а затем
с A результатом соединения. Он также может соединить сначала A с C, а затем результат с B — но
это будет не эффективно, так как ему придётся сформировать полное декартово произведение A
и C из-за отсутствия в предложении WHERE условия, подходящего для оптимизации соединения. (В
PostgreSQL исполнитель запросов может соединять только по две таблицы, поэтому для получения
результата нужно выбрать один из этих способов.) При этом важно понимать, что все эти разные
способы соединения дают одинаковые по смыслу результаты, но стоимость их может различаться
многократно. Поэтому планировщик должен изучить их все и найти самый эффективный способ
выполнения запроса.
Когда запрос включает только две или три таблицы, возможны всего несколько вариантов их со-
единения. Но их число растёт экспоненциально с увеличением числа задействованных таблиц.
Если число таблиц больше десяти, уже практически невозможно выполнить полный перебор всех
вариантов, и даже для шести или семи таблиц планирование может занять недопустимо много
времени. Когда таблиц слишком много, планировщик PostgreSQL переключается с полного поис-
ка на алгоритм генетического вероятностного поиска в ограниченном числе вариантов. (Порог
для этого переключения задаётся параметром выполнения geqo_threshold.) Генетический поиск
выполняется быстрее, но не гарантирует, что найденный план будет наилучшим.
Когда запрос включает внешние соединения, планировщик имеет меньше степеней свободы, чем
с обычными (внутренними) соединениями. Например, рассмотрим запрос:
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Хотя ограничения в этом запросе очень похожи на показанные в предыдущем примере, смысл его
отличается, так как результирующая строка должна выдаваться для каждой строки A, даже если
для неё не находится соответствия в соединении B и C. Таким образом, здесь планировщик не мо-
жет выбирать порядок соединения: он должен соединить B с C, а затем соединить A с результатом.
Соответственно, и план этого запроса построится быстрее, чем предыдущего. В других случаях
планировщик сможет определить, что можно безопасно выбрать один из нескольких способов со-
единения. Например, для запроса:
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
можно соединить A либо с B, либо с C. В настоящее время только FULL JOIN полностью ограничи-
вает порядок соединения. На практике в большинстве запросов с LEFT JOIN и RIGHT JOIN порядком
можно управлять в некоторой степени.
Синтаксис явного внутреннего соединения (INNER JOIN, CROSS JOIN или лаконичный JOIN) по смыс-
лу равнозначен перечислению отношений в предложении FROM, так что он никак не ограничивает
порядок соединений.
Хотя большинство видов JOIN не полностью ограничивают порядок соединения, в PostgreSQL мож-
но принудить планировщик обрабатывать все предложения JOIN как ограничивающие этот поря-
док. Например, следующие три запроса логически равнозначны:
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
Но если мы укажем планировщику соблюдать порядок JOIN, на планирование второго и третьего
уйдёт меньше времени. Когда речь идёт только о трёх таблицах, выигрыш будет незначительным,
но для множества таблиц это может быть очень эффективно.
437Оптимизация производительности
Чтобы планировщик соблюдал порядок внутреннего соединения, выраженный явно предложения-
ми JOIN, нужно присвоить параметру выполнения join_collapse_limit значение 1. (Другие допусти-
мые значения обсуждаются ниже.)
Чтобы сократить время поиска, необязательно полностью ограничивать порядок соединений, в
JOIN можно соединять элементы как в обычном списке FROM. Например, рассмотрите следующий
запрос:
SELECT * FROM a CROSS JOIN b, c, d, e WHERE …;
Если join_collapse_limit = 1, планировщик будет вынужден соединить A с B раньше, чем резуль-
тат с другими таблицами, но в дальнейшем выборе вариантов он не ограничен. В данном примере
число возможных вариантов соединения уменьшается в 5 раз.
Упрощать для планировщика задачу перебора вариантов таким способом — это полезный приём,
помогающий не только выбрать сократить время планирования, но и подтолкнуть планировщик
к хорошему плану. Если планировщик по умолчанию выбирает неудачный порядок соединения,
вы можете заставить его выбрать лучший, применив синтаксис JOIN, конечно если вы сами его
знаете. Эффект подобной оптимизации рекомендуется подтверждать экспериментально.
На время планирования влияет и другой, тесно связанный фактор — решение о включении подза-
просов в родительский запрос. Пример такого запроса:
SELECT *
FROM x, y,
(SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;
Такая же ситуация может возникнуть с представлением, содержащим соединение; вместо ссылки
на это представление будет вставлено его выражение SELECT и в результате получится запрос, по-
хожий на показанный выше. Обычно планировщик старается включить подзапрос в родительский
запрос и получить таким образом:
SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;
Часто это позволяет построить лучший план, чем при планировании подзапросов по отдельности.
(Например, внешние условия WHERE могут быть таковы, что при соединении сначала X с A будет ис-
ключено множество строк A, а значит формировать логический результат подзапроса полностью
не потребуется.) Но в то же время тем самым мы увеличиваем время планирования; две задачи
соединения трёх элементов мы заменяем одной с пятью элементами. Так как число вариантов уве-
личивается экспоненциально, сложность задачи увеличивается многократно. Планировщик пыта-
ется избежать проблем поиска с огромным числом вариантов, рассматривая подзапросы отдельно,
если в предложении FROM родительского запроса оказывается больше чем from_collapse_limit
элементов. Изменяя этот параметр выполнения, можно подобрать оптимальное соотношение вре-
мени планирования и качества плана.
Параметры from_collapse_limit и join_collapse_limit называются похоже, потому что они делают
практически одно и то же: первый параметр определяет, когда планировщик будет «сносить» в
предложение FROM подзапросы, а второй — явные соединения. Обычно join_collapse_limit уста-
навливается равным from_collapse_limit (чтобы явные соединения и подзапросы обрабатывались
одинаково) или 1 (если требуется управлять порядком соединений). Но вы можете задать другие
значения, чтобы добиться оптимального соотношения времени планирования и времени выполне-
ния запросов.
14.4. Наполнение базы данных
Довольно часто в начале или в процессе использования базы данных возникает необходимость
загрузить в неё большой объём данных. В этом разделе приведены рекомендации, которые помогут
сделать это максимально эффективно.
14.4.1. Отключите автофиксацию транзакций
438Оптимизация производительности
Выполняя серию команд INSERT, выключите автофиксацию транзакций и зафиксируйте транзак-
цию только один раз в самом конце. (В обычном SQL это означает, что нужно выполнить BEGIN до,
и COMMIT после этой серии. Некоторые клиентские библиотеки могут делать это автоматически,
в таких случаях нужно убедиться, что это так.) Если вы будете фиксировать каждое добавление
по отдельности, PostgreSQL придётся проделать много действий для каждой добавляемой строки.
Выполнять все операции в одной транзакции хорошо ещё и потому, что в случае ошибки добавле-
ния одной из строк произойдёт откат к исходному состоянию и вы не окажетесь в сложной ситуа-
ции с частично загруженными данными.
14.4.2. Используйте COPY
Используйте COPY, чтобы загрузить все строки одной командой вместо серии INSERT. Команда
COPY оптимизирована для загрузки большого количества строк; хотя она не так гибка, как INSERT,
но при загрузке больших объёмов данных она влечёт гораздо меньше накладных расходов. Так как
COPY — это одна команда, применяя её, нет необходимости отключать автофиксацию транзакций.
В случаях, когда COPY не подходит, может быть полезно создать подготовленный оператор INSERT с
помощью PREPARE, а затем выполнять EXECUTE столько раз, сколько потребуется. Это позволит из-
бежать накладных расходов, связанных с разбором и анализом каждой команды INSERT. В разных
интерфейсах это может выглядеть по-разному; за подробностями обратитесь к описанию «подго-
товленных операторов» в документации конкретного интерфейса.
Заметьте, что с помощью COPY большое количество строк практически всегда загружается быст-
рее, чем с помощью INSERT, даже если используется PREPARE и серия операций добавления заклю-
чена в одну транзакцию.
COPY работает быстрее всего, если она выполняется в одной транзакции с командами CREATE TABLE
или TRUNCATE. В таких случаях записывать WAL не нужно, так как в случае ошибки файлы, содер-
жащие загружаемые данные, будут всё равно удалены. Однако это замечание справедливо, только
когда параметр wal_level равен minimal, так как в противном случае все команды должны записы-
вать свои изменения в WAL.
14.4.3. Удалите индексы
Если вы загружаете данные в только что созданную таблицу, быстрее всего будет загрузить данные
с помощью COPY, а затем создать все необходимые для неё индексы. На создание индекса для
уже существующих данных уйдёт меньше времени, чем на последовательное его обновление при
добавлении каждой строки.
Если вы добавляете данные в существующую таблицу, может иметь смысл удалить индексы, за-
грузить таблицу, а затем пересоздать индексы. Конечно, при этом надо учитывать, что времен-
ное отсутствие индексов может отрицательно повлиять на скорость работы других пользователей.
Кроме того, следует дважды подумать, прежде чем удалять уникальные индексы, так как без них
соответствующие проверки ключей не будут выполняться.
14.4.4. Удалите ограничения внешних ключей
Как и с индексами, проверки, связанные с ограничениями внешних ключей, выгоднее выполнять
«массово», а не для каждой строки в отдельности. Поэтому может быть полезно удалить ограни-
чения внешних ключей, загрузить данные, а затем восстановить прежние ограничения. И в этом
случае тоже приходится выбирать между скоростью загрузки данных и риском допустить ошибки
в отсутствие ограничений.
Более того, когда вы загружаете данные в таблицу с существующими ограничениями внешнего
ключа, для каждой новой строки добавляется запись в очередь событий триггера (так как именно
срабатывающий триггер проверяет такие ограничения для строки). При загрузке многих миллио-
нов строк очередь событий триггера может занять всю доступную память, что приведёт к недопу-
стимой нагрузке на файл подкачки или даже к сбою команды. Таким образом, загружая большие
объёмы данных, может быть не просто желательно, а необходимо удалять, а затем восстанавливать
439Оптимизация производительности
внешние ключи. Если же временное отключение этого ограничения неприемлемо, единственно
возможным решением может быть разделение всей операции загрузки на меньшие транзакции.
14.4.5. Увеличьте maintenance_work_mem
Ускорить загрузку больших объёмов данных можно, увеличив параметр конфигурации
maintenance_work_mem на время загрузки. Это приведёт к увеличению быстродействия CREATE
INDEX и ALTER TABLE ADD FOREIGN KEY. На скорость самой команды COPY это не повлияет, так что
этот совет будет полезен, только если вы применяете какой-либо из двух вышеописанных приёмов.
14.4.6. Увеличьте max_wal_size
Также массовую загрузку данных можно ускорить, изменив на время загрузки параметр конфигу-
рации max_wal_size. Загружая большие объёмы данных, PostgreSQL вынужден увеличивать частоту
контрольных точек по сравнению с обычной (которая задаётся параметром checkpoint_timeout), а
значит и чаще сбрасывать «грязные» страницы на диск. Временно увеличив max_wal_size, можно
уменьшить частоту контрольных точек и связанных с ними операций ввода-вывода.
14.4.7. Отключите архивацию WAL и потоковую репликацию
Для загрузки больших объёмов данных в среде, где используется архивация WAL или потоковая
репликация, быстрее будет сделать копию базы данных после загрузки данных, чем обрабатывать
множество операций изменений в WAL. Чтобы отключить передачу изменений через WAL в про-
цессе загрузки, отключите архивацию и потоковую репликацию, назначьте параметру wal_level
значение minimal, archive_mode — off, а max_wal_senders — 0. Но имейте в виду, что изменённые
параметры вступят в силу только после перезапуска сервера.
Это не только поможет сэкономить время архивации и передачи WAL, но и непосредственно уско-
рит некоторые команды, которые могут вовсе не использовать WAL, если wal_level равен minimal.
(Они могут гарантировать безопасность при сбое, не записывая все изменения в WAL, а выполнив
только fsync в конце операции, что будет гораздо дешевле.) Это относится к следующим командам:
• CREATE TABLE AS SELECT
• CREATE INDEX (и подобные команды, как например ALTER TABLE ADD PRIMARY KEY)
• ALTER TABLE SET TABLESPACE
• CLUSTER
• COPY FROM, когда целевая таблица была создана или опустошена ранее в той же транзакции
14.4.8. Выполните в конце ANALYZE
Всякий раз, когда распределение данных в таблице значительно меняется, настоятельно рекомен-
дуется выполнять ANALYZE. Эта рекомендация касается и загрузки в таблицу большого объёма
данных. Выполнив ANALYZE (или VACUUM ANALYZE), вы тем самым обновите статистику по данной
таблице для планировщика. Когда планировщик не имеет статистики или она не соответствует
действительности, он не сможет правильно планировать запросы, что приведёт к снижению быст-
родействия при работе с соответствующими таблицами. Заметьте, что если включён демон авто-
очистки, он может запускать ANALYZE автоматически; подробнее об этом можно узнать в Подраз-
деле 24.1.3 и Подразделе 24.1.6.
14.4.9. Несколько замечаний относительно pg_dump
В скриптах загрузки данных, которые генерирует pg_dump, автоматически учитываются некото-
рые, но не все из этих рекомендаций. Чтобы загрузить данные, которые выгрузил pg_dump, мак-
симально быстро, вам нужно будет выполнить некоторые дополнительные действия вручную. (За-
метьте, что эти замечания относятся только к восстановлению данных, но не к выгрузке их. Следу-
ющие рекомендации применимы вне зависимости от того, загружается ли архивный файл pg_dump
в psql или в pg_restore.)
440Оптимизация производительности
По умолчанию pg_dump использует команду COPY и когда она выгружает полностью схему и дан-
ные, в сгенерированном скрипте она сначала предусмотрительно загружает данные, а потом со-
здаёт индексы и внешние ключи. Так что в этом случае часть рекомендаций выполняется автома-
тически. Вам остаётся учесть только следующие:
• Установите подходящие (то есть превышающие обычные) значения для maintenance_work_mem
и max_wal_size.
• Если вы используете архивацию WAL или потоковую репликацию, по возможности отклю-
чите их на время восстановления. Для этого перед загрузкой данных, присвойте параметру
archive_mode значение off, wal_level — minimal, а max_wal_senders — 0. Закончив восстанов-
ление, верните их обычные значения и сделайте свежую базовую резервную копию.
• Поэкспериментируйте с режимами параллельного копирования и восстановления команд
pg_dump и pg_restore, и подберите оптимальное число параллельных заданий. Параллельное
копирование и восстановление данных, управляемое параметром -j, должно дать значитель-
ный выигрыш в скорости по сравнению с последовательным режимом.
• Если это возможно в вашей ситуации, восстановите все данные в рамках одной транзакции.
Для этого передайте параметр -1 или –single-transaction команде psql или pg_restore. Но
учтите, что в этом режиме даже незначительная ошибка приведёт к откату всех изменений и
часы восстановления будут потрачены зря. В зависимости от того, насколько взаимосвязаны
данные, предпочтительнее может быть вычистить их вручную. Команды COPY будут работать
максимально быстро, когда они выполняются в одной транзакции и архивация WAL выключе-
на.
• Если на сервере баз данных установлено несколько процессоров, полезным может оказаться
параметр –jobs команды pg_restore. С его помощью можно выполнить загрузку данных и со-
здание индексов параллельно.
• После загрузки данных запустите ANALYZE.
При выгрузке данных без схемы тоже используется команда COPY, но индексы, как обычно и
1
внешние ключи, при этом не удаляются и не пересоздаются. Поэтому, загружая только дан-
ные, вы сами должны решить, нужно ли для ускорения загрузки удалять и пересоздавать индек-
сы и внешние ключи. При этом будет так же полезно увеличить параметр max_wal_size, но не
maintenance_work_mem; его стоит менять, только если вы впоследствии пересоздаёте индексы и
внешние ключи вручную. И не забудьте выполнить ANALYZE после; подробнее об этом можно узнать
в Подразделе 24.1.3 и Подразделе 24.1.6.
14.5. Оптимизация, угрожающая стабильности
Стабильность — это свойство базы данных, гарантирующее, что результат зафиксированных тран-
закций будет сохранён даже в случае сбоя сервера или отключения питания. Однако обеспечива-
ется стабильность за счёт значительной дополнительной нагрузки. Поэтому, если вы можете отка-
заться от такой гарантии, PostgreSQL можно ускорить ещё больше, применив следующие методы
оптимизации. Кроме явно описанных исключений, даже с такими изменениями конфигурации при
сбое программного ядра СУБД гарантия стабильности сохраняется; риск потери или разрушения
данных возможен только в случае внезапной остановки операционной системы.
• Поместите каталог данных кластера БД в файловую систему, размещённую в памяти (т. е. в
RAM-диск). Так вы исключите всю активность ввода/вывода, связанную с базой данных, если
только размер базы данных не превышает объём свободной памяти (возможно, с учётом фай-
ла подкачки).
• Выключите fsync; сбрасывать данные на диск не нужно.
• Выключите synchronous_commit; нет необходимости принудительно записывать WAL на диск
при фиксации каждой транзакции. Но учтите, это может привести к потере транзакций (хотя
данные останутся согласованными) в случае сбоя базы данных.
1
Вы можете отключить внешние ключи, используя параметр –disable-triggers — но при этом нужно понимать, что тем самым вы не просто отложите, а
полностью выключите соответствующие проверки, что позволит вставить недопустимые данные.
441Оптимизация производительности
• Выключите full_page_writes; защита от частичной записи страниц не нужна.
• Увеличьте max_wal_size и checkpoint_timeout; это уменьшит частоту контрольных точек, хотя
объём /pg_wal при этом вырастет.
• Создавайте нежурналируемые таблицы для оптимизации записи в WAL (но учтите, что такие
таблицы не защищены от сбоя).</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-013/" title="Глава 13. Управление конкурентным доступом"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 13. Управление конкурентным доступом"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-013/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~34 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-013/" rel="bookmark" title="Глава 13. Управление конкурентным доступом" itemprop="url">Глава 13. Управление конкурентным доступом</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 13. Управление конкурентным доступом</p>

<p>В этой главе описывается поведение СУБД PostgreSQL в ситуациях, когда два или более сеансов
пытаются одновременно обратиться к одним и тем же данным. В таких ситуациях важно, чтобы
все сеансы могли эффективно работать с данными, и при этом сохранялась целостность данных.
Обсуждаемые в этой главе темы заслуживают внимания всех разработчиков баз данных.
13.1. Введение
PostgreSQL предоставляет разработчикам богатый набор средств для управления конкурент-
ным доступом к данным. Внутри он поддерживает целостность данных, реализуя модель MVCC
(Multiversion Concurrency Control, Многоверсионное управление конкурентным доступом). Это
означает, что каждый SQL-оператор видит снимок данных (версию базы данных) на определённый
момент времени, вне зависимости от текущего состояния данных. Это защищает операторы от
несогласованности данных, возможной, если другие конкурирующие транзакции внесут измене-
ния в те же строки данных, и обеспечивает тем самым изоляцию транзакций для каждого сеан-
са баз данных. MVCC, отходя от методик блокирования, принятых в традиционных СУБД, снижа-
ет уровень конфликтов блокировок и таким образом обеспечивает более высокую производитель-
ность в многопользовательской среде.
Основное преимущество использования модели MVCC по сравнению с блокированием заключа-
ется в том, что блокировки MVCC, полученные для чтения данных, не конфликтуют с блокиров-
ками, полученными для записи, и поэтому чтение никогда не мешает записи, а запись чтению.
PostgreSQL гарантирует это даже для самого строгого уровня изоляции транзакций, используя ин-
новационный уровень изоляции SSI (Serializable Snapshot Isolation, Сериализуемая изоляция сним-
ков).
Для приложений, которым в принципе не нужна полная изоляция транзакций и которые предпо-
читают явно определять точки конфликтов, в PostgreSQL также есть средства блокировки на уров-
не таблиц и строк. Однако при правильном использовании MVCC обычно обеспечивает лучшую
производительность, чем блокировки. Кроме этого, приложения могут использовать рекоменда-
тельные блокировки, не привязанные к какой-либо одной транзакции.
13.2. Изоляция транзакций
Стандарт SQL определяет четыре уровня изоляции транзакций. Наиболее строгий из них — сериа-
лизуемый, определяется одним абзацем, говорящем, что при параллельном выполнении несколь-
ко сериализуемых транзакций должны гарантированно выдавать такой же результат, как если бы
они запускались по очереди в некотором порядке. Остальные три уровня определяются через опи-
сания особых явлений, которые возможны при взаимодействии параллельных транзакций, но не
допускаются на определённом уровне. Как отмечается в стандарте, из определения сериализуе-
мого уровня вытекает, что на этом уровне ни одно из этих явлений не возможно. (В самом деле
— если эффект транзакций должен быть тем же, что и при их выполнении по очереди, как можно
было бы увидеть особые явления, связанные с другими транзакциями?)
Стандарт описывает следующие особые условия, недопустимые для различных уровней изоляции:
«грязное» чтение
Транзакция читает данные, записанные параллельной незавершённой транзакцией.
неповторяемое чтение
Транзакция повторно читает те же данные, что и раньше, и обнаруживает, что они были изме-
нены другой транзакцией (которая завершилась после первого чтения).
407Управление конку-
рентным доступом
фантомное чтение
Транзакция повторно выполняет запрос, возвращающий набор строк для некоторого условия,
и обнаруживает, что набор строк, удовлетворяющих условию, изменился из-за транзакции, за-
вершившейся за это время.
аномалия сериализации
Результат успешной фиксации группы транзакций оказывается несогласованным при всевоз-
можных вариантах исполнения этих транзакций по очереди.
Уровни изоляции транзакций, описанные в стандарте SQL и реализованные в PostgreSQL, описы-
ваются в Таблице 13.1.
Таблица 13.1. Уровни изоляции транзакций
Уровень
ции
изоля- «Грязное»
ние
Read uncommited Допускается,
(Чтение незафик- не в PG
сированных дан-
ных)
чте- Неповторяемое
чтение
Фантомное
ние
чте- Аномалия сериа-
лизации
но Возможно Возможно Возможно
Read committed ( Невозможно
Чтение зафикси-
рованных данных) Возможно Возможно Возможно
Repeatable read ( Невозможно
Повторяемое чте-
ние) Невозможно Допускается,
не в PG Serializable (Сери- Невозможно
ализуемость) Невозможно Невозможно
но Возможно
Невозможно
В PostgreSQL вы можете запросить любой из четырёх уровней изоляции транзакций, однако внут-
ри реализованы только три различных уровня, то есть режим Read Uncommitted в PostgreSQL дей-
ствует как Read Committed. Причина этого в том, что только так можно сопоставить стандартные
уровни изоляции с реализованной в PostgreSQL архитектурой многоверсионного управления кон-
курентным доступом.
В этой таблице также показано, что реализация Repeatable Read в PostgreSQL не допускает фан-
томное чтение. Стандарт SQL допускает возможность более строгого поведения: четыре уровня
изоляции определяют только, какие особые условия не должны наблюдаться, но не какие обяза-
тельно должны. Поведение имеющихся уровней изоляции подробно описывается в следующих
подразделах.
Для выбора нужного уровня изоляции транзакций используется команда SET TRANSACTION.
Важно
Поведение некоторых функций и типов данных PostgreSQL в транзакциях подчиняет-
ся особым правилам. В частности, изменения последовательностей (и следовательно,
счётчика в столбце, объявленному как serial) немедленно видны во всех остальных
транзакциях и не откатываются назад, если выполнившая их транзакция прерывается.
См. Раздел 9.16 и Подраздел 8.1.4.
13.2.1. Уровень изоляции Read Committed
Read Committed — уровень изоляции транзакции, выбираемый в PostgreSQL по умолчанию. В тран-
закции, работающей на этом уровне, запрос SELECT (без предложения FOR UPDATE/SHARE) видит
только те данные, которые были зафиксированы до начала запроса; он никогда не увидит неза-
фиксированных данных или изменений, внесённых в процессе выполнения запроса параллельны-
408Управление конку-
рентным доступом
ми транзакциями. По сути запрос SELECT видит снимок базы данных в момент начала выполнения
запроса. Однако SELECT видит результаты изменений, внесённых ранее в этой же транзакции, да-
же если они ещё не зафиксированы. Также заметьте, что два последовательных оператора SELECT
могут видеть разные данные даже в рамках одной транзакции, если какие-то другие транзакции
зафиксируют изменения после запуска первого SELECT, но до запуска второго.
Команды UPDATE, DELETE, SELECT FOR UPDATE и SELECT FOR SHARE ведут себя подобно SELECT при
поиске целевых строк: они найдут только те целевые строки, которые были зафиксированы на мо-
мент начала команды. Однако к моменту, когда они будут найдены, эти целевые строки могут быть
уже изменены (а также удалены или заблокированы) другой параллельной транзакцией. В этом
случае запланированное изменение будет отложено до фиксирования или отката первой изменя-
ющей данные транзакции (если она ещё выполняется). Если первая изменяющая транзакция от-
катывается, её результат отбрасывается и вторая изменяющая транзакция может продолжить из-
менение изначально полученной строки. Если первая транзакция зафиксировалась, но в резуль-
тате удалила эту строку, вторая будет игнорировать её, а в противном случае попытается выпол-
нить свою операцию с изменённой версией строки. Условие поиска в команде (предложение WHERE)
вычисляется повторно для выяснения, соответствует ли по-прежнему этому условию изменённая
версия строки. Если да, вторая изменяющая транзакция продолжают свою работу с изменённой
версией строки. Применительно к командам SELECT FOR UPDATE и SELECT FOR SHARE это означает,
что изменённая версия строки блокируется и возвращается клиенту.
Похожим образом ведёт себя INSERT с предложением ON CONFLICT DO UPDATE. В режиме Read
Committed каждая строка, предлагаемая для добавления, будет либо вставлена, либо изменена. Ес-
ли не возникнет несвязанных ошибок, гарантируется один из этих двух исходов. Если конфликт бу-
дет вызван другой транзакцией, результат которой ещё не видим для INSERT, предложение UPDATE
подействует на эту строку, даже несмотря на то, что эта команда обычным образом может не ви-
деть никакую версию этой строки.
При выполнении INSERT с предложением ON CONFLICT DO NOTHING строка может не добавиться в
результате действия другой транзакции, эффект которой не виден в снимке команды INSERT. Это
опять же имеет место только в режиме Read Committed.
Вследствие описанных выше правил, изменяющая команда может увидеть несогласованное состо-
яние: она может видеть результаты параллельных команд, изменяющих те же строки, что пытает-
ся изменить она, но при этом она не видит результаты этих команд в других строках таблиц. Из-за
этого поведения уровень Read Committed не подходит для команд со сложными условиями поиска;
однако он вполне пригоден для простых случаев. Например, рассмотрим изменение баланса счёта
в таких транзакциях:
BEGIN;
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 12345;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 7534;
COMMIT;
Если две такие транзакции пытаются параллельно изменить баланс счёта 12345, мы, естественно,
хотим, чтобы вторая транзакция работала с изменённой версией строки счёта. Так как каждая
команда влияет только на определённую строку, если она будет видеть изменённую версию строки,
это не приведёт к проблемам несогласованности.
В более сложных ситуациях уровень Read Committed может приводить к нежелательным резуль-
татам. Например, рассмотрим команду DELETE, работающую со строками, которые параллельно
добавляет и удаляет из множества, определённого её условием, другая команда. Например, пред-
положим, что website — таблица из двух строк, в которых website.hits равны 9 и 10:
BEGIN;
UPDATE website SET hits = hits + 1;
– выполняется параллельно: DELETE FROM website WHERE hits = 10;
COMMIT;
Команда DELETE не сделает ничего, даже несмотря на то, что строка с website.hits = 10 была в
таблице и до, и после выполнения UPDATE. Это происходит потому, что строка со значением 9 до
409Управление конку-
рентным доступом
изменения пропускается, а когда команда UPDATE завершается и DELETE получает освободившуюся
блокировку, строка с 10 теперь содержит 11, а это значение уже не соответствует условию.
Так как в режиме Read Committed каждая команда начинается с нового снимка состояния, кото-
рый включает результаты всех транзакций, зафиксированных к этому моменту, последующие ко-
манды в одной транзакции будут в любом случае видеть эффекты всех параллельных зафиксиро-
ванных транзакций. Вопрос здесь состоит в том, видит ли одна команда абсолютно согласованное
состояние базы данных.
Частичная изоляция транзакция, обеспечиваемая в режиме Read Committed, приемлема для мно-
жества приложений. Этот режим быстр и прост в использовании, однако он подходит не для всех
случаев. Приложениям, выполняющим сложные запросы и изменения, могут потребоваться более
строго согласованное представление данных, чем то, что даёт Read Committed.
13.2.2. Уровень изоляции Repeatable Read
В режиме Repeatable Read видны только те данные, которые были зафиксированы до начала тран-
закции, но не видны незафиксированные данные и изменения, произведённые другими транзак-
циями в процессе выполнения данной транзакции. (Однако запрос будет видеть эффекты предыду-
щих изменений в своей транзакции, несмотря на то, что они не зафиксированы.) Это самое стро-
гое требование, которое стандарт SQL вводит для этого уровня изоляции, и при его выполнении
предотвращаются все явления, описанные в Таблице 13.1, за исключением аномалий сериализа-
ции. Как было сказано выше, это не противоречит стандарту, так как он определяет только мини-
мальную защиту, которая должна обеспечиваться на каждом уровне изоляции.
Этот уровень отличается от Read Committed тем, что запрос в транзакции данного уровня видит
снимок данных на момент начала первого оператора в транзакции (не считая команд управле-
ния транзакциями), а не начала текущего оператора. Таким образом, последовательные команды
SELECT в одной транзакции видят одни и те же данные; они не видят изменений, внесённых и за-
фиксированных другими транзакциями после начала их текущей транзакции.
Приложения, использующие этот уровень, должны быть готовы повторить транзакции в случае
сбоев сериализации.
Команды UPDATE, DELETE, SELECT FOR UPDATE и SELECT FOR SHARE ведут себя подобно SELECT при
поиске целевых строк: они найдут только те целевые строки, которые были зафиксированы на мо-
мент начала транзакции. Однако к моменту, когда они будут найдены, эти целевые строки могут
быть уже изменены (а также удалены или заблокированы) другой параллельной транзакцией. В
этом случае транзакция в режиме Repeatable Read будет ожидать фиксирования или отката первой
изменяющей данные транзакции (если она ещё выполняется). Если первая изменяющая транзак-
ция откатывается, её результат отбрасывается и текущая транзакция может продолжить измене-
ние изначально полученной строки. Если же первая транзакция зафиксировалась и в результате
изменила или удалила эту строку, а не просто заблокировала её, произойдёт откат текущей тран-
закции с сообщением
ОШИБКА: не удалось сериализовать доступ из-за параллельного изменения
так как транзакция уровня Repeatable Read не может изменять или блокировать строки, изменён-
ные другими транзакциями с момента её начала.
Когда приложение получает это сообщение об ошибке, оно должна прервать текущую транзакцию
и попытаться повторить её с самого начала. Во второй раз транзакция увидит внесённое до этого
изменение как часть начального снимка базы данных, так что новая версия строки вполне может
использоваться в качестве отправной точки для изменения в повторной транзакции.
Заметьте, что потребность в повторении транзакции может возникнуть, только если эта транзак-
ция изменяет данные; в транзакциях, которые только читают данные, конфликтов сериализации
не бывает.
Режим Repeatable Read строго гарантирует, что каждая транзакция видит полностью стабильное
представление базы данных. Однако это представление не обязательно будет согласовано с неко-
410Управление конку-
рентным доступом
торым последовательным выполнением транзакций одного уровня. Например, даже транзакция,
которая только читает данные, в этом режиме может видеть строку, показывающую, что некото-
рое задание завершено, но не видеть одну из строк логических частей задания, так как эта тран-
закция может прочитать более раннюю версию строки задания, чем ту, для которой параллельно
добавлялась очередная логическая часть. Строго исполнить бизнес-правила в транзакциях, рабо-
тающих на этом уровне изоляции, скорее всего не удастся без явных блокировок конфликтующих
транзакций.
Примечание
До версии 9.1 в PostgreSQL при запросе режима Serializable поведение системы в точ-
ности соответствовало вышеописанному. Таким образом, чтобы сейчас получить ста-
рое поведение Serializable, нужно запрашивать режим Repeatable Read.
13.2.3. Уровень изоляции Serializable
Уровень Serializable обеспечивает самую строгую изоляцию транзакций. На этом уровне модели-
руется последовательное выполнение всех зафиксированных транзакций, как если бы транзак-
ции выполнялись одна за другой, последовательно, а не параллельно. Однако, как и на уровне
Repeatable Read, на этом уровне приложения должны быть готовы повторять транзакции из-за сбо-
ев сериализации. Фактически этот режим изоляции работает так же, как и Repeatable Read, только
он дополнительно отслеживает условия, при которых результат параллельно выполняемых сери-
ализуемых транзакций может не согласовываться с результатом этих же транзакций, выполняе-
мых по очереди. Это отслеживание не привносит дополнительных препятствий для выполнения,
кроме тех, что присущи режиму Repeatable Read, но тем не менее создаёт некоторую добавочную
нагрузку, а при выявлении исключительных условий регистрируется аномалия сериализации и
происходит сбой сериализации.
Например, рассмотрим таблицу mytab, изначально содержащую:
class | value
——-+——-
1 |
10
1 |
20
2 |
100
2 |
200
Предположим, что сериализуемая транзакция A вычисляет:
SELECT SUM(value) FROM mytab WHERE class = 1;
а затем вставляет результат (30) в поле value в новую строку со значением class = 2. В это же
время сериализуемая транзакция B вычисляет:
SELECT SUM(value) FROM mytab WHERE class = 2;
получает результат 300 и вставляет его в новую строку со значением class = 1. Затем обе транзак-
ции пытаются зафиксироваться. Если бы одна из этих транзакций работала в режиме Repeatable
Read, зафиксироваться могли бы обе; но так как полученный результат не соответствовал бы по-
следовательному порядку, в режиме Serializable будет зафиксирована только одна транзакция, а
вторая закончится откатом с сообщением:
ОШИБКА: не удалось сериализовать доступ из-за зависимостей чтения/записи между
транзакциями
Это объясняется тем, что при выполнении A перед B транзакция B вычислила бы сумму 330, а не
300, а при выполнении в обратном порядке A вычислила бы другую сумму.
Рассчитывая, что сериализуемые транзакции предотвратят аномалии, важно понимать, что любые
данные, полученные из постоянной таблицы пользователя, не должны считаться действительны-
ми, пока транзакция, прочитавшая их, не будет успешно зафиксирована. Это верно даже для тран-
закций, не модифицирующих данные, за исключением случая, когда данные считываются в от-
411Управление конку-
рентным доступом
кладываемой транзакции такого типа. В этом случае данные могут считаться действительными,
так как такая транзакция ждёт, пока не сможет получить снимок, гарантированно предотвраща-
ющий подобные проблемы. Во всех остальных случаях приложения не должны полагаться на ре-
зультаты чтения данных в транзакции, которая не была зафиксирована; в случае ошибки и отката
приложения должны повторять транзакцию, пока она не будет завершена успешно.
Для полной гарантии сериализуемости в PostgreSQL применяются предикатные блокировки, то
есть блокировки, позволяющие определить, когда запись могла бы повлиять на результат преды-
дущего чтения параллельной транзакции, если бы эта запись выполнялась сначала. В PostgreSQL
эти блокировки не приводят к фактическим блокировкам данным и следовательно никоим обра-
зом не могут повлечь взаимоблокировки транзакций. Они помогают выявить и отметить зависимо-
сти между параллельными транзакциями уровня Serializable, которые в определённых сочетани-
ях могут приводить к аномалиям сериализации. Транзакции Read Committed или Repeatable Read
для обеспечения целостности данных, напротив, должны либо блокировать таблицы целиком, что
помешает пользователям обращаться к этим таблицам, либо применять SELECT FOR UPDATE или
SELECT FOR SHARE, что не только заблокирует другие транзакции, но и создаст дополнительную
нагрузку на диск.
Предикатные блокировки в PostgreSQL, как и в большинстве других СУБД, устанавливаются для
данных, фактически используемых в транзакции. Они отображаются в системном представлении
pg_locks со значением mode равным SIReadLock. Какие именно блокировки будут затребованы при
выполнении запроса, зависит от плана запроса, при этом детализированные блокировки (напри-
мер, блокировки строк) могут объединяться в более общие (например, в блокировки страниц) в
процессе транзакции для экономии памяти, расходуемой для отслеживания блокировок. Транзак-
ция READ ONLY может даже освободить свои блокировки SIRead до завершения, если обнаружива-
ется, что конфликты, которые могли бы привести к аномалии сериализации, исключены. На самом
деле для транзакций READ ONLY этот факт чаще всего устанавливается в самом начале, так что
они обходятся без предикатных блокировок. Если же вы явно запросите транзакцию SERIALIZABLE
READ ONLY DEFERRABLE, она будет заблокирована до тех пор, пока не сможет установить этот
факт. (Это единственный случай, когда транзакции уровня Serializable блокируются, а транзакции
Repeatable Read — нет.) С другой стороны, блокировки SIRead часто должны сохраняться и после
фиксирования транзакции, пока не будут завершены другие, наложившиеся на неё транзакции.
При правильном использовании сериализуемые транзакции могут значительно упростить разра-
ботку приложений. Гарантия того, что любое сочетание успешно зафиксированных параллельных
сериализуемых транзакций даст тот же результат, что и последовательность этих транзакций, вы-
полненных по очереди, означает, что если вы уверены, что единственная транзакция определён-
ного содержания работает правильно, когда она запускается отдельно, вы можете быть уверены,
что она будет работать так же правильно в любом сочетании сериализуемых транзакций, вне за-
висимости от того, что они делают, либо же она не будет зафиксирована успешно. При этом важно,
чтобы в среде, где применяется этот подход, была реализована общая обработка сбоев сериализа-
ции (которые можно определить по значению SQLSTATE ‘40001’), так как заведомо определить,
какие именно транзакции могут стать жертвами зависимостей чтения/записи и не будут зафик-
сированы для предотвращения аномалий сериализации, обычно очень сложно. Отслеживание за-
висимостей чтения-записи неизбежно создаёт дополнительную нагрузку, как и перезапуск тран-
закций, не зафиксированных из-за сбоев сериализации, но если на другую чашу весов положить
нагрузку и блокирование, связанные с применением явных блокировок и SELECT FOR UPDATE или
SELECT FOR SHARE, использовать сериализуемые транзакции в ряде случаев окажется выгоднее.
Тогда как уровень изоляции транзакций Serializable в PostgreSQL позволяет фиксировать парал-
лельные транзакции, только если есть уверенность, что тот же результат будет получен при по-
следовательном их выполнении, он не всегда предотвращает ошибки, которые не возникли бы при
действительно последовательном выполнении. В частности, можно столкнуться с нарушениями
ограничений уникальности, вызванными наложением сериализуемых транзакций, даже после яв-
ной проверки отсутствия ключа перед добавлением его. Этого можно избежать, если все сериа-
лизуемые транзакции, добавляющие потенциально конфликтующие ключи, будут предварительно
явно проверять, можно ли вставить ключ. Например, приложение, добавляющее новый ключ, мо-
жет запрашивать его у пользователя и затем проверять, существует ли он, сначала пытаясь найти
его, либо генерировать новый ключ, выбирая максимальное существующее значение и увеличивая
412Управление конку-
рентным доступом
его на один. Если некоторые сериализуемые транзакции добавляют новые ключи сразу, не следуя
этому протоколу, возможны нарушения ограничений уникальности, даже когда они не наблюда-
лись бы при последовательном выполнении этих транзакций.
Применяя сериализуемые транзакции для управления конкурентным доступом, примите к сведе-
нию следующие рекомендации:
• Объявляйте транзакции как READ ONLY, если это отражает их суть.
• Управляйте числом активных подключений, при необходимости используя пул соединений.
Это всегда полезно для увеличения производительности, но особенно важно это в загружен-
ной системе с сериализуемыми транзакциями.
• Заключайте в одну транзакцию не больше команд, чем необходимо для обеспечения целост-
ности.
• Не оставляйте соединения «простаивающими в транзакции» дольше, чем необходимо. Для ав-
томатического отключения затянувшихся транзакций можно применить параметр конфигура-
ции idle_in_transaction_session_timeout.
• Исключите явные блокировки, SELECT FOR UPDATE и SELECT FOR SHARE там, где они не нужны
благодаря защите, автоматически предоставляемой сериализуемыми транзакциями.
• Когда система вынуждена объединять предикатные блокировки уровня страницы в одну пре-
дикатную блокировку уровня таблицы из-за нехватки памяти, может возрасти частота сбо-
ев сериализации. Избежать этого можно, увеличив параметр max_pred_locks_per_transaction,
max_pred_locks_per_relation и/или max_pred_locks_per_page.
• Последовательное сканирование всегда влечёт за собой предикатную блокировку на уровне
таблицы. Это приводит к увеличению сбоев сериализации. В таких ситуациях бывает полезно
склонить систему к использованию индексов, уменьшая random_page_cost и/или увеличивая
cpu_tuple_cost. Однако тут важно сопоставить выигрыш от уменьшения числа откатов и пере-
запусков транзакций с проигрышем от возможного менее эффективного выполнения запро-
сов.
13.3. Явные блокировки
Для управления параллельным доступом к данным в таблицах PostgreSQL предоставляет несколь-
ко режимов явных блокировок. Эти режимы могут применяться для блокировки данных со стороны
приложения в ситуациях, когда MVCC не даёт желаемый результат. Кроме того, большинство ко-
манд PostgreSQL автоматически получают блокировки соответствующих режимов, защищающие
от удаления или изменения задействованных таблиц, несовместимого с характером выполняемой
команды. (Например, TRUNCATE не может безопасно выполняться одновременно с другими опера-
циями с этой таблицей, так что во избежание конфликта эта команда получает исключительную
блокировку для данной таблицы.)
Список текущих активных блокировок на сервере можно получить, прочитав системное представ-
ление pg_locks. За дополнительными сведениями о наблюдении за состоянием менеджера блоки-
ровок обратитесь к Главе 28.
13.3.1. Блокировки на уровне таблицы
В приведённом ниже списке перечислены имеющиеся режимы блокировок и контексты, где их ав-
томатически применяет PostgreSQL. Вы можете также явно запросить любую из этих блокировок
с помощью команды LOCK. Помните, что все эти режимы работают на уровне таблицы, даже если
имя режима содержит слово «row»; такие имена сложились исторически. В некоторой степени эти
имена отражают типичное применение каждого режима блокировки, но смысл у всех один. Един-
ственное, что действительно отличает один режим блокировки от другого, это набор режимов, с
которыми конфликтует каждый из них (см. Таблицу 13.2). Две транзакции не могут одновременно
владеть блокировками конфликтующих режимов для одной и той же таблицы. (Однако учтите, что
транзакция никогда не конфликтует с собой. Например, она может запросить блокировку ACCESS
EXCLUSIVE, а затем ACCESS SHARE для той же таблицы.) При этом разные транзакции свободно могут
одновременно владеть блокировками неконфликтующих режимов. Заметьте, что некоторые режи-
413Управление конку-
рентным доступом
мы блокировки конфликтуют сами с собой (например, блокировкой ACCESS EXCLUSIVE в один мо-
мент времени может владеть только одна транзакция), а некоторые — нет (например, блокировку
ACCESS SHARE могут получить сразу несколько транзакций).
Режимы блокировок на уровне таблицы
ACCESS SHARE
Конфликтует только с режимом блокировки ACCESS EXCLUSIVE.
Команда SELECT получает такую блокировку для таблиц, на которые она ссылается. Вообще
говоря, блокировку в этом режиме получает любой запрос, который только читает таблицу,
но не меняет её данные.
ROW SHARE
Конфликтует с режимами блокировки EXCLUSIVE и ACCESS EXCLUSIVE.
Команды SELECT FOR UPDATE и SELECT FOR SHARE получают такую блокировку для своих целе-
вых таблиц (помимо блокировок ACCESS SHARE для любых таблиц, которые используется в этих
запросов, но не в предложении FOR UPDATE/FOR SHARE).
ROW EXCLUSIVE
Конфликтует с режимами блокировки SHARE, SHARE
EXCLUSIVE.
ROW
EXCLUSIVE, EXCLUSIVE и ACCESS
Команды UPDATE, DELETE и INSERT получают такую блокировку для целевой таблицы (в допол-
нение к блокировкам ACCESS SHARE для всех других задействованных таблиц). Вообще говоря,
блокировку в этом режиме получает любая команда, которая изменяет данные в таблице.
SHARE UPDATE EXCLUSIVE
Конфликтует с режимами блокировки SHARE UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE,
EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельного изменения
схемы и запуска процесса VACUUM.
Запрашивается командами VACUUM (без FULL), ANALYZE, CREATE INDEX CONCURRENTLY, CREATE
STATISTICS, ALTER TABLE VALIDATE и другими видами ALTER TABLE (за подробностями обрати-
тесь к ALTER TABLE).
SHARE
Конфликтует с режимами блокировки ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE ROW
EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельного
изменения данных.
Запрашивается командой CREATE INDEX (без параметра CONCURRENTLY).
SHARE ROW EXCLUSIVE
Конфликтует с режимами блокировки ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE, SHARE, SHARE
ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим защищает таблицу от параллельных
изменений данных и при этом он является самоисключающим, так что такую блокировку может
получить только один сеанс.
Запрашивается командой CREATE COLLATION, CREATE TRIGGER и многими формами ALTER TABLE
(см. ALTER TABLE).
EXCLUSIVE
Конфликтует с режимами блокировки ROW SHARE, ROW EXCLUSIVE, SHARE UPDATE EXCLUSIVE,
SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE. Этот режим совместим только с
блокировкой ACCESS SHARE, то есть параллельно с транзакцией, получившей блокировку в этом
режиме, допускается только чтение таблицы.
414Управление конку-
рентным доступом
Запрашивается командой REFRESH MATERIALIZED VIEW CONCURRENTLY.
ACCESS EXCLUSIVE
Конфликтует со всеми режимами блокировки (ACCESS SHARE, ROW SHARE, ROW EXCLUSIVE, SHARE
UPDATE EXCLUSIVE, SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE и ACCESS EXCLUSIVE). Этот режим
гарантирует, что кроме транзакции, получившей эту блокировку, никакая другая транзакция
не может обращаться к таблице каким-либо способом.
Запрашивается командами DROP TABLE, TRUNCATE, REINDEX, CLUSTER, VACUUM FULL и REFRESH
MATERIALIZED VIEW (без CONCURRENTLY). Блокировку на этом уровне запрашивают также многие
виды ALTER TABLE. В этом режиме по умолчанию запрашивают блокировку и операторы LOCK
TABLE, если явно не выбран другой режим.
Подсказка
Только блокировка ACCESS EXCLUSIVE блокирует оператор SELECT (без FOR UPDATE/
SHARE).
Полученная транзакцией блокировка обычно сохраняется до конца транзакции. Но если блокиров-
ка получена после установки точки сохранения, она освобождается немедленно в случае отката
к этой точке. Это согласуется с принципом действия ROLLBACK — эта команда отменяет эффекты
всех команд после точки сохранения. То же справедливо и для блокировок, полученных в блоке
исключений PL/pgSQL: при выходе из блока с ошибкой такие блокировки освобождаются.
Таблица 13.2. Конфликтующие режимы блокировки
Запраши Текущий режим блокировки
ваемый ACCESS ROW
ROW
SHARE
SHARE
режим
SHARE
SHARE
EXCLUSIVE
UPDATE
блоки
EXCLUSIVE
ровки
SHARE
EXCLU
ROW
SIVE
EXCLUSIVE
ACCESS
EXCLUSIVE
ACCESS
SHARE               X
ROW
SHARE             X X
ROW
EXCLUSIVE         X X X X
SHARE
UPDATE
EXCLUSIVE       X X X X X
SHARE     X X   X X X
SHARE
ROW
EXCLUSIVE     X X X X X X
EXCLU
SIVE   X X X X X X X
ACCESS
EXCLUSIVE X X X X X X X X
13.3.2. Блокировки на уровне строк
В дополнение к блокировкам на уровне таблицы, существуют блокировки на уровне строк, пере-
численные ниже с контекстами, где PostgreSQL применяет их по умолчанию. Полный перечень
конфликтов блокировок на уровне строк приведён в Таблице 13.3. Заметьте, что одна транзакция
415Управление конку-
рентным доступом
может владеть несколькими конфликтующими блокировками одной строки, даже в разных под-
транзакциях; но две разных транзакции никогда не получат конфликтующие блокировки одной и
той же строки. Блокировки на уровне строк блокируют только запись в определённые строки, но
никак не влияют на выборку.
Режимы блокировки на уровне строк
FOR UPDATE
В режиме FOR UPDATE строки, выданные оператором SELECT, блокируются как для изменения.
При этом они защищаются от блокировки, изменения и удаления другими транзакциями до за-
вершения текущей. То есть другие транзакции, пытающиеся выполнить UPDATE, DELETE, SELECT
FOR UPDATE, SELECT FOR NO KEY UPDATE, SELECT FOR SHARE или SELECT FOR KEY SHARE с эти-
ми строками, будут заблокированы до завершения текущей транзакции; и наоборот, команда
SELECT FOR UPDATE будет ожидать окончания параллельной транзакции, в которой выполни-
лась одна из этих команд с той же строкой, а затем установит блокировку и вернёт изменён-
ную строку (или не вернёт, если она была удалена). Однако в транзакции REPEATABLE READ или
SERIALIZABLE возникнет ошибка, если блокируемая строка изменилась с момента начала тран-
закции. Подробнее это обсуждается в Разделе 13.4.
Режим блокировки FOR UPDATE также запрашивается на уровне строки любой командой DELETE
и командой UPDATE, изменяющей значения определённых столбцов. В настоящее время блоки-
ровка с UPDATE касается столбцов, по которым создан уникальный индекс, применимый в каче-
стве внешнего ключа (так что на частичные индексы и индексы выражений это не распростра-
няется), но в будущем это может поменяться.
FOR NO KEY UPDATE
Действует подобно FOR UPDATE, но запрашиваемая в этом режиме блокировка слабее: она не
будет блокировать команды SELECT FOR KEY SHARE, пытающиеся получить блокировку тех же
строк. Этот режим блокировки также запрашивается любой командой UPDATE, которая не тре-
бует блокировки FOR UPDATE.
FOR SHARE
Действует подобно FOR NO KEY UPDATE, за исключением того, что для каждой из полученных
строк запрашивается разделяемая, а не исключительная блокировка. Разделяемая блокировка
не позволяет другим транзакциям выполнять с этими строками UPDATE, DELETE, SELECT FOR
UPDATE или SELECT FOR NO KEY UPDATE, но допускает SELECT FOR SHARE и SELECT FOR KEY SHARE.
FOR KEY SHARE
Действует подобно FOR SHARE, но устанавливает более слабую блокировку: блокируется SELECT
FOR UPDATE, но не SELECT FOR NO KEY UPDATE. Блокировка разделяемого ключа не позволяет
другим транзакциям выполнять команды DELETE и UPDATE, только если они меняют значение
ключа (но не другие UPDATE), и при этом допускает выполнение команд SELECT FOR NO KEY
UPDATE, SELECT FOR SHARE и SELECT FOR KEY SHARE.
PostgreSQL не держит информацию об изменённых строках в памяти, так что никаких ограниче-
ний на число блокируемых строк нет. Однако блокировка строки может повлечь запись на диск,
например, если SELECT FOR UPDATE изменяет выбранные строки, чтобы заблокировать их, при этом
происходит запись на диск.
Таблица 13.3. Конфликтующие блокировки на уровне строк
Запрашиваемый Текущий режим блокировки
режим
блоки FOR KEY SHARE FOR SHARE
ровки
FOR
NO
UPDATE
KEY FOR UPDATE
FOR KEY SHARE       X
FOR SHARE     X X
416Управление конку-
рентным доступом
Запрашиваемый Текущий режим блокировки
режим
блоки FOR KEY SHARE FOR SHARE
ровки
FOR
NO
UPDATE
FOR UPDATE
KEY
FOR
NO
UPDATE
KEY FOR UPDATE
  X X X
X X X X
13.3.3. Блокировки на уровне страниц
В дополнение к блокировкам на уровне таблицы и строк, для управления доступом к страницам
таблиц в общих буферах используются блокировки на уровне страниц, исключительные и разде-
ляемые. Эти блокировки освобождаются немедленно после выборки или изменения строк. Разра-
ботчикам приложений обычно можно не задумываться о блокировках страниц, здесь они упоми-
наются только для полноты картины.
13.3.4. Взаимоблокировки
Частое применение явных блокировок может увеличить вероятность взаимоблокировок, то есть
ситуаций, когда две (или более) транзакций держат блокировки так, что взаимно блокируют друг
друга. Например, если транзакция 1 получает исключительную блокировку таблицы A, а затем пы-
тается получить исключительную блокировку таблицы B, которую до этого получила транзакция
2, в данный момент требующая исключительную блокировку таблицы A, ни одна из транзакций
не сможет продолжить работу. PostgreSQL автоматически выявляет такие ситуации и разрешает
их, прерывая одну из сцепившихся транзакций и тем самым позволяя другой (другим) продолжить
работу. (Какая именно транзакция будет прервана, обычно сложно предсказать, так что рассчи-
тывать на определённое поведение не следует.)
Заметьте, что взаимоблокировки могут вызываться и блокировками на уровне строк (таким обра-
зом, они возможны, даже если не применяются явные блокировки). Рассмотрим случай, когда две
параллельных транзакции изменяют таблицу. Первая транзакция выполняет:
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 11111;
При этом она получает блокировку строки с указанным номером счёта. Затем вторая транзакция
выполняет:
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 22222;
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 11111;
Первый оператор UPDATE успешно получает блокировку указанной строки и изменяет данные в
ней. Однако второй оператор UPDATE обнаруживает, что строка, которую он пытается изменить,
уже заблокирована, так что он ждёт завершения транзакции, получившей блокировку. Таким об-
разом, вторая транзакция сможет продолжиться только после завершения первой. Теперь первая
транзакция выполняет:
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 22222;
Первая транзакция пытается получить блокировку заданной строки, но ей это не удаётся: эта бло-
кировка уже принадлежит второй транзакции. Поэтому первой транзакции остаётся только ждать
завершения второй. В результате первая транзакция блокируется второй, а вторая — первой: про-
исходит взаимоблокировка. PostgreSQL выявляет эту ситуацию и прерывает одну из транзакций.
Обычно лучший способ предотвращения взаимоблокировок — добиться, чтобы все приложения,
обращающиеся к базе данных, запрашивали блокировки нескольких объектов единообразно. В дан-
ном примере, если бы обе транзакции изменяли строки в одном порядке, взаимоблокировка бы не
произошла. Блокировки в транзакции следует упорядочивать так, чтобы первой для какого-либо
объекта запрашивалась наиболее ограничивающая из тех, которые для него потребуются. Если
заранее обеспечить такой порядок нельзя, взаимоблокировки можно обработать по факту, повто-
ряя прерванные транзакции.
Если ситуация взаимоблокировки не будет выявлена, транзакция, ожидающая блокировки на уров-
не таблицы или строки, будет ждать её освобождения неограниченное время. Это означает, что
417Управление конку-
рентным доступом
приложения не должны оставлять транзакции открытыми долгое время (например, ожидая ввода
пользователя).
13.3.5. Рекомендательные блокировки
PostgreSQL также имеет средства создания блокировок, смысл которых определяют сами прило-
жения. Такие блокировки называются рекомендательными, так как система не форсирует их ис-
пользование — правильно их использовать должно само приложение. Рекомендательные блоки-
ровки бывают полезны для реализаций стратегий блокирования, плохо вписывающихся в модель
MVCC. Например, рекомендательные блокировки часто применяются для исполнения стратегии
пессимистичной блокировки, типичной для систем управления данными «плоский файл». Хотя для
этого можно использовать и дополнительные флаги в таблицах, рекомендательные блокировки ра-
ботают быстрее, не нагружают таблицы и автоматически ликвидируется сервером в конце сеанса.
В PostgreSQL есть два варианта получить рекомендательные блокировки: на уровне сеанса и на
уровне транзакции. Рекомендательная блокировка, полученная на уровне сеанса, удерживается,
пока она не будет явно освобождена, или до конца сеанса. В отличие от стандартных рекомен-
дательные блокировки уровня сеанса нарушают логику транзакций — блокировка, полученная в
транзакции, даже если произойдёт откат этой транзакции, будет сохраняться в сеансе; аналогич-
но, освобождение блокировки остаётся в силе, даже если транзакция, в которой оно было выпол-
нено, позже прерывается. Вызывающий процесс может запросить блокировку несколько раз; при
этом каждому запросу блокировки должен соответствовать запрос освобождения, чтобы она была
действительно освобождена. Рекомендательные блокировки на уровне транзакций, напротив, во
многом похожи на обычные блокировки: они автоматически освобождаются в конце транзакций и
не требуют явного освобождения. Для кратковременного применения блокировок это поведение
часто более уместно, чем поведение рекомендательных блокировок на уровне сеанса. Запросы ре-
комендательных блокировок одного идентификатора на уровне сеанса и на уровне транзакции бу-
дут блокировать друг друга вполне предсказуемым образом. Если сеанс уже владеет данной реко-
мендуемой блокировкой, дополнительные запросы её в том же сеансе будут всегда успешны, даже
если её ожидают другие сеансы. Это утверждение справедливо вне зависимости от того, на каком
уровне (сеанса или транзакции) установлены или запрашиваются новые блокировки.
Как и остальные блокировки в PostgreSQL, все рекомендательные блокировки, связанные с любы-
ми сеансами, можно просмотреть в системном представлении pg_locks.
И рекомендательные, и обычные блокировки сохраняются в области общей памяти, размер кото-
рой определяется параметрами конфигурации max_locks_per_transaction и max_connections. Важ-
но, чтобы этой памяти было достаточно, так как в противном случае сервер не сможет выдать ника-
кую блокировку. Таким образом, число рекомендуемых блокировок, которые может выдать сервер,
ограничивается обычно десятками или сотнями тысяч в зависимости от конфигурации сервера.
В определённых случаях при использовании рекомендательных блокировок, особенно в запросах
с явными указаниями ORDER BY и LIMIT, важно учитывать, что получаемые блокировки могут за-
висеть от порядка вычисления SQL-выражений. Например:
SELECT pg_advisory_lock(id) FROM foo WHERE id = 12345; – ok
SELECT pg_advisory_lock(id) FROM foo WHERE id &gt; 12345 LIMIT 100; – опасно!
SELECT pg_advisory_lock(q.id) FROM
(
SELECT id FROM foo WHERE id &gt; 12345 LIMIT 100
) q; – ok
В этом примере второй вариант опасен, так как LIMIT не обязательно будет применяться перед
вызовом функции блокировки. В результате приложение может получить блокировки, на которые
оно не рассчитывает и которые оно не сможет освободить (до завершения сеанса). С точки зрения
приложения такие блокировки окажутся в подвешенном состоянии, хотя они и будут отображаться
в pg_locks.
Функции, предназначенные для работы с рекомендательными блокировками, описаны в Подраз-
деле 9.26.10.
418Управление конку-
рентным доступом
13.4. Проверки целостности данных на уровне прило-
жения
Используя транзакции Read Committed, очень сложно обеспечить целостность данных с точки зре-
ния бизнес-логики, так как представление данных смещается с каждым оператором и даже один
оператор может не ограничиваться своим снимком состояния в случае конфликта записи.
Хотя транзакция Repeatable Read получает стабильное представление данных в процессе выпол-
нения, с использованием снимков MVCC для проверки целостности данных всё же связаны тонкие
моменты, включая так называемые конфликты чтения/записи. Если одна транзакция записыва-
ет данные, а другая в это же время пытается их прочитать (до или после записи), она не может
увидеть результат работы первой. В таком случае создаётся впечатление, что читающая транзак-
ция выполняется первой вне зависимости от того, какая из них была начата или зафиксирована
раньше. Если этим всё и ограничивается, нет никаких проблем, но если читающая транзакция
также пишет данные, которые читает параллельная транзакция, получается, что теперь эта тран-
закция будет исполняться, как будто она запущена перед другими вышеупомянутыми. Если же
транзакция, которая должна исполняться как последняя, на самом деле зафиксирована первой, в
графе упорядоченных транзакций легко может возникнуть цикл. И когда он возникает, проверки
целостности не будут работать правильно без дополнительных мер.
Как было сказано в Подразделе  13.2.3, сериализуемые транзакции представляют собой те же
транзакции Repeatable Read, но дополненные неблокирующим механизмом отслеживания опас-
ных условий конфликтов чтения/записи. Когда выявляется условие, приводящее к циклу в порядке
транзакций, одна из этих транзакций откатывается и этот цикл таким образом разрывается.
13.4.1. Обеспечение согласованности в сериализуемых транзак-
циях
Если для всех операций чтения и записи, нуждающихся в согласованном представлении данных,
используются транзакции уровня изоляции Serializable, это обеспечивает необходимую согласо-
ванность без дополнительных усилий. Приложения из других окружений, применяющие сериали-
зуемые транзакции для обеспечения целостности, в PostgreSQL в этом смысле будут «просто ра-
ботать».
Применение этого подхода избавляет программистов приложений от лишних сложностей, если
приложение использует инфраструктуру, которая автоматически повторяет транзакции в случае
отката из-за сбоев сериализации. Возможно, serializable стоит даже установить в качестве уров-
ня изоляции по умолчанию (default_transaction_isolation). Также имеет смысл принять меры
для предотвращения использования других уровней изоляции, непреднамеренного или с целью
обойти проверки целостности, например проверять уровень изоляции в триггерах.
Рекомендации по увеличению быстродействия приведены в Подразделе 13.2.3.
Предупреждение
Защита целостности с применением сериализуемых транзакций пока ещё не поддер-
живается в режиме горячего резерва (Раздел 26.5). Поэтому там, где применяется го-
рячий резерв, следует использовать уровень Repeatable Read и явные блокировки на
главном сервере.
13.4.2. Применение явных блокировок для обеспечения согласо-
ванности
Когда возможны несериализуемые операции записи, для обеспечения целостности строк и защи-
ты от одновременных изменений, следует использовать SELECT FOR UPDATE, SELECT FOR SHARE
или соответствующий оператор LOCK TABLE. (SELECT FOR UPDATE и SELECT FOR SHARE защищают
419Управление конку-
рентным доступом
от параллельных изменений только возвращаемые строки, тогда как LOCK TABLE блокирует всю
таблицу.) Это следует учитывать, перенося в PostgreSQL приложения из других СУБД.
Мигрируя в PostgreSQL из других СУБД также следует учитывать, что команда SELECT FOR UPDATE
сама по себе не гарантирует, что параллельная транзакция не изменит или не удалит выбранную
строку. Для получения такой гарантии в PostgreSQL нужно именно изменить эту строку, даже ес-
ли никакие значения в ней менять не требуется. SELECT FOR UPDATE временно блокирует другие
транзакции, не давая им получить ту же блокировку или выполнить команды UPDATE или DELETE,
которые бы повлияли на заблокированную строку, но как только транзакция, владеющая этой бло-
кировкой, фиксируется или откатывается, заблокированная транзакция сможет выполнить кон-
фликтующую операцию, если только для данной строки действительно не был выполнен UPDATE,
пока транзакция владела блокировкой.
Реализация глобальной целостности с использованием несериализуемых транзакций MVCC тре-
бует более вдумчивого подхода. Например, банковскому приложению может потребоваться про-
верить, равняется ли сумма всех расходов в одной таблице сумме приходов в другой, при том, что
обе таблицы активно изменяются. Просто сравнивать результаты двух успешных последователь-
ных команд SELECT sum(…) в режиме Read Committed нельзя, так как вторая команда может
захватить результаты транзакций, пропущенных первой. Подсчитывая суммы в одной транзакции
Repeatable Read, можно получить точную картину только для транзакций, которые были зафикси-
рованы до начала данной, но при этом может возникнуть законный вопрос — будет ли этот резуль-
тат актуален тогда, когда он будет выдан. Если транзакция Repeatable Read сама вносит какие-то
изменения, прежде чем проверять равенство сумм, полезность этой проверки становится ещё бо-
лее сомнительной, так как при проверке будут учитываться некоторые, но не все изменения, про-
изошедшие после начала транзакции. В таких случаях предусмотрительный разработчик может
заблокировать все таблицы, задействованные в проверке, чтобы получить картину действитель-
ности, не вызывающую сомнений. Для этого применяется блокировка SHARE (или более строгая),
которая гарантирует, что в заблокированной таблице не будет незафиксированных изменений, за
исключением тех, что внесла текущая транзакция.
Также заметьте, что, применяя явные блокировки для предотвращения параллельных операций
записи, следует использовать либо режим Read Committed, либо в режиме Repeatable Read обяза-
тельно получать блокировки прежде, чем выполнять запросы. Блокировка, получаемая транзакци-
ей Repeatable Read, гарантирует, что никакая другая транзакция, изменяющая таблицу, не выпол-
няется, но если снимок состояния, полученный транзакцией, предшествует блокировке, он может
не включать на данный момент уже зафиксированные изменения. Снимок состояния в транзакции
Repeatable Read создаётся фактически на момент начала первой команды выборки или изменения
данных (SELECT, INSERT, UPDATE или DELETE), так что получить явные блокировки можно до того,
как он будет сформирован.
13.5. Ограничения
Некоторые команды DDL, в настоящее время это TRUNCATE и формы ALTER TABLE, перезаписы-
вающие таблицу, не являются безопасными с точки зрения MVCC. Это значит, что после фиксации
усечения или перезаписи таблица окажется пустой для всех параллельных транзакций, если они
работают со снимком, полученным перед фиксацией такой команды DDL. Это может проявиться
только в транзакции, которая не обращалась к таблице до момента начала команды DDL — лю-
бая транзакция, которая обращалась к ней раньше, получила бы как минимум блокировку ACCESS
SHARE, которая заблокировала бы эту команду DDL до завершения транзакции. Поэтому такие ко-
манды не приводят ни к каким видимым несоответствиям с содержимым таблицы при последова-
тельных запросах к целевой таблице, хотя возможно видимое несоответствие между содержимым
целевой таблицы и другими таблицами в базе данных.
Поддержка уровня изоляции Serializable ещё не реализована для целевых серверов горячего ре-
зерва (они описываются в Разделе 26.5). На данный момент самый строгий уровень изоляции, под-
держиваемый в режиме горячего резерва, это Repeatable Read. Хотя и тогда, когда главный сервер
выполняет запись в транзакциях Serializable, все резервные серверы в итоге достигают согласо-
ванного состояния, но транзакция Repeatable Read на резервном сервере иногда может увидеть
420Управление конку-
рентным доступом
промежуточное состояние, не соответствующее результату последовательного выполнения тран-
закций на главном сервере.
13.6. Блокировки и индексы
Хотя PostgreSQL обеспечивает неблокирующий доступ на чтение/запись к данным таблиц, для ин-
дексов в настоящий момент это поддерживается не в полной мере. PostgreSQL управляет доступом
к различным типам индексов следующим образом:
Индексы типа B-дерево, GiST и SP-GiST
Для управления чтением/записью используются кратковременные блокировки на уровне стра-
ницы, исключительные и разделяемые. Блокировки освобождаются сразу после извлечения
или добавления строки индекса. Эти типы индексов обеспечивают максимальное распаралле-
ливание операций, не допуская взаимоблокировок.
Хеш-индексы
Для управления чтением/записью используются блокировки на уровне групп хеша. Блокиров-
ки освобождаются после обработки всей группы. Такие блокировки с точки зрения распарал-
леливания лучше, чем блокировки на уровне индекса, но не исключают взаимоблокировок, так
как они сохраняются дольше, чем выполняется одна операция с индексом.
Индексы GIN
Для управления чтением/записью используются кратковременные блокировки на уровне стра-
ницы, исключительные и разделяемые. Блокировки освобождаются сразу после извлечения
или добавления строки индекса. Но заметьте, что добавление значения в поле с GIN-индексом
обычно влечёт добавление нескольких ключей индекса, так что GIN может проделывать целый
ряд операций для одного значения.
В настоящее время в многопоточной среде наиболее производительны индексы-B-деревья; и так
как они более функциональны, чем хеш-индексы, их рекомендуется использовать в такой среде
для приложений, когда нужно индексировать скалярные данные. Если же нужно индексировать
не скалярные данные, B-деревья не подходят, и вместо них следует использовать индексы GiST,
SP-GiST или GIN.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
      <div class="entry-image-index">
        <a href="http://localhost:4000/PostgreSQL-V11_Doc-012/" title="Глава 12. Полнотекстовый поиск"><img src="http://localhost:4000/images/abstract-11.jpg" alt="Глава 12. Полнотекстовый поиск"></a>
      </div><!-- /.entry-image -->
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2018-12-01T00:00:00+02:00"><a href="http://localhost:4000/PostgreSQL-V11_Doc-012/">December 01, 2018</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Sergey Khatsiola">Sergey Khatsiola</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~63 minutes
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/PostgreSQL-V11_Doc-012/" rel="bookmark" title="Глава 12. Полнотекстовый поиск" itemprop="url">Глава 12. Полнотекстовый поиск</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Глава 12. Полнотекстовый поиск</p>

<p>12.1. Введение
Полнотекстовый поиск (или просто поиск текста) — это возможность находить документы на
естественном языке, соответствующие запросу, и, возможно, дополнительно сортировать их по
релевантности для этого запроса. Наиболее распространённая задача — найти все документы,
содержащие слова запроса, и выдать их отсортированными по степени соответствия запросу.
Понятия запроса и соответствия довольно расплывчаты и зависят от конкретного приложения.
В самом простом случае запросом считается набор слов, а соответствие определяется частотой
слов в документе.
Операторы текстового поиска существуют в СУБД уже многие годы. В PostgreSQL для текстовых
типов данных есть операторы ~, ~*, LIKE и ILIKE, но им не хватает очень важных вещей, которые
требуются сегодня от информационных систем:
• Нет поддержки лингвистического функционала, даже для английского языка. Возможности
регулярных выражений ограничены — они не рассчитаны на работу со словоформами, напри-
мер, подходят и подходить. С ними вы можете пропустить документы, которые содержат под-
ходят, но, вероятно, и они представляют интерес при поиске по ключевому слову подходить.
Конечно, можно попытаться перечислить в регулярном выражении все варианты слова, но
это будет очень трудоёмко и чревато ошибками (некоторые слова могут иметь десятки слово-
форм).
• Они не позволяют упорядочивать результаты поиска (по релевантности), а без этого поиск
неэффективен, когда находятся сотни подходящих документов.
• Они обычно выполняются медленно из-за отсутствия индексов, так как при каждом поиске
приходится просматривать все документы.
Полнотекстовая индексация заключается в предварительной обработке документов и сохране-
нии индекса для последующего быстрого поиска. Предварительная обработка включает следую-
щие операции:
Разбор документов на фрагменты. При этом полезно выделить различные классы фрагмен-
тов, например, числа, слова, словосочетания, почтовые адреса и т. д., которые будут обраба-
тываться по-разному. В принципе классы фрагментов могут зависеть от приложения, но для
большинства применений вполне подойдёт предопределённый набор классов. Эту операцию в
PostgreSQL выполняет анализатор (parser). Вы можете использовать как стандартный анали-
затор, так и создавать свои, узкоспециализированные.
Преобразование фрагментов в лексемы. Лексема — это нормализованный фрагмент, в кото-
ром разные словоформы приведены к одной. Например, при нормализации буквы верхнего ре-
гистра приводятся к нижнему, а из слов обычно убираются окончания (в частности, s или es в
английском). Благодаря этому можно находить разные формы одного слова, не вводя вручную
все возможные варианты. Кроме того, на данном шаге обычно исключаются стоп-слова, то
есть слова, настолько распространённые, что искать их нет смысла. (Другими словами, фраг-
менты представляют собой просто подстроки текста документа, а лексемы — это слова, имею-
щие ценность для индексации и поиска.) Для выполнения этого шага в PostgreSQL использу-
ются словари. Набор существующих стандартных словарей при необходимости можно расши-
рять, создавая свои собственные.
Хранение документов в форме, подготовленной для поиска. Например, каждый документ мо-
жет быть представлен в виде сортированного массива нормализованных лексем. Помимо лек-
сем часто желательно хранить информацию об их положении для ранжирования по близо-
сти, чтобы документ, в котором слова запроса расположены «плотнее», получал более высо-
кий ранг, чем документ с разбросанными словами.
Словари позволяют управлять нормализацией фрагментов с большой гибкостью. Создавая слова-
ри, можно:
• Определять стоп-слова, которые не будут индексироваться.
370Полнотекстовый поиск
•
•
•
•
Сопоставлять
Сопоставлять
Сопоставлять
Сопоставлять
Snowball.
синонимы с одним словом, используя Ispell.
словосочетания с одним словом, используя тезаурус.
различные склонения слова с канонической формой, используя словарь Ispell.
различные склонения слова с канонической формой, используя стеммер
Для хранения подготовленных документов в PostgreSQL предназначен тип данных tsvector, а для
представления обработанных запросов — тип tsquery (Раздел 8.11). С этими типами данных ра-
ботают целый ряд функций и операторов (Раздел 9.13), и наиболее важный из них — оператор со-
ответствия @@, с которым мы познакомимся в Подразделе 12.1.2. Для ускорения полнотекстового
поиска могут применяться индексы (Раздел 12.9).
12.1.1. Что такое документ?
Документ — это единица обработки в системе полнотекстового поиска; например, журнальная
статья или почтовое сообщение. Система поиска текста должна уметь разбирать документы и со-
хранять связи лексем (ключевых слов) с содержащим их документом. Впоследствии эти связи мо-
гут использоваться для поиска документов с заданными ключевыми словами.
В контексте поиска в PostgreSQL документ — это обычно содержимое текстового поля в строке
таблицы или, возможно, сочетание (объединение) таких полей, которые могут храниться в разных
таблицах или формироваться динамически. Другими словами, документ для индексации может
создаваться из нескольких частей и не храниться где-либо как единое целое. Например:
SELECT title || ‘ ‘ ||
AS document
FROM messages
WHERE mid = 12;
author || ‘ ‘ ||
abstract || ‘ ‘ || body
SELECT m.title || ‘ ‘ || m.author || ‘ ‘ || m.abstract || ‘ ‘ || d.body
AS document
FROM messages m, docs d
WHERE mid = did AND mid = 12;
Примечание
На самом деле в этих примерах запросов следует использовать функцию coalesce, что-
бы значение NULL в каком-либо одном атрибуте не привело к тому, что результирую-
щим документом окажется NULL.
Документы также можно хранить в обычных текстовых файлах в файловой системе. В этом случае
база данных может быть просто хранилищем полнотекстового индекса и исполнителем запросов,
а найденные документы будут загружаться из файловой системы по некоторым уникальным иден-
тификаторам. Однако для загрузки внешних файлов требуются права суперпользователя или под-
держка специальных функций, так что это обычно менее удобно, чем хранить все данные внутри
БД PostgreSQL. Кроме того, когда всё хранится в базе данных, это упрощает доступ к метаданным
документов при индексации и выводе результатов.
Для нужд текстового поиска каждый документ должен быть сведён к специальному формату
tsvector. Поиск и ранжирование выполняется исключительно с этим представлением документа
— исходный текст потребуется извлечь, только когда документ будет отобран для вывода пользо-
вателю. Поэтому мы часто подразумеваем под tsvector документ, тогда как этот тип, конечно,
содержит только компактное представление всего документа.
12.1.2. Простое соответствие текста
Полнотекстовый поиск в PostgreSQL реализован на базе оператора соответствия @@, который воз-
вращает true, если tsvector (документ) соответствует tsquery (запросу). Для этого оператора не
важно, какой тип записан первым:
371Полнотекстовый поиск
SELECT ‘a fat cat sat on a mat and ate a fat rat’::tsvector @@
‘cat &amp; rat’::tsquery;
?column?
———-
t
SELECT ‘fat &amp; cow’::tsquery @@
‘a fat cat sat on a mat and ate a fat rat’::tsvector;
?column?
———-
f
Как можно догадаться из этого примера, tsquery — это не просто текст, как и tsvector. Значение
типа tsquery содержит искомые слова, это должны быть уже нормализованные лексемы, возможно
объединённые в выражение операторами И, ИЛИ, НЕ и ПРЕДШЕСТВУЕТ. (Подробнее синтаксис
описан в Подразделе 8.11.2.) Вы можете воспользоваться функциями to_tsquery, plainto_tsquery
и phraseto_tsquery, которые могут преобразовать заданный пользователем текст в значение
tsquery, прежде всего нормализуя слова в этом тексте. Функция to_tsvector подобным образом
может разобрать и нормализовать текстовое содержимое документа. Так что запрос с поиском
соответствия на практике выглядит скорее так:
SELECT to_tsvector(‘fat cats ate fat rats’) @@ to_tsquery(‘fat &amp; rat’);
?column?
———-
t
Заметьте, что соответствие не будет обнаружено, если запрос записан как
SELECT ‘fat cats ate fat rats’::tsvector @@ to_tsquery(‘fat &amp; rat’);
?column?
———-
f
так как слово rats не будет нормализовано. Элементами tsvector являются лексемы, предполо-
жительно уже нормализованные, так что rats считается не соответствующим rat.
Оператор @@ также может принимать типы text, позволяя опустить явные преобразования тексто-
вых строк в типы tsvector и tsquery в простых случаях. Всего есть четыре варианта этого опера-
тора:
tsvector @@ tsquery
tsquery @@ tsvector
text @@ tsquery
text @@ text
Первые два мы уже видели раньше. Форма text@@tsquery равнозначна выражению to_tsvector(x)
@@ y, а форма text@@text — выражению to_tsvector(x) @@ plainto_tsquery(y).
В значении tsquery оператор &amp; (И) указывает, что оба его операнда должны присутствовать в до-
кументе, чтобы он удовлетворял запросу. Подобным образом, оператор | (ИЛИ) указывает, что
в документе должен присутствовать минимум один из его операндов, тогда как оператор ! (НЕ)
указывает, что его операнд не должен присутствовать, чтобы условие удовлетворялось. Например,
запросу fat &amp; ! rat соответствуют документы, содержащие fat и не содержащие rat.
Фразовый поиск возможен с использованием оператора &lt;-&gt; (ПРЕДШЕСТВУЕТ) типа tsquery, ко-
торый находит соответствие, только если его операнды расположены рядом и в заданном порядке.
Например:
SELECT to_tsvector(‘fatal error’) @@ to_tsquery(‘fatal &lt;-&gt; error’);
?column?
———-
t
372Полнотекстовый поиск
SELECT to_tsvector(‘error is not fatal’) @@ to_tsquery(‘fatal &lt;-&gt; error’);
?column?
———-
f
Более общая версия оператора ПРЕДШЕСТВУЕТ имеет вид <N>, где N — целое число, выражающее
разность между позициями найденных лексем. Запись &lt;1&gt; равнозначна &lt;-&gt;, тогда как &lt;2&gt; допуска-
ет существование ровно одной лексемы между этими лексемами и т. д. Функция phraseto_tsquery
задействует этот оператор для конструирования tsquery, который может содержать многослов-
ную фразу, включающую в себя стоп-слова. Например:
SELECT phraseto_tsquery('cats ate rats');
phraseto_tsquery
-------------------------------
'cat' &lt;-&gt; 'ate' &lt;-&gt; 'rat'
SELECT phraseto_tsquery('the cats ate the rats');
phraseto_tsquery
-------------------------------
'cat' &lt;-&gt; 'ate' &lt;2&gt; 'rat'
Особый случай, который иногда бывает полезен, представляет собой запись &lt;0&gt;, требующая, чтобы
обоим лексемам соответствовало одно слово.
Сочетанием операторов tsquery можно управлять, применяя скобки. Без скобок операторы имеют
следующие приоритеты, в порядке возрастания: |, &amp;, &lt;-&gt; и самый приоритетный — !.
Стоит отметить, что операторы И/ИЛИ/НЕ имеют несколько другое значение, когда они приме-
няются в аргументах оператора ПРЕДШЕСТВУЕТ, так как в этом случае имеет значение точная
позиция совпадения. Например, обычному !x соответствуют только документы, не содержащие
x нигде. Но условию !x &lt;-&gt; y соответствует y, если оно не следует непосредственно за x; при
вхождении x в любом другом месте документа он не будет исключаться из рассмотрения. Другой
пример: для условия x &amp; y обычно требуется, чтобы и x, и y встречались в каком-то месте доку-
мента, но для выполнения условия (x &amp; y) &lt;-&gt; z требуется, чтобы x и y располагались в одном
месте, непосредственно перед z. Таким образом, этот запрос отличается от x &lt;-&gt; z &amp; y &lt;-&gt; z,
которому удовлетворяют документы, содержащие две отдельные последовательности x z и y z.
(Этот конкретный запрос в таком виде, как он записан, не имеет смысла, так как x и y не могут
находиться в одном месте; но в более сложных ситуациях, например, с шаблонами поиска по мас-
ке, запросы этого вида могут быть полезны.)
12.1.3. Конфигурации
До этого мы рассматривали очень простые примеры поиска текста. Как было упомянуто выше, весь
функционал текстового поиска позволяет делать гораздо больше: пропускать определённые сло-
ва (стоп-слова), обрабатывать синонимы и выполнять сложный анализ слов, например, выделять
фрагменты не только по пробелам. Все эти функции управляются конфигурациями текстового
поиска. В PostgreSQL есть набор предопределённых конфигураций для многих языков, но вы также
можете создавать собственные конфигурации. (Все доступные конфигурации можно просмотреть
с помощью команды \dF в psql.)
Подходящая конфигурация для данной среды выбирается во время установки и записывается в
параметре default_text_search_config в postgresql.conf. Если вы используете для всего кластера
одну конфигурацию текстового поиска, вам будет достаточно этого параметра в postgresql.conf.
Если же требуется использовать в кластере разные конфигурации, но для каждой базы данных
одну определённую, её можно задать командой ALTER DATABASE ... SET. В противном случае
конфигурацию можно выбрать в рамках сеанса, определив параметр default_text_search_config.
У каждой функции текстового поиска, зависящей от конфигурации, есть необязательный аргу-
мент regconfig, в котором можно явно указать конфигурацию для данной функции. Значение
default_text_search_config используется, только когда этот аргумент опущен.
373Полнотекстовый поиск
Для упрощения создания конфигураций текстового поиска они строятся из более простых объек-
тов. В PostgreSQL есть четыре типа таких объектов:
• Анализаторы текстового поиска разделяют документ на фрагменты и классифицируют их
(например, как слова или числа).
• Словари текстового поиска приводят фрагменты к нормализованной форме и отбрасывают
стоп-слова.
• Шаблоны текстового поиска предоставляют функции, образующие реализацию словарей.
(При создании словаря просто задаётся шаблон и набор параметров для него.)
• Конфигурации текстового поиска выбирают анализатор и набор словарей, который будет ис-
пользоваться для нормализации фрагментов, выданных анализатором.
Анализаторы и шаблоны текстового поиска строятся из низкоуровневых функций на языке C; что-
бы создать их, нужно программировать на C, а подключить их к базе данных может только супер-
пользователь. (В подкаталоге contrib/ инсталляции PostgreSQL можно найти примеры дополни-
тельных анализаторов и шаблонов.) Так как словари и конфигурации представляют собой просто
наборы параметров, связывающие анализаторы и шаблоны, их можно создавать, не имея админи-
стративных прав. Далее в этой главе будут приведены примеры их создания.
12.2. Таблицы и индексы
В предыдущем разделе приводились примеры, которые показывали, как можно выполнить сопо-
ставление с простыми текстовыми константами. В этом разделе показывается, как находить текст
в таблице, возможно с применением индексов.
12.2.1. Поиск в таблице
Полнотекстовый поиск можно выполнить, не применяя индекс. Следующий простой запрос выво-
дит заголовок (title) каждой строки, содержащей слово friend в поле body:
SELECT title
FROM pgweb
WHERE to_tsvector('english', body) @@ to_tsquery('english', 'friend');
При этом также будут найдены связанные слова, такие как friends и friendly, так как все они
сводятся к одной нормализованной лексеме.
В показанном выше примере для разбора и нормализации строки явно выбирается конфигурация
english. Хотя параметры, задающие конфигурацию, можно опустить:
SELECT title
FROM pgweb
WHERE to_tsvector(body) @@ to_tsquery('friend');
Такой запрос будет использовать конфигурацию, заданную в параметре default_text_search_config.
В следующем более сложном примере выбираются десять документов, изменённых последними,
со словами create и table в полях title или body:
SELECT title
FROM pgweb
WHERE to_tsvector(title || ' ' || body) @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
Чтобы найти строки, содержащие NULL в одном из полей, нужно воспользоваться функцией
coalesce, но здесь мы опустили её вызовы для краткости.
Хотя такие запросы будут работать и без индекса, для большинства приложений скорость будет
неприемлемой; этот подход рекомендуется только для нерегулярного поиска и динамического со-
держимого. Для практического применения полнотекстового поиска обычно создаются индексы.
374Полнотекстовый поиск
12.2.2. Создание индексов
Для ускорения текстового поиска мы можем создать индекс GIN (см. Раздел 12.9):
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', body));
Заметьте, что здесь используется функция to_tsvector с двумя аргументами. В выражениях, опре-
деляющих индексы, можно использовать только функции, в которых явно задаётся имя конфигура-
ции текстового поиска (см. Раздел 11.7). Это объясняется тем, что содержимое индекса не должно
зависеть от значения параметра default_text_search_config. В противном случае содержимое ин-
декса может быть неактуальным, если разные его элементы tsvector будут создаваться с разными
конфигурациями текстового поиска и нельзя будет понять, какую именно использовать. Выгрузить
и восстановить такой индекс будет невозможно.
Так как при создании индекса использовалась версия to_tsvector с двумя аргументами, этот ин-
декс будет использоваться только в запросах, где to_tsvector вызывается с двумя аргументами и
во втором передаётся имя той же конфигурации. То есть, WHERE to_tsvector('english', body)
@@ 'a &amp; b' сможет использовать этот индекс, а WHERE to_tsvector(body) @@ 'a &amp; b' — нет. Это
гарантирует, что индекс будет использоваться только с той конфигурацией, с которой создавались
его элементы.
Индекс можно создать более сложным образом, определив для него имя конфигурации в другом
столбце таблицы, например:
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector(config_name, body));
где config_name — имя столбца в таблице pgweb. Так можно сохранить имя конфигурации, связан-
ной с элементом индекса, и, таким образом, иметь в одном индексе элементы с разными конфигу-
рациями. Это может быть полезно, например, когда в коллекции документов хранятся документы
на разных языках. И в этом случае в запросах должен использоваться тот же индекс (с таким же
образом задаваемой конфигурацией), например, так: WHERE to_tsvector(config_name, body) @@
'a &amp; b'.
Индексы могут создаваться даже по объединению столбцов:
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', title || ' ' ||
body));
Ещё один вариант — создать отдельный столбец tsvector, в котором сохранить результат
to_tsvector. Следующий пример показывает, как можно подготовить для индексации объединён-
ное содержимое столбцов title и body, применив функцию coalesce для получения желаемого
результата, даже когда один из столбцов NULL:
ALTER TABLE pgweb ADD COLUMN textsearchable_index_col tsvector;
UPDATE pgweb SET textsearchable_index_col =
to_tsvector('english', coalesce(title,'') || ' ' || coalesce(body,''));
Затем мы создаём индекс GIN для ускорения поиска:
CREATE INDEX textsearch_idx ON pgweb USING GIN (textsearchable_index_col);
Теперь мы можем быстро выполнять полнотекстовый поиск:
SELECT title
FROM pgweb
WHERE textsearchable_index_col @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
Когда представление tsvector хранится в отдельном столбце, необходимо создать триггер, кото-
рый будет поддерживать столбец с tsvector в актуальном состоянии при любых изменениях title
или body. Как это сделать, рассказывается в Подразделе 12.4.3.
Хранение вычисленного выражения индекса в отдельном столбце даёт ряд преимуществ. Во-пер-
вых, для использования индекса в запросах не нужно явно указывать имя конфигурации тексто-
375Полнотекстовый поиск
вого поиска. Как показано в вышеприведённом примере, в этом случае запрос может зависеть от
default_text_search_config. Во-вторых, поиск выполняется быстрее, так как для проверки соот-
ветствия данных индексу не нужно повторно выполнять to_tsvector. (Это актуально больше для
индексов GiST, чем для GIN; см. Раздел 12.9.) С другой стороны, схему с индексом по выражению
проще реализовать и она позволяет сэкономить место на диске, так как представление tsvector
не хранится явно.
12.3. Управление текстовым поиском
Для реализации полнотекстового поиска необходимы функции, позволяющие создать tsvector из
документа и tsquery из запроса пользователя. Кроме того, результаты нужно выдавать в удобном
порядке, так что нам потребуется функция, оценивающая релевантность документа для данно-
го запроса. Важно также иметь возможность выводить найденный текст подходящим образом. В
PostgreSQL есть все необходимые для этого функции.
12.3.1. Разбор документов
Для преобразования документа в тип tsvector PostgreSQL предоставляет функцию to_tsvector.
to_tsvector([конфигурация regconfig,] документ text) returns tsvector
to_tsvector разбирает текстовый документ на фрагменты, сводит фрагменты к лексемам и воз-
вращает значение tsvector, в котором перечисляются лексемы и их позиции в документе. При
обработке документа используется указанная конфигурация текстового поиска или конфигурация
по умолчанию. Простой пример:
SELECT to_tsvector('english', 'a fat cat sat on a mat - it ate a fat rats');
to_tsvector
-----------------------------------------------------
'ate':9 'cat':3 'fat':2,11 'mat':7 'rat':12 'sat':4
В этом примере мы видим, что результирующий tsvector не содержит слова a, on и it, слово rats
превратилось rat, а знак препинания «-» был проигнорирован.
Функция to_tsvector внутри вызывает анализатор, который разбивает текст документа на фраг-
менты и классифицирует их. Для каждого фрагмента она проверяет список словарей (Раздел 12.6),
определяемый типом фрагмента. Первый же словарь, распознавший фрагмент, выдаёт одну или
несколько представляющих его лексем. Например, rats превращается в rat, так как один из сло-
варей понимает, что слово rats — это слово rat во множественном числе. Некоторое слова рас-
познаются как стоп-слова (Подраздел 12.6.1) и игнорируются как слова, фигурирующие в тексте
настолько часто, что искать их бессмысленно. В нашем примере это a, on и it. Если фрагмент не
воспринимается ни одним словарём из списка, он так же игнорируется. В данном примере это
происходит со знаком препинания -, так как с таким типом фрагмента (символы-разделители) не
связан никакой словарь и значит такие фрагменты никогда не будут индексироваться. Выбор ана-
лизатора, словарей и индексируемых типов фрагментов определяется конфигурацией текстового
поиска (Раздел 12.7). В одной базе данных можно использовать разные конфигурации, в том числе,
предопределённые конфигурации для разных языков. В нашем примере мы использовали конфи-
гурацию по умолчанию для английского языка — english.
Для назначения элементам tsvector разных весов используется функция setweight. Вес элемента
задаётся буквой A, B, C или D. Обычно это применяется для обозначения важности слов в разных
частях документа, например в заголовке или в теле документа. Затем эта информация может ис-
пользоваться при ранжировании результатов поиска.
Так как to_tsvector(NULL) вернёт NULL, мы советуем использовать coalesce везде, где соответству-
ющее поле может быть NULL. Создавать tsvector из структурированного документа рекоменду-
ется так:
UPDATE tt SET ti =
setweight(to_tsvector(coalesce(title,'')), 'A')
376
||Полнотекстовый поиск
setweight(to_tsvector(coalesce(keyword,'')), 'B') ||
setweight(to_tsvector(coalesce(abstract,'')), 'C') ||
setweight(to_tsvector(coalesce(body,'')), 'D');
Здесь мы использовали setweight для пометки происхождения каждой лексемы в сформирован-
ных значениях tsvector и объединили помеченные значения с помощью оператора конкатенации
типов tsvector ||. (Подробнее эти операции рассматриваются в Подразделе 12.4.1.)
12.3.2. Разбор запросов
PostgreSQL предоставляет функции to_tsquery, plainto_tsquery, phraseto_tsquery и
websearch_to_tsquery для приведения запроса к типу tsquery. Функция to_tsquery даёт больше
возможностей, чем plainto_tsquery или phraseto_tsquery, но более строга к входным данным.
Функция websearch_to_tsquery представляет собой упрощённую версию to_tsquery с альтерна-
тивным синтаксисом, подобным тому, что принят в поисковых системах в Интернете.
to_tsquery([конфигурация regconfig,] текст_запроса text) returns tsquery
to_tsquery создаёт значение tsquery из текста_запроса, который может состоять из простых
фрагментов, разделённых логическими операторами tsquery: &amp; (И), | (ИЛИ), ! (НЕ) и &lt;-&gt; (ПРЕД-
ШЕСТВУЕТ), возможно, сгруппированных скобками. Другими словами, входное значение для
to_tsquery должно уже соответствовать общим правилам для значений tsquery, описанным в Под-
разделе 8.11.2. Различие их состоит в том, что во вводимом в tsquery значении фрагменты вос-
принимаются буквально, тогда как to_tsquery нормализует фрагменты, приводя их к лексемам,
используя явно указанную или подразумеваемую конфигурацию, и отбрасывая стоп-слова. Напри-
мер:
SELECT to_tsquery('english', 'The &amp; Fat &amp; Rats');
to_tsquery
---------------
'fat' &amp; 'rat'
Как и при вводе значения tsquery, для каждой лексемы можно задать вес(а), чтобы при поиске
можно было выбрать из tsvector только лексемы с заданными весами. Например:
SELECT to_tsquery('english', 'Fat | Rats:AB');
to_tsquery
------------------
'fat' | 'rat':AB
К лексеме также можно добавить *, определив таким образом условие поиска по префиксу:
SELECT to_tsquery('supern:*A &amp; star:A*B');
to_tsquery
--------------------------
'supern':*A &amp; 'star':*AB
Такая лексема будет соответствовать любому слову в tsvector, начинающемуся с данной подстро-
ки.
to_tsquery может также принимать фразы в апострофах. Это полезно в основном когда конфигу-
рация включает тезаурус, который может обрабатывать такие фразы. В показанном ниже примере
предполагается, что тезаурус содержит правило supernovae stars : sn:
SELECT to_tsquery('''supernovae stars'' &amp; !crab');
to_tsquery
---------------
'sn' &amp; !'crab'
Если убрать эти апострофы, to_tsquery не примет фрагменты, не разделённые операторами И,
ИЛИ и ПРЕДШЕСТВУЕТ, и выдаст синтаксическую ошибку.
plainto_tsquery([конфигурация regconfig,] текст_запроса text) returns tsquery
377Полнотекстовый поиск
plainto_tsquery преобразует неформатированный текст_запроса в значение tsquery. Текст раз-
бирается и нормализуется подобно тому, как это делает to_tsvector, а затем между оставшимися
словами вставляются операторы &amp; (И) типа tsquery.
Пример:
SELECT plainto_tsquery('english', 'The Fat Rats');
plainto_tsquery
-----------------
'fat' &amp; 'rat'
Заметьте, что plainto_tsquery не распознает во входной строке операторы tsquery, метки весов
или обозначения префиксов:
SELECT plainto_tsquery('english', 'The Fat &amp; Rats:C');
plainto_tsquery
---------------------
'fat' &amp; 'rat' &amp; 'c'
В данном случае все знаки пунктуации были отброшены как символы-разделители.
phraseto_tsquery([конфигурация regconfig,] текст_запроса text) returns tsquery
phraseto_tsquery ведёт себя подобно plainto_tsquery, за исключением того, что она вставляет
между оставшимися словами оператор &lt;-&gt; (ПРЕДШЕСТВУЕТ) вместо оператора &amp; (И). Кроме того,
стоп-слова не просто отбрасываются, а подсчитываются, и вместо операторов &lt;-&gt; используются
операторы <N> с подсчитанным числом. Эта функция полезна при поиске точных последователь-
ностей лексем, так как операторы ПРЕДШЕСТВУЕТ проверяют не только наличие всех лексем, но
и их порядок.
Пример:
SELECT phraseto_tsquery('english', 'The Fat Rats');
phraseto_tsquery
------------------
'fat' &lt;-&gt; 'rat'
Как и plainto_tsquery, функция phraseto_tsquery не распознает во входной строке операторы
типа tsquery, метки весов или обозначения префиксов:
SELECT phraseto_tsquery('english', 'The Fat &amp; Rats:C');
phraseto_tsquery
-----------------------------
'fat' &lt;-&gt; 'rat' &lt;-&gt; 'c'
websearch_to_tsquery([конфигурация regconfig,] текст_запроса text) returns tsquery
Функция websearch_to_tsquery создаёт значение tsquery из текста_запроса, используя альтер-
нативный синтаксис, в котором запрос задаётся просто неформатированным текстом. В отличие
от plainto_tsquery и phraseto_tsquery, она также принимает определённые операторы. Более
того, эта функция не должна никогда выдавать синтаксические ошибки, что позволяет осуществ-
лять поиск по произвольному заданному пользователем запросу. Она поддерживает следующий
синтаксис:
• текст не в кавычках: текст, не заключённый в кавычки, который будет преобразован в слова,
разделяемые операторами &amp;, как его восприняла бы функция plainto_tsquery.
• "текст в кавычках": текст, заключённый в кавычки, будет преобразован в слова, разделяе-
мые операторами &lt;-&gt;, как его восприняла бы функция phraseto_tsquery.
• OR: логическая операция ИЛИ будет преобразована в оператор |.
• -: логическая операция НЕ, преобразуется в оператор !.
Примеры:
SELECT websearch_to_tsquery('english', 'The fat rats');
378Полнотекстовый поиск
websearch_to_tsquery
----------------------
'fat' &amp; 'rat'
(1 row)
SELECT websearch_to_tsquery('english', '"supernovae stars" -crab');
websearch_to_tsquery
----------------------------------
'supernova' &lt;-&gt; 'star' &amp; !'crab'
(1 row)
SELECT websearch_to_tsquery('english', '"sad cat" or "fat rat"');
websearch_to_tsquery
-----------------------------------
'sad' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
(1 row)
SELECT websearch_to_tsquery('english', 'signal -"segmentation fault"');
websearch_to_tsquery
---------------------------------------
'signal' &amp; !( 'segment' &lt;-&gt; 'fault' )
(1 row)
SELECT websearch_to_tsquery('english', '""" )( dummy \\ query &lt;-&gt;');
websearch_to_tsquery
----------------------
'dummi' &amp; 'queri'
(1 row)
12.3.3. Ранжирование результатов поиска
Ранжирование документов можно представить как попытку оценить, насколько они релевантны
заданному запросу и отсортировать их так, чтобы наиболее релевантные выводились первыми. В
PostgreSQL встроены две функции ранжирования, принимающие во внимание лексическую, пози-
ционную и структурную информацию; то есть, они учитывают, насколько часто и насколько близ-
ко встречаются в документе ключевые слова и какова важность содержащей их части документа.
Однако само понятие релевантности довольно размытое и во многом определяется приложением.
Приложения могут использовать для ранжирования и другую информацию, например, время из-
менения документа. Встроенные функции ранжирования можно рассматривать лишь как примеры
реализации. Для своих конкретных задач вы можете разработать собственные функции ранжиро-
вания и/или учесть при обработке их результатов дополнительные факторы.
Ниже описаны две встроенные функции ранжирования:
ts_rank([веса float4[],] вектор tsvector, запрос tsquery [, нормализация integer]) returns
float4
Ранжирует векторы по частоте найденных лексем.
ts_rank_cd([веса float4[],] вектор tsvector, запрос tsquery [, нормализация integer])
returns float4
Эта функция вычисляет плотность покрытия для данного вектора документа и запроса, ис-
пользуя метод, разработанный Кларком, Кормаком и Тадхоуп и описанный в статье "Relevance
Ranking for One to Three Term Queries" в журнале "Information Processing and Management" в
1999 г. Плотность покрытия вычисляется подобно рангу ts_rank, но в расчёт берётся ещё и
близость соответствующих лексем друг к другу.
Для вычисления результата этой функции требуется информация о позиции лексем. Поэтому
она игнорируют «очищенные» от этой информации лексемы в tsvector. Если во входных дан-
379Полнотекстовый поиск
ных нет неочищенных лексем, результат будет равен нулю. (За дополнительными сведениями о
функции strip и позиционной информации в данных tsvector обратитесь к Подразделу 12.4.1.)
Для обеих этих функций аргумент веса позволяет придать больший или меньший вес словам, в
зависимости от их меток. В передаваемом массиве весов определяется, насколько весома каждая
категория слов, в следующем порядке:
{вес D, вес C, вес B, вес A}
Если этот аргумент опускается, подразумеваются следующие значения:
{0.1, 0.2, 0.4, 1.0}
Обычно весами выделяются слова из особых областей документа, например из заголовка или крат-
кого введения, с тем, чтобы эти слова считались более и менее значимыми, чем слова в основном
тексте документа.
Так как вероятность найти ключевые слова увеличивается с размером документа, при ранжиро-
вании имеет смысл учитывать его, чтобы, например, документ с сотней слов, содержащий пять
вхождений искомых слов, считался более релевантным, чем документ с тысячей слов и теми же
пятью вхождениями. Обе функции ранжирования принимают целочисленный параметр нормали-
зации, определяющий, как ранг документа будет зависеть от его размера. Этот параметр пред-
ставляет собой битовую маску и управляет несколькими режимами: вы можете включить сразу
несколько режимов, объединив значения оператором | (например так: 2|4).
•
•
•
•
0 (по умолчанию): длина документа не учитывается
1: ранг документа делится на 1 + логарифм длины документа
2: ранг документа делится на его длину
4: ранг документа делится на среднее гармоническое расстояние между блоками (это реали-
зовано только в ts_rank_cd)
• 8: ранг документа делится на число уникальных слов в документе
• 16: ранг документа делится на 1 + логарифм числа уникальных слов в документе
• 32: ранг делится своё же значение + 1
Если включены несколько флагов, соответствующие операции выполняются в показанном поряд-
ке.
Важно заметить, что функции ранжирования не используют никакую внешнюю информацию, так
что добиться нормализации до 1% или 100% невозможно, хотя иногда это желательно. Применив
параметр 32 (rank/(rank+1)), можно свести все ранги к диапазону 0..1, но это изменение будет
лишь косметическим, на порядке сортировки результатов это не отразится.
В данном примере выбираются десять найденных документов с максимальным рангом:
SELECT title, ts_rank_cd(textsearch, query) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
title
|
rank
-----------------------------------------------+----------
Neutrinos in the Sun
|
3.1
The Sudbury Neutrino Detector
|
2.4
A MACHO View of Galactic Dark Matter
| 2.01317
Hot Gas and Dark Matter
| 1.91171
The Virgo Cluster: Hot Plasma and Dark Matter | 1.90953
Rafting for Solar Neutrinos
|
1.9
NGC 4650A: Strange Galaxy and Dark Matter
| 1.85774
Hot Gas and Dark Matter
|
1.6123
Ice Fishing for Cosmic Neutrinos
|
1.6
Weak Lensing Distorts the Universe
| 0.818218
Тот же пример с нормализованным рангом:
380Полнотекстовый поиск
SELECT title, ts_rank_cd(textsearch, query, 32 /* rank/(rank+1) */ ) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
title
|
rank
-----------------------------------------------+-------------------
Neutrinos in the Sun
| 0.756097569485493
The Sudbury Neutrino Detector
| 0.705882361190954
A MACHO View of Galactic Dark Matter
| 0.668123210574724
Hot Gas and Dark Matter
| 0.65655958650282
The Virgo Cluster: Hot Plasma and Dark Matter | 0.656301290640973
Rafting for Solar Neutrinos
| 0.655172410958162
NGC 4650A: Strange Galaxy and Dark Matter
| 0.650072921219637
Hot Gas and Dark Matter
| 0.617195790024749
Ice Fishing for Cosmic Neutrinos
| 0.615384618911517
Weak Lensing Distorts the Universe
| 0.450010798361481
Ранжирование может быть довольно дорогостоящей операцией, так как для вычисления ранга
необходимо прочитать tsvector каждого подходящего документа и это займёт значительное вре-
мя, если придётся обращаться к диску. К сожалению, избежать этого вряд ли возможно, так как
на практике по многим запросам выдаётся большое количество результатов.
12.3.4. Выделение результатов
Представляя результаты поиска, в идеале нужно выделять часть документа и показывать, как он
связан с запросом. Обычно поисковые системы показывают фрагменты документа с отмеченны-
ми искомыми словами. В PostgreSQL для реализации этой возможности представлена функция
ts_headline.
ts_headline([конфигурация regconfig,] документ text, запрос tsquery [, параметры text])
returns text
ts_headline принимает документ вместе с запросом и возвращает выдержку из документа, в
которой выделяются слова из запроса. Применяемую для разбора документа конфигурацию
можно указать в параметре config; если этот параметр опущен, применяется конфигурация
default_text_search_config.
Если в параметрах передаётся строка options, она должна состоять из списка разделённых запя-
тыми пар параметр=значение. Параметры могут быть следующими:
• StartSel, StopSel: строки, которые будут разграничивать слова запроса в документе, выделяя
их среди остальных. Если эти строки содержат пробелы или запятые, их нужно заключить в
кавычки.
• MaxWords, MinWords: эти числа определяет нижний и верхний предел размера выдержки.
• ShortWord: слова такой длины или короче в начале и конце выдержки будут отбрасываться.
Значение по умолчанию, равное 3, исключает распространённые английские артикли.
• HighlightAll: логический флаг; если он равен true, выдержкой будет весь документ и три
предыдущие параметра игнорируются.
• MaxFragments: максимальное число выводимых текстовых выдержек или фрагментов. Значе-
ние по умолчанию, равное 0, выбирает метод создания выдержки без фрагментов. При значе-
нии большем 0 выбирается метод с фрагментами, когда находятся все фрагменты, содержа-
щие как можно больше слов запроса, а затем они сжимаются до слов запроса. Такие фрагмен-
ты могут содержать какие-то ключевые слова в середине и ограничиваются двумя искомыми
словами. При этом фрагменты могут содержать не больше MaxWords слов, а в начале и конце
они будут очищены от слов длины ShortWord и меньше. Если в документе найдены не все сло-
ва запроса, выводится один фрагмент, включающий первые MinWords слов в документе.
• FragmentDelimiter: Когда выводятся несколько фрагментов, они будут разделяться этой стро-
кой.
381Полнотекстовый поиск
Имена этих параметров распознаются без учёта регистра. Явно не определённые параметры по-
лучают такие значения по умолчанию:
StartSel=<b>, StopSel=</b>,
MaxWords=35, MinWords=15, ShortWord=3, HighlightAll=FALSE,
MaxFragments=0, FragmentDelimiter=" ... "
Пример использования:
SELECT ts_headline('english',
'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
to_tsquery('query &amp; similarity'));
ts_headline
------------------------------------------------------------
containing given <b>query</b> terms
and return them in order of their <b>similarity</b> to the
<b>query</b>.
SELECT ts_headline('english',
'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
to_tsquery('query &amp; similarity'),
'StartSel = &lt;, StopSel = &gt;');
ts_headline
-------------------------------------------------------
containing given <query> terms
and return them in order of their <similarity> to the</similarity></query></N></N></p>
<query>.
Функция ts_headline работает с оригинальным документом, а не его сжатым представлением
tsvector, так что она может быть медленной и использовать её следует осмотрительно.
12.4. Дополнительные возможности
В этом разделе описываются дополнительные функции и операторы, которые могут быть полезны
при поиске текста.
12.4.1. Обработка документов
В Подразделе 12.3.1 показывалось, как обычные текстовые документы можно преобразовать в зна-
чения tsvector. PostgreSQL предлагает также набор функций и операторов для обработки доку-
ментов, уже представленных в формате tsvector.
tsvector || tsvector
Оператор конкатенации значений tsvector возвращает вектор, объединяющий лексемы и по-
зиционную информацию двух векторов, переданных ему в аргументах. В полученном результа-
те сохраняются позиции и метки весов. При этом позиции в векторе справа сдвигаются на мак-
симальное значение позиции в векторе слева, что почти равносильно применению to_tsvector
к результату конкатенации двух исходных строк документов. (Почти, потому что стоп-слова,
исключаемые в конце левого аргумента, при конкатенации исходных строк влияют на позиции
лексем в правой части, а при конкатенации tsvector — нет.)
Преимущество же конкатенации документов в векторной форме по сравнению с конкатенаци-
ей текста до вызова to_tsvector заключается в том, что так можно разбирать разные части
документа, применяя разные конфигурации. И так как функция setweight помечает все лексе-
382Полнотекстовый поиск
мы данного вектора одинаково, разбирать текст и выполнять setweight нужно до объединения
разных частей документа с подразумеваемым разным весом.
setweight(вектор tsvector, вес "char") returns tsvector
setweight возвращает копию входного вектора, помечая в ней каждую позицию заданным ве-
сом, меткой A, B, C или D. (Метка D по умолчанию назначается всем векторам, так что при выводе
она опускается.) Эти метки сохраняются при конкатенации векторов, что позволяет придавать
разные веса словам из разных частей документа и, как следствие, ранжировать их по-разному.
Заметьте, что веса назначаются позициям, а не лексемам. Если входной вектор очищен от
позиционной информации, setweight не делает ничего.
length(вектор tsvector) returns integer
Возвращает число лексем, сохранённых в векторе.
strip(вектор tsvector) returns tsvector
Возвращает вектор с теми же лексемами, что и в данном, но без информации о позиции и весе.
Очищенный вектор обычно оказывается намного меньше исходного, но при этом и менее по-
лезным. С очищенными векторами хуже работает ранжирование, а также оператор &lt;-&gt; (ПРЕД-
ШЕСТВУЕТ) типа tsquery никогда не найдёт соответствие в них, так как не сможет определить
расстояние между вхождениями лексем.
Полный список связанных с tsvector функций приведён в Таблице 9.41.
12.4.2. Обработка запросов
В Подразделе 12.3.2 показывалось, как обычные текстовые запросы можно преобразовывать в зна-
чения tsquery. PostgreSQL предлагает также набор функций и операторов для обработки запро-
сов, уже представленных в формате tsquery.
tsquery &amp;&amp; tsquery
Возвращает логическое произведение (AND) двух данных запросов.
tsquery || tsquery
Возвращает логическое объединение (OR) двух данных запросов.
!! tsquery
Возвращает логическое отрицание (NOT) данного запроса.
tsquery &lt;-&gt; tsquery
Возвращает запрос, который ищет соответствие первому данному запросу, за которым следует
соответствие второму данному запросу, с применением оператора &lt;-&gt; (ПРЕДШЕСТВУЕТ) типа
tsquery. Например:
SELECT to_tsquery('fat') &lt;-&gt; to_tsquery('cat | rat');
?column?
-----------------------------------
'fat' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
tsquery_phrase(запрос1 tsquery, запрос2 tsquery [, расстояние integer ]) returns tsquery
Возвращает запрос, который ищет соответствие первому данному запросу, за которым следует
соответствие второму данному запросу (число лексем между ними задаётся параметром рас-
стояние), с применением оператора <N> типа tsquery. Например:
SELECT tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10);
tsquery_phrase
------------------
'fat' &lt;10&gt; 'cat'
383Полнотекстовый поиск
numnode(запрос tsquery) returns integer
Возвращает число узлов (лексем и операторов) в значении tsquery. Эта функция помогает
определить, имеет ли смысл запрос (тогда её результат &gt; 0) или он содержит только стоп-слова
(тогда она возвращает 0). Примеры:
SELECT numnode(plainto_tsquery('the any'));
ЗАМЕЧАНИЕ: запрос поиска текста игнорируется, так как содержит
только стоп-слова или не содержит лексем
numnode
---------
0
SELECT numnode('foo &amp; bar'::tsquery);
numnode
---------
3
querytree(запрос tsquery) returns text
Возвращает часть tsquery, которую можно использовать для поиска по индексу. Эта функция
помогает выявить неиндексируемые запросы, например, такие, которые содержат только стоп-
слова или условия отрицания. Например:
SELECT querytree(to_tsquery('!defined'));
querytree
-----------
12.4.2.1. Перезапись запросов
Семейство запросов ts_rewrite ищет в данном tsquery вхождения целевого подзапроса и заменя-
ет каждое вхождение указанной подстановкой. По сути эта операция похожа на замену подстроки
в строке, только рассчитана на работу с tsquery. Сочетание целевого подзапроса с подстановкой
можно считать правилом перезаписи запроса. Набор таких правил перезаписи может быть очень
полезен при поиске. Например, вы можете улучшить результаты, добавив синонимы (например,
big apple, nyc и gotham для new york) или сузить область поиска, чтобы нацелить пользователя на
некоторую область. Это в некотором смысле пересекается с функциональностью тезаурусов (Под-
раздел  12.6.4). Однако, при таком подходе вы можете изменять правила перезаписи «на лету»,
тогда как при обновлении тезауруса необходима переиндексация.
ts_rewrite (запрос tsquery, цель tsquery, замена tsquery) returns tsquery
Эта форма ts_rewrite просто применяет одно правило перезаписи: цель заменяется подста-
новкой везде, где она находится в запросе. Например:
SELECT ts_rewrite('a &amp; b'::tsquery, 'a'::tsquery, 'c'::tsquery);
ts_rewrite
------------
'b' &amp; 'c'
ts_rewrite (запрос tsquery, выборка text) returns tsquery
Эта форма ts_rewrite принимает начальный запрос и SQL-команду select, которая задаётся
текстовой строкой. Команда select должна выдавать два столбца типа tsquery. Для каждой
строки результата select вхождения первого столбца (цели) заменяются значениями второго
столбца (подстановкой) в тексте запроса. Например:
CREATE TABLE aliases (t tsquery PRIMARY KEY, s tsquery);
INSERT INTO aliases VALUES('a', 'c');
SELECT ts_rewrite('a &amp; b'::tsquery, 'SELECT t,s FROM aliases');
ts_rewrite
384Полнотекстовый поиск
------------
'b' &amp; 'c'
Заметьте, что когда таким способом применяются несколько правил перезаписи, порядок их
применения может иметь значение, поэтому в исходном запросе следует добавить ORDER BY
по какому-либо ключу.
Давайте рассмотрим практический пример на тему астрономии. Мы развернём запрос supernovae,
используя правила перезаписи в таблице:
CREATE TABLE aliases (t tsquery primary key, s tsquery);
INSERT INTO aliases VALUES(to_tsquery('supernovae'),
to_tsquery('supernovae|sn'));
SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
ts_rewrite
---------------------------------
'crab' &amp; ( 'supernova' | 'sn' )
Мы можем скорректировать правила перезаписи, просто изменив таблицу:
UPDATE aliases
SET s = to_tsquery('supernovae|sn &amp; !nebulae')
WHERE t = to_tsquery('supernovae');
SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
ts_rewrite
---------------------------------------------
'crab' &amp; ( 'supernova' | 'sn' &amp; !'nebula' )
Перезапись может быть медленной, когда задано много правил перезаписи, так как соответствия
будут проверяться для каждого правила. Чтобы отфильтровать явно неподходящие правила, можно
использовать проверки включения для типа tsquery. В следующем примере выбираются только те
правила, которые могут соответствовать исходному запросу:
SELECT ts_rewrite('a &amp; b'::tsquery,
'SELECT t,s FROM aliases WHERE ''a &amp; b''::tsquery @&gt; t');
ts_rewrite
------------
'b' &amp; 'c'
12.4.3. Триггеры для автоматического обновления
Когда представление документа в формате tsvector хранится в отдельном столбце, необходимо
создать триггер, который будет обновлять его содержимое при изменении столбцов, из которых со-
ставляется исходный документ. Для этого можно использовать две встроенные триггерные функ-
ции или написать свои собственные.
tsvector_update_trigger(столбец_tsvector, имя_конфигурации, столбец_текста [, ...])
tsvector_update_trigger_column(столбец_tsvector, столбец_конфигурации,
столбец_текста [, ...])
Эти триггерные функции автоматически вычисляют значение для столбца tsvector из одного или
нескольких текстовых столбцов с параметрами, указанными в команде CREATE TRIGGER. Пример
их использования:
CREATE TABLE messages (
title
text,
body
text,
tsv
tsvector
);
385Полнотекстовый поиск
CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE FUNCTION
tsvector_update_trigger(tsv, 'pg_catalog.english', title, body);
INSERT INTO messages VALUES('title here', 'the body text is here');
SELECT * FROM messages;
title
|
body
|
tsv
------------+-----------------------+----------------------------
title here | the body text is here | 'bodi':4 'text':5 'titl':1
SELECT title, body FROM messages WHERE tsv @@ to_tsquery('title &amp; body');
title
|
body
------------+-----------------------
title here | the body text is here
С таким триггером любое изменение в полях title или body будет автоматически отражаться в
содержимом tsv, так что приложению не придётся заниматься этим.
Первым аргументом этих функций должно быть имя столбца tsvector, содержимое которого будет
обновляться. Ещё один аргумент — конфигурация текстового поиска, которая будет использовать-
ся для преобразования. Для tsvector_update_trigger имя конфигурации передаётся просто как
второй аргумент триггера. Это имя должно быть определено полностью, чтобы поведение триггера
не менялось при изменениях в пути поиска (search_path). Для tsvector_update_trigger_column
во втором аргументе триггера передаётся имя другого столбца таблицы, который должен иметь
тип regconfig. Это позволяет использовать разные конфигурации для разных строк. В оставшихся
аргументах передаются имена текстовых столбцов (типа text, varchar или char). Их содержимое
будет включено в документ в заданном порядке. При этом значения NULL будут пропущены (а
другие столбцы будут индексироваться).
Ограничение этих встроенных триггеров заключается в том, что они обрабатывают все столбцы
одинаково. Чтобы столбцы обрабатывались по-разному, например для текста заголовка задавался
не тот же вес, что для тела документа, потребуется разработать свой триггер. К примеру, так это
можно сделать на языке PL/pgSQL:
CREATE FUNCTION messages_trigger() RETURNS trigger AS $$
begin
new.tsv :=
setweight(to_tsvector('pg_catalog.english', coalesce(new.title,'')), 'A') ||
setweight(to_tsvector('pg_catalog.english', coalesce(new.body,'')), 'D');
return new;
end
$$ LANGUAGE plpgsql;
CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE FUNCTION messages_trigger();
Помните, что, создавая значения tsvector в триггерах, важно явно указывать имя конфигурации,
чтобы содержимое столбца не зависело от изменений default_text_search_config. В противном
случае могут возникнуть проблемы, например результаты поиска изменятся после выгрузки и вос-
становления данных.
12.4.4. Сбор статистики по документу
Функция ts_stat может быть полезна для проверки конфигурации и нахождения возможных стоп-
слов.
ts_stat(sql_запрос text, [веса text,]
OUT слово text, OUT число_док integer,
OUT число_вхожд integer) returns setof record
386Полнотекстовый поиск
Здесь sql_запрос — текстовая строка, содержащая SQL-запрос, который должен возвращать один
столбец tsvector. Функция ts_stat выполняет запрос и возвращает статистику по каждой отдель-
ной лексеме (слову), содержащейся в данных tsvector. Её результат представляется в столбцах
• слово text — значение лексемы
• число_док integer — число документов (значений tsvector), в которых встретилось слово
• число_вхожд integer — общее число вхождений слова
Если передаётся параметр weights, то подсчитываются только вхождения с указанными в нём
весами.
Например, найти десять наиболее часто используемых слов в коллекции документов можно так:
SELECT * FROM ts_stat('SELECT vector FROM apod')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
Следующий запрос возвращает тоже десять слов, но при выборе их учитываются только вхождения
с весами A или B:
SELECT * FROM ts_stat('SELECT vector FROM apod', 'ab')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
12.5. Анализаторы
Задача анализаторов текста — разделить текст документа на фрагменты и присвоить каждому
из них тип из набора, определённого в самом анализаторе. Заметьте, что анализаторы не меняют
текст — они просто выдают позиции предполагаемых слов. Вследствие такой ограниченности их
функций, собственные специфические анализаторы бывают нужны гораздо реже, чем собственные
словари. В настоящее время в PostgreSQL есть только один встроенный анализатор, который может
быть полезен для широкого круга приложений.
Этот встроенный анализатор называется pg_catalog.default. Он распознаёт 23 типа фрагментов,
перечисленные в Таблице 12.1.
Таблица 12.1. Типы фрагментов, выделяемых стандартным анализатором
Псевдоним Описание
Пример
asciiword Слово только из букв ASCII
elephant
word Слово из любых букв
mañana
numword Слово из букв и цифр
beta1
asciihword Слово только из букв ASCII с де- up-to-date
фисами
hword Слово из любых букв с дефиса- lógico-matemática
ми
numhword Слово из букв и цифр с дефиса- postgresql-beta1
ми
hword_asciipart Часть слова с дефисами, только postgresql в словосочетании
из букв ASCII
postgresql-beta1
hword_part Часть слова с дефисами, из лю- lógico или matemática в слово-
бых букв
сочетании lógico-matemática
hword_numpart Часть слова с дефисами, из букв beta1
в
словосочетании
и цифр
postgresql-beta1
email Адрес электронной почты
foo@example.com
protocol Префикс протокола
http://
387Полнотекстовый поиск
Псевдоним Описание Пример
url URL example.com/stuff/
index.html
host Имя узла example.com
url_path Путь в адресе URL /stuff/index.html, как часть
URL
file Путь или имя файла /usr/local/foo.txt, если не яв-
ляется частью URL
sfloat Научная запись числа -1.234e56
float Десятичная запись числа -1.234
int Целое со знаком -1234
uint Целое без знака 1234
version Номер версии 8.3.0
tag Тег XML &lt;a
"dictionaries.html"&gt;
entity Сущность XML &amp;
blank Символы-разделители (любые пробельные символы
или знаки препинания, не по-
павшие в другие категории)
href=
Примечание
Понятие «буквы» анализатор определяет исходя из локали, заданной для базы данных,
в частности параметра lc_ctype. Слова, содержащие только буквы из ASCII (латинские
буквы), распознаются как фрагменты отдельного типа, так как иногда бывает полезно
выделить их. Для многих европейских языков типы фрагментов word и asciiword мож-
но воспринимать как синонимы.
email принимает не все символы, которые считаются допустимыми по стандарту RFC
5322. В частности, имя почтового ящика помимо алфавитно-цифровых символов может
содержать только точку, минус и подчёркивание.
Анализатор может выделить в одном тексте несколько перекрывающихся фрагментов. Например,
слово с дефисом будет выдано как целое составное слово и по частям:
SELECT alias, description, token FROM ts_debug('foo-bar-beta1');
alias
|
description
|
token
-----------------+------------------------------------------+--------------
numhword
| Hyphenated word, letters and digits
| foo-bar-beta1
hword_asciipart | Hyphenated word part, all ASCII
| foo
blank
| Space symbols
| -
hword_asciipart | Hyphenated word part, all ASCII
| bar
blank
| Space symbols
| -
hword_numpart
| Hyphenated word part, letters and digits | beta1
Это поведение считается желательным, так как это позволяет находить при последующем поиске
и всё слово целиком, и его части. Ещё один показательный пример:
SELECT alias, description, token
FROM ts_debug('http://example.com/stuff/index.html');
alias
| description |
token
----------+---------------+------------------------------
protocol | Protocol head | http://
388Полнотекстовый поиск
url
| URL
host
| Host
url_path | URL path
| example.com/stuff/index.html
| example.com
| /stuff/index.html
12.6. Словари
Словари полнотекстового поиска предназначены для исключения стоп-слов (слов, которые не
должны учитываться при поиске) и нормализации слов, чтобы разные словоформы считались сов-
падающими. Успешно нормализованное слово называется лексемой. Нормализация и исключение
стоп-слов не только улучшает качество поиска, но и уменьшает размер представления документа в
формате tsvector, и, как следствие, увеличивает быстродействие. Нормализация не всегда имеет
лингвистический смысл, обычно она зависит от требований приложения.
Несколько примеров нормализации:
• Лингвистическая нормализация — словари Ispell пытаются свести слова на входе к нормали-
зованной форме, а стеммеры убирают окончания слов
• Адреса URL могут быть канонизированы, чтобы например следующие адреса считались оди-
наковыми:
• http://www.pgsql.ru/db/mw/index.html
• http://www.pgsql.ru/db/mw/
• http://www.pgsql.ru/db/../db/mw/index.html
• Названия цветов могут быть заменены их шестнадцатеричными значениями, например red,
green, blue, magenta -&gt; FF0000, 00FF00, 0000FF, FF00FF
• При индексировании чисел можно отбросить цифры в дробной части для сокращения множе-
ства всевозможных чисел, чтобы например 3.14159265359, 3.1415926 и 3.14 стали одинаковы-
ми после нормализации, при которой после точки останутся только две цифры.
Словарь — это программа, которая принимает на вход фрагмент и возвращает:
• массив лексем, если входной фрагмент известен в словаре (заметьте, один фрагмент может
породить несколько лексем)
• одну лексему с установленным флагом TSL_FILTER для замены исходного фрагмента новым,
чтобы следующие словари работали с новым вариантом (словарь, который делает это, называ-
ется фильтрующим словарём)
• пустой массив, если словарь воспринимает этот фрагмент, но считает его стоп-словом
• NULL, если словарь не воспринимает полученный фрагмент
В PostgreSQL встроены стандартные словари для многих языков. Есть также несколько предопре-
делённых шаблонов, на основании которых можно создавать новые словари с изменёнными пара-
метрами. Все эти шаблоны описаны ниже. Если же ни один из них не подходит, можно создать и
свои собственные шаблоны. Соответствующие примеры можно найти в каталоге contrib/ инстал-
ляции PostgreSQL.
Конфигурация текстового поиска связывает анализатор с набором словарей, которые будут обра-
батывать выделенные им фрагменты. Для каждого типа фрагментов, выданных анализатором, в
конфигурации задаётся отдельный список словарей. Найденный анализатором фрагмент проходит
через все словари по порядку, пока какой-либо словарь не увидит в нём знакомое для него слово.
Если он окажется стоп-словом или его не распознает ни один словарь, этот фрагмент не будет
учитываться при индексации и поиске. Обычно результат определяет первый же словарь, который
возвращает не NULL, и остальные словари уже не проверяются; однако фильтрующий словарь мо-
жет заменить полученное слово другим, которое и будет передано следующим словарям.
Общее правило настройки списка словарей заключается в том, чтобы поставить наиболее частные
и специфические словари в начале, затем перечислить более общие и закончить самым общим
словарём, например стеммером Snowball или словарём simple, который распознаёт всё. Напри-
мер, для поиска по теме астрономии (конфигурация astro_en) тип фрагментов asciiword (слово из
букв ASCII) можно связать со словарём синонимов астрономических терминов, затем с обычным
английским словарём и наконец со стеммером английских окончаний Snowball:
389Полнотекстовый поиск
ALTER TEXT SEARCH CONFIGURATION astro_en
ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
Фильтрующий словарь можно включить в любом месте списка, кроме конца, где он будет бесполе-
зен. Фильтрующие словари бывают полезны для частичной нормализации слов и упрощения зада-
чи следующих словарей. Например, фильтрующий словарь может удалить из текста диакритиче-
ские знаки, как это делает модуль unaccent.
12.6.1. Стоп-слова
Стоп-словами называются слова, которые встречаются очень часто, практически в каждом доку-
менте, и поэтому не имеют различительной ценности. Таким образом, при полнотекстовом поиске
их можно игнорировать. Например, в каждом английском тексте содержатся артикли a и the, так
что хранить их в индексе бессмысленно. Однако стоп-слова влияют на позиции лексем в значении
tsvector, от чего, в свою очередь, зависит ранжирование:
SELECT to_tsvector('english','in the list of stop words');
to_tsvector
----------------------------
'list':3 'stop':5 'word':6
В результате отсутствуют позиции 1,2,4, потому что фрагменты в этих позициях оказались стоп-
словами. Ранги, вычисленные для документов со стоп-словами и без них, могут значительно раз-
личаться:
SELECT ts_rank_cd (to_tsvector('english','in the list of stop words'),
to_tsquery('list &amp; stop'));
ts_rank_cd
------------
0.05
SELECT ts_rank_cd (to_tsvector('english','list stop words'),
to_tsquery('list &amp; stop'));
ts_rank_cd
------------
0.1
Как именно обрабатывать стоп-слова, определяет сам словарь. Например, словари ispell снача-
ла нормализуют слова, а затем просматривают список стоп-слов, тогда как стеммеры Snowball
просматривают свой список стоп-слов в первую очередь. Это различие в поведении объясняется
стремлением уменьшить шум.
12.6.2. Простой словарь
Работа шаблона словарей simple сводится к преобразованию входного фрагмента в нижний ре-
гистр и проверки результата по файлу со списком стоп-слов. Если это слово находится в файле,
словарь возвращает пустой массив и фрагмент исключается из дальнейшего рассмотрения. В про-
тивном случае словарь возвращает в качестве нормализованной лексемы слово в нижнем регистре.
Этот словарь можно настроить и так, чтобы все слова, кроме стоп-слов, считались неопознанными
и передавались следующему словарю в списке.
Определить словарь на основе шаблона simple можно так:
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
TEMPLATE = pg_catalog.simple,
STOPWORDS = english
);
Здесь english — базовое имя файла со стоп-словами. Полным именем файла будет $SHAREDIR/
tsearch_data/english.stop, где $SHAREDIR указывает на каталог с общими данными PostgreSQL,
часто это /usr/local/share/postgresql (точно узнать его можно с помощью команды pg_config
390Полнотекстовый поиск
--sharedir). Этот текстовый файл должен содержать просто список слов, по одному слову в строке.
Пустые строки и окружающие пробелы игнорируются, все символы переводятся в нижний регистр
и на этом обработка файла заканчивается.
Теперь мы можем проверить наш словарь:
SELECT ts_lexize('public.simple_dict','YeS');
ts_lexize
-----------
{yes}
SELECT ts_lexize('public.simple_dict','The');
ts_lexize
-----------
{}
Мы также можем настроить словарь так, чтобы он возвращал NULL вместо слова в нижнем реги-
стре, если оно не находится в файле стоп-слов. Для этого нужно присвоить параметру Accept зна-
чение false. Продолжая наш пример:
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );
SELECT ts_lexize('public.simple_dict','YeS');
ts_lexize
-----------
SELECT ts_lexize('public.simple_dict','The');
ts_lexize
-----------
{}
Со значением Accept = true (по умолчанию) словарь simple имеет смысл включать только в конце
списка словарей, так как он никогда не передаст фрагмент следующему словарю. И напротив,
Accept = false имеет смысл, только если за ним следует ещё минимум один словарь.
Внимание
Большинство словарей работают с дополнительными файлами, например, файлами
стоп-слов. Содержимое этих файлов должно иметь кодировку UTF-8. Если база данных
работает в другой кодировке, они будут переведены в неё, когда сервер будет загру-
жать их.
Внимание
Обычно в рамках одного сеанса дополнительный файл словаря загружается только
один раз, при первом использовании. Если же вы измените его и захотите, чтобы суще-
ствующие сеансы работали с новым содержимым, выполните для этого словаря коман-
ду ALTER TEXT SEARCH DICTIONARY. Это обновление словаря может быть «фиктивным»,
фактически не меняющим значения никаких параметров.
12.6.3. Словарь синонимов
Этот шаблон словарей используется для создания словарей, заменяющих слова синонимами. Сло-
восочетания такие словари не поддерживают (используйте для этого тезаурус (Подраздел 12.6.4)).
Словарь синонимов может помочь в преодолении лингвистических проблем, например, не дать
391Полнотекстовый поиск
стеммеру английского уменьшить слово «Paris» до «pari». Для этого достаточно поместить в сло-
варь синонимов строку Paris paris и поставить этот словарь перед словарём english_stem. На-
пример:
SELECT * FROM ts_debug('english', 'Paris');
alias |
description | token| dictionaries | dictionary | lexemes
----------+----------------+------+---------------+-------------+--------
asciiword| Word, all ASCII| Paris| {english_stem}| english_stem| {pari}
CREATE TEXT SEARCH DICTIONARY my_synonym (
TEMPLATE = synonym,
SYNONYMS = my_synonyms
);
ALTER TEXT SEARCH CONFIGURATION english
ALTER MAPPING FOR asciiword
WITH my_synonym, english_stem;
SELECT * FROM ts_debug('english', 'Paris');
alias |
description | token| dictionaries | dictionary| lexemes
----------+----------------+------+--------------+-----------+--------
asciiword| Word, all ASCII| Paris| {my_synonym, | my_synonym| {paris}
|
|
| english_stem}|
|
Шаблон synonym принимает единственный параметр, SYNONYMS, в котором задаётся базовое имя
его файла конфигурации — в данном примере это my_synonyms. Полным именем файла будет
$SHAREDIR/tsearch_data/my_synonyms.syn (где $SHAREDIR указывает на каталог общих данных
PostgreSQL). Содержимое этого файла должны составлять строки с двумя словами в каждой (пер-
вое — заменяемое слово, а второе — его синоним), разделёнными пробелами. Пустые строки и
окружающие пробелы при разборе этого файла игнорируются.
Шаблон synonym также принимает необязательный параметр CaseSensitive, который по умолча-
нию имеет значение false. Когда CaseSensitive равен false, слова в файле синонимов перево-
дятся в нижний регистр, вместе с проверяемыми фрагментами. Если же он не равен true, регистр
слов в файле и проверяемых фрагментов не меняются, они сравниваются «как есть».
В конце синонима в этом файле можно добавить звёздочку (*), тогда этот синоним будет рассмат-
риваться как префикс. Эта звёздочка будет игнорироваться в to_tsvector(), но to_tsquery() из-
менит результат, добавив в него маркер сопоставления префикса (см. Подраздел 12.3.2). Напри-
мер, предположим, что файл $SHAREDIR/tsearch_data/synonym_sample.syn имеет следующее со-
держание:
postgres
postgresql
postgre pgsql
gogle
googl
indices index*
pgsql
pgsql
С ним мы получим такие результаты:
mydb=# CREATE TEXT SEARCH DICTIONARY
syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn','indices');
ts_lexize
-----------
{index}
(1 row)
mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword
392Полнотекстовый поиск
WITH syn;
mydb=# SELECT to_tsvector('tst','indices');
to_tsvector
-------------
'index':1
(1 row)
mydb=# SELECT to_tsquery('tst','indices');
to_tsquery
------------
'index':*
(1 row)
mydb=# SELECT 'indexes are very useful'::tsvector;
tsvector
---------------------------------
'are' 'indexes' 'useful' 'very'
(1 row)
mydb=# SELECT 'indexes are very useful'::tsvector @@
to_tsquery('tst','indices');
?column?
----------
t
(1 row)
12.6.4. Тезаурус
Тезаурус (или сокращённо TZ) содержит набор слов и информацию о связях слов и словосочета-
ний, то есть более широкие понятия (Broader Terms, BT), более узкие понятия (Narrow Terms, NT),
предпочитаемые названия, исключаемые названия, связанные понятия и т. д.
В основном тезаурус заменяет исключаемые слова и словосочетания предпочитаемыми и может
также сохранить исходные слова для индексации. Текущая реализация тезауруса в PostgreSQL
представляет собой расширение словаря синонимов с поддержкой фраз. Конфигурация тезауруса
определяется файлом следующего формата:
# это комментарий
образец слов(а) : индексируемые слова
другой образец слов(а) : другие индексируемые слова
...
Здесь двоеточие (:) служит разделителем между исходной фразой и её заменой.
Прежде чем проверять соответствие фраз, тезаурус нормализует файл конфигурации, используя
внутренний словарь (который указывается в конфигурации словаря-тезауруса). Этот внутренний
словарь для тезауруса может быть только одним. Если он не сможет распознать какое-либо слово,
произойдёт ошибка. В этом случае необходимо либо исключить это слово, либо добавить его во
внутренний словарь. Также можно добавить звёздочку (*) перед индексируемыми словами, чтобы
они не проверялись по внутреннему словарю, но все слова-образцы должны быть известны внут-
реннему словарю.
Если входному фрагменту соответствуют несколько фраз в этом списке, тезаурус выберет самое
длинное определение, а если таких окажется несколько, самое последнее из них.
Выделить во фразе какие-то стоп-слова нельзя; вместо этого можно вставить ? в том месте, где
может оказаться стоп-слово. Например, в предположении, что a и the — стоп-слова по внутреннему
словарю:
? one ? two : swsw
393Полнотекстовый поиск
соответствует входным строкам a one the two и the one a two, так что обе эти строки будут
заменены на swsw.
Как и обычный словарь, тезаурус должен привязываться к лексемам определённых типов. Так как
тезаурус может распознавать фразы, он должен запоминать своё состояние и взаимодействовать с
анализатором. Учитывая свои привязки, он может либо обрабатывать следующий фрагмент, либо
прекратить накопление фразы. Поэтому настройка тезаурусов в системе требует особого внима-
ния. Например, если привязать тезаурус только к типу фрагментов asciiword, тогда определение
в тезаурусе one 7 не будет работать, так как этот тезаурус не связан с типом uint.
Внимание
Тезаурусы используются при индексации, поэтому при любом изменении параметров
или содержимого тезауруса необходима переиндексация. Для большинства других ти-
пов словарей при небольших изменениях, таких как удаление и добавление стоп-слов,
переиндексация не требуется.
12.6.4.1. Конфигурация тезауруса
Для создания нового словаря-тезауруса используется шаблон thesaurus. Например:
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
TEMPLATE = thesaurus,
DictFile = mythesaurus,
Dictionary = pg_catalog.english_stem
);
Здесь:
• thesaurus_simple — имя нового словаря
• mythesaurus — базовое имя файла конфигурации тезауруса. (Полным путём к файлу будет
$SHAREDIR/tsearch_data/mythesaurus.ths, где $SHAREDIR указывает на каталог общих данных
PostgreSQL.)
• pg_catalog.english_stem — внутренний словарь (в данном случае, это стеммер Snowball для
английского) для нормализации тезауруса. Заметьте, что внутренний словарь имеет собствен-
ную конфигурацию (например, список стоп-слов), но здесь она не рассматривается.
Теперь тезаурус thesaurus_simple можно связать с желаемыми типами фрагментов в конфигура-
ции, например так:
ALTER TEXT SEARCH CONFIGURATION english
ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
WITH thesaurus_simple;
12.6.4.2. Пример тезауруса
Давайте рассмотрим простой астрономический тезаурус thesaurus_astro, содержащий несколько
астрономических терминов:
supernovae stars : sn
crab nebulae : crab
Ниже мы создадим словарь и привяжем некоторые типы фрагментов к астрономическому тезау-
русу и английскому стеммеру:
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
TEMPLATE = thesaurus,
DictFile = thesaurus_astro,
Dictionary = english_stem
);
ALTER TEXT SEARCH CONFIGURATION russian
394Полнотекстовый поиск
ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
WITH thesaurus_astro, english_stem;
Теперь можно проверить, как он работает. Функция ts_lexize не очень полезна для проверки теза-
уруса, так как она обрабатывает входную строку как один фрагмент. Вместо неё мы можем исполь-
зовать функции plainto_tsquery и to_tsvector, которые разбивают входную строку на несколько
фрагментов:
SELECT plainto_tsquery('supernova star');
plainto_tsquery
-----------------
'sn'
SELECT to_tsvector('supernova star');
to_tsvector
-------------
'sn':1
В принципе так же можно использовать to_tsquery, если заключить аргумент в кавычки:
SELECT to_tsquery(' ''supernova star''');
to_tsquery
------------
'sn'
Заметьте, что supernova star совпадает с supernovae stars в thesaurus_astro, так как мы под-
ключили стеммер english_stem в определении тезауруса. Этот стеммер удалил конечные буквы
e и s.
Чтобы проиндексировать исходную фразу вместе с заменой, её нужно просто добавить в правую
часть соответствующего определения:
supernovae stars : sn supernovae stars
SELECT plainto_tsquery('supernova star');
plainto_tsquery
-----------------------------
'sn' &amp; 'supernova' &amp; 'star'
12.6.5. Словарь Ispell
Шаблон словарей Ispell поддерживает морфологические словари, которые могут сводить множе-
ство разных лингвистических форм слова к одной лексеме. Например, английский словарь Ispell
может связать вместе все склонения и спряжения ключевого слова bank: banking, banked, banks,
banks',bank's и т. п.
Стандартный дистрибутив PostgreSQL не включает файлы конфигурации Ispell. Загрузить словари
для множества языков можно со страницы Ispell. Кроме того, поддерживаются и другие современ-
ные форматы словарей: MySpell (OO &lt; 2.0.1) и Hunspell (OO &gt;= 2.0.2). Большой набор соответству-
ющих словарей можно найти на странице OpenOffice Wiki.
Чтобы создать словарь Ispell, выполните следующие действия:
• загрузите файлы конфигурации словаря. Пакет с дополнительным словарём OpenOffice имеет
расширение .oxt. Из него необходимо извлечь файлы .aff и .dic, и сменить их расширения
на .affix и .dict, соответственно. Для некоторых файлов словарей также необходимо преоб-
разовать символы в кодировку UTF-8 с помощью, например, таких команд (для норвежского
языка):
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
• скопируйте файлы в каталог $SHAREDIR/tsearch_data
395Полнотекстовый поиск
• загрузите эти файлы в PostgreSQL следующей командой:
CREATE TEXT SEARCH DICTIONARY english_hunspell (
TEMPLATE = ispell,
DictFile = en_us,
AffFile = en_us,
Stopwords = english);
Здесь параметры DictFile, AffFile и StopWords определяют базовые имена файлов словаря, аф-
фиксов и стоп-слов. Файл стоп-слов должен иметь тот же формат, что рассматривался выше в опи-
сании словаря simple. Формат других файлов здесь не рассматривается, но его можно узнать по
вышеуказанным веб-адресам.
Словари Ispell обычно воспринимают ограниченный набор слов, так что за ними следует подклю-
чить другой, более общий словарь, например, Snowball, который принимает всё.
Файл .affix для Ispell имеет такую структуру:
prefixes
flag *A:
.
suffixes
flag T:
E
[^AEIOU]Y
[AEIOU]Y
[^EY]
&gt; RE # As in enter &gt; reenter
&gt;
&gt;
&gt;
&gt; ST
-Y,IEST
EST
EST #
#
#
#
As
As
As
As
in
in
in
in
late &gt; latest
dirty &gt; dirtiest
gray &gt; grayest
small &gt; smallest
А файл .dict — такую:
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
Формат файла .dict следующий:
basic_form/affix_class_name
В файле .affix каждый флаг аффиксов описывается в следующем формате:
условие &gt; [-отсекаемые_буквы,] добавляемый_аффикс
Здесь условие записывается в формате, подобном формату регулярных выражений. В нём возмож-
но описать группы [...] и [^...]. Например, запись [AEIOU]Y означает, что последняя буква сло-
ва — "y", а предпоследней может быть "a", "e", "i", "o" или "u". Запись [^EY] означает, что по-
следняя буква не "e" и не "y".
Словари Ispell поддерживают разделение составных слов, что бывает полезно. Заметьте, что для
этого в файле аффиксов нужно пометить специальным оператором compoundwords controlled сло-
ва, которые могут участвовать в составных образованиях:
compoundwords
controlled z
Вот как это работает для норвежского языка:
SELECT ts_lexize('norwegian_ispell',
'overbuljongterningpakkmesterassistent');
{over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
{sjokoladefabrikk,sjokolade,fabrikk}
Формат MySpell представляет собой подмножество формата Hunspell. Файл .affix словаря
Hunspell имеет следующую структуру:
396Полнотекстовый поиск
PFX
PFX
SFX
SFX
SFX
SFX
SFX
A Y 1
A
0
T N 4
T
0
T
y
T
0
T
0
re .
st
iest
est
est e
[^aeiou]y
[aeiou]y
[^ey]
Первая строка класса аффиксов — заголовок. Поля правил аффиксов указываются после заголов-
ка:
•
•
•
•
•
имя параметра (PFX или SFX)
флаг (имя класса аффиксов)
отсекаемые символы в начале (в префиксе) или в конце (в суффиксе) слова
добавляемый аффикс
условие в формате, подобном регулярным выражениям.
Файл .dict подобен файлу .dict словаря Ispell:
larder/M
lardy/RT
large/RSPMYT
largehearted
Примечание
Словарь MySpell не поддерживает составные слова. С другой стороны, Hunspell под-
держивает множество операции с ними, но в настоящее время PostgreSQL использует
только самые простые из этого множества.
12.6.6. Словарь Snowball
Шаблон словарей Snowball основан на проекте Мартина Потера, изобретателя популярного алго-
ритма стемминга для английского языка. Сейчас Snowball предлагает алгоритмы и для многих
других языков (за подробностями обратитесь на сайт Snowball). Каждый алгоритм знает, как для
данного языка свести распространённые словоформы к начальной форме. Для словаря Snowball
задаётся обязательный параметр language, определяющий, какой именно стеммер использовать,
и может задаваться параметр stopword, указывающий файл со списком исключаемых слов. (Стан-
дартные списки стоп-слов PostgreSQL используется также в и проекте Snowball.) Например, встро-
енное определение выглядит так
CREATE TEXT SEARCH DICTIONARY english_stem (
TEMPLATE = snowball,
Language = english,
StopWords = english
);
Формат файла стоп-слов не отличается от рассмотренного ранее.
Словарь Snowball распознаёт любые фрагменты, даже если он не может упростить слова, так что
он должен быть самым последним в списке словарей. Помещать его перед другими словарями нет
смысла, так как после него никакой фрагмент не будет передан следующему словарю.
12.7. Пример конфигурации
Конфигурация текстового поиска определяет всё, что необходимо для преобразования документа
в формат tsvector: анализатор, который будет разбивать текст на фрагменты, и словари, которые
будут преобразовывать фрагменты в лексемы. При каждом вызове to_tsvector или to_tsquery
обязательно используется конфигурация текстового поиска. В конфигурации сервера есть пара-
397Полнотекстовый поиск
метр default_text_search_config, задающий имя конфигурации текстового поиска по умолчанию,
которая будет использоваться, когда при вызове функций поиска соответствующий аргумент не
определён. Этот параметр можно задать в postgresql.conf или установить в рамках отдельного
сеанса с помощью команды SET.
В системе есть несколько встроенных конфигураций текстового поиска и вы можете легко допол-
нить их своими. Для удобства управления объектами текстового поиска в PostgreSQL реализованы
соответствующие SQL-команды и специальные команды в psql, выводящие информацию об этих
объектах (Раздел 12.10).
В качестве примера использования этих команд мы создадим конфигурацию pg, взяв за основу
встроенную конфигурацию english:
CREATE TEXT SEARCH CONFIGURATION public.pg ( COPY = pg_catalog.english );
Мы будем использовать список синонимов, связанных с PostgreSQL, в файле $SHAREDIR/
tsearch_data/pg_dict.syn. Этот файл содержит строки:
postgres
pgsql
postgresql
pg
pg
pg
Мы определим словарь синонимов следующим образом:
CREATE TEXT SEARCH DICTIONARY pg_dict (
TEMPLATE = synonym,
SYNONYMS = pg_dict
);
Затем мы зарегистрируем словарь Ispell english_ispell, у которого есть собственные файлы кон-
фигурации:
CREATE TEXT SEARCH DICTIONARY english_ispell (
TEMPLATE = ispell,
DictFile = english,
AffFile = english,
StopWords = english
);
Теперь мы можем настроить сопоставления для слов в конфигурации pg:
ALTER TEXT SEARCH CONFIGURATION pg
ALTER MAPPING FOR asciiword, asciihword, hword_asciipart,
word, hword, hword_part
WITH pg_dict, english_ispell, english_stem;
Мы решили не индексировать и не учитывать при поиске некоторые типы фрагментов, которые не
обрабатываются встроенной конфигурацией:
ALTER TEXT SEARCH CONFIGURATION pg
DROP MAPPING FOR email, url, url_path, sfloat, float;
Теперь мы можем протестировать нашу конфигурацию:
SELECT * FROM ts_debug('public.pg', '
PostgreSQL, the highly scalable, SQL compliant, open source
object-relational database management system, is now undergoing
beta testing of the next version of our software.
');
И наконец мы выбираем в текущем сеансе эту конфигурацию, созданную в схеме public:
=&gt; \dF
List of text search configurations
398Полнотекстовый поиск
Schema | Name | Description
---------+------+-------------
public | pg
|
SET default_text_search_config = 'public.pg';
SET
SHOW default_text_search_config;
default_text_search_config
----------------------------
public.pg
12.8. Тестирование и отладка текстового поиска
Поведение нестандартной конфигурации текстового поиска по мере её усложнения может стать
непонятным. В этом разделе описаны функции, полезные для тестирования объектов текстового
поиска. Вы можете тестировать конфигурацию как целиком, так и по частям, отлаживая анализа-
торы и словари по отдельности.
12.8.1. Тестирование конфигурации
Созданную конфигурацию текстового поиска можно легко протестировать с помощью функции
ts_debug.
ts_debug([конфигурация regconfig,] документ text,
OUT псевдоним text,
OUT описание text,
OUT фрагмент text,
OUT словари regdictionary[],
OUT словарь regdictionary,
OUT лексемы text[])
returns setof record
ts_debug выводит информацию обо всех фрагментах данного документа, которые были выданы
анализатором и обработаны настроенными словарями. Она использует конфигурацию, указанную
в аргументе config, или default_text_search_config, если этот аргумент опущен.
ts_debug возвращает по одной строке для каждого фрагмента, найденного в тексте анализатором.
Эта строка содержит следующие столбцы:
•
•
•
•
синоним text — краткое имя типа фрагмента
описание text — описание типа фрагмента
фрагмент text — текст фрагмента
словари regdictionary[] — словари, назначенные в конфигурации для фрагментов такого ти-
па
• словарь regdictionary — словарь, распознавший этот фрагмент, или NULL, если подходящего
словаря не нашлось
• лексемы text[] — лексемы, выданные словарём, распознавшим фрагмент, или NULL, если под-
ходящий словарь не нашёлся; может быть также пустым массивом ({}), если фрагмент распо-
знан как стоп-слово
Простой пример:
SELECT * FROM ts_debug('english',
'a fat cat sat on a mat - it ate a fat rats');
alias |
description | token| dictionaries | dictionary |lexemes
----------+----------------+------+---------------+-------------+-------
asciiword| Word, all ASCII| a
| {english_stem}| english_stem| {}
blank
| Space symbols |
| {}
|
|
399Полнотекстовый поиск
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
blank
|
asciiword|
Word,
Space
Word,
Space
Word,
Space
Word,
Space
Word,
Space
Word,
Space
Space
Word,
Space
Word,
Space
Word,
Space
Word,
Space
Word,
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
symbols |
all ASCII|
fat
|
|
cat |
|
sat |
|
on
|
|
a
|
|
mat |
|
-
|
it
|
|
ate |
|
a
|
|
fat |
|
rats |
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
{}
|
{english_stem}|
english_stem|
|
english_stem|
|
english_stem|
|
english_stem|
|
english_stem|
|
english_stem|
|
|
english_stem|
|
english_stem|
|
english_stem|
|
english_stem|
|
english_stem|
{fat}
{cat}
{sat}
{}
{}
{mat}
{}
{ate}
{}
{fat}
{rat}
Для более полной демонстрации мы сначала создадим конфигурацию public.english и словарь
Ispell для английского языка:
CREATE TEXT SEARCH CONFIGURATION public.english
( COPY = pg_catalog.english );
CREATE TEXT SEARCH DICTIONARY english_ispell (
TEMPLATE = ispell,
DictFile = english,
AffFile = english,
StopWords = english
);
ALTER TEXT SEARCH CONFIGURATION public.english
ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
SELECT * FROM ts_debug('public.english','The Brightest supernovaes');
alias | description |
token
| dictionaries |dictionary| lexemes
---------+-------------+-----------+----------- ---+----------+-----------
asciiword|Word,
|The
|{english_ispell|english_ |{}
| all ASCII
|
|,english_stem} |ispell
|
blank
|Space symbols|
|{}
|
|
|
|
|
|
|
asciiword|Word,
|Brightest |{english_ispell|english_ |{bright}
|all ASCII
|
|,english_stem} |ispell
|
blank
|Space symbols|
| {}
|
|
|
|
|
|
|
asciiword|Word,
|supernovaes|{english_ispell|english_ |{supernova}
|all ASCII
|
|,english_stem} |stem
|
В этом примере слово Brightest было воспринято анализатором как фрагмент ASCII word
(синоним asciiword). Для этого типа фрагментов список словарей включает english_ispell и
english_stem. Данное слово было распознано словарём english_ispell, который свёл его к bright.
Слово supernovaes оказалось незнакомо словарю english_ispell, так что оно было передано сле-
дующему словарю, который его благополучно распознал (на самом деле english_stem — это стем-
мер Snowball, который распознаёт всё, поэтому он включён в список словарей последним).
400Полнотекстовый поиск
Слово The было распознано словарём english_ispell как стоп-слово (см. Подраздел 12.6.1) и по-
этому не будет индексироваться. Пробелы тоже отбрасываются, так как в данной конфигурации
для них нет словарей.
Вы можете уменьшить ширину вывода, явно перечислив только те столбцы, которые вы хотите
видеть:
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english','The Brightest supernovaes');
alias
|
token
|
dictionary
|
lexemes
-----------+-------------+----------------+-------------
asciiword | The
| english_ispell | {}
blank
|
|
|
asciiword | Brightest
| english_ispell | {bright}
blank
|
|
|
asciiword | supernovaes | english_stem
| {supernova}
12.8.2. Тестирование анализатора
Следующие функции позволяют непосредственно протестировать анализатор текстового поиска.
ts_parse(имя_анализатора text, документ text,
OUT код_фрагмента integer, OUT фрагмент text) returns setof record
ts_parse(oid_анализатора oid, документ text,
OUT код_фрагмента integer, OUT фрагмент text) returns setof record
ts_parse разбирает данный документ и возвращает набор записей, по одной для каждого извле-
чённого фрагмента. Каждая запись содержит код_фрагмента, код назначенного типа фрагмента,
и фрагмент, собственно текст фрагмента. Например:
SELECT * FROM ts_parse('default', '123 - a number');
tokid | token
-------+--------
22 | 123
12 |
12 | -
1 | a
12 |
1 | number
ts_token_type(имя_анализатора text, OUT код_фрагмента integer,
OUT псевдоним text, OUT описание text) returns setof record
ts_token_type(oid_анализатора oid, OUT код_фрагмента integer,
OUT псевдоним text, OUT описание text) returns setof record
ts_token_type возвращает таблицу, описывающую все типы фрагментов, которые может распо-
знать анализатор. Для каждого типа в этой таблице указывается его целочисленный код_фрагмен-
та, псевдоним , с которым этот тип фигурирует в командах, и краткое description. Например:
SELECT * FROM ts_token_type('default');
tokid |
alias
|
description
-------+-----------------+------------------------------------------
1 | asciiword
| Word, all ASCII
2 | word
| Word, all letters
3 | numword
| Word, letters and digits
4 | email
| Email address
5 | url
| URL
6 | host
| Host
7 | sfloat
| Scientific notation
8 | version
| Version number
401Полнотекстовый поиск
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
hword_numpart
hword_part
hword_asciipart
blank
tag
protocol
numhword
asciihword
hword
url_path
file
float
int
uint
entity
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
Hyphenated word part, letters and digits
Hyphenated word part, all letters
Hyphenated word part, all ASCII
Space symbols
XML tag
Protocol head
Hyphenated word, letters and digits
Hyphenated word, all ASCII
Hyphenated word, all letters
URL path
File or path name
Decimal notation
Signed integer
Unsigned integer
XML entity
12.8.3. Тестирование словаря
Для тестирования словаря предназначена функция ts_lexize.
ts_lexize(словарь regdictionary, фрагмент text) returns text[]
ts_lexize возвращает массив лексем, если входной фрагмент известен словарю, либо пустой мас-
сив, если этот фрагмент считается в словаре стоп-словом, либо NULL, если он не был распознан.
Примеры:
SELECT ts_lexize('english_stem', 'stars');
ts_lexize
-----------
{star}
SELECT ts_lexize('english_stem', 'a');
ts_lexize
-----------
{}
Примечание
Функция ts_lexize принимает одиночный фрагмент, а не просто текст. Вот пример
возможного заблуждения:
SELECT ts_lexize('thesaurus_astro','supernovae stars') is null;
?column?
----------
t
Хотя фраза supernovae stars есть в тезаурусе thesaurus_astro, ts_lexize не работа-
ет, так как она не разбирает входной текст, а воспринимает его как один фрагмент.
Поэтому для проверки тезаурусов следует использовать функции plainto_tsquery и
to_tsvector, например:
SELECT plainto_tsquery('supernovae stars');
plainto_tsquery
-----------------
'sn'
12.9. Типы индексов GIN и GiST
402Полнотекстовый поиск
Для ускорения полнотекстового поиска можно использовать индексы двух видов. Заметьте, что эти
индексы не требуются для поиска, но если по какому-то столбцу поиск выполняется регулярно,
обычно желательно её индексировать.
CREATE INDEX имя ON таблица USING GIN (столбец);
Создаёт индекс на базе GIN (Generalized Inverted Index, Обобщённый Инвертированный Ин-
декс). Столбец должен иметь тип tsvector.
CREATE INDEX имя ON таблица USING GIST (столбец);
Создаёт индекс на базе GiST (Generalized Search Tree, Обобщённое дерево поиска). Здесь стол-
бец может иметь тип tsvector или tsquery.
Более предпочтительными для текстового поиска являются индексы GIN. Будучи инвертирован-
ными индексами, они содержат записи для всех отдельных слов (лексем) с компактным списком
мест их вхождений. При поиске нескольких слов можно найти первое, а затем воспользоваться
индексом и исключить строки, в которых дополнительные слова отсутствуют. Индексы GIN хранят
только слова (лексемы) из значений tsvector, и теряют информацию об их весах. Таким образом
для выполнения запроса с весами потребуется перепроверить строки в таблице.
Индекс GiST допускает неточности, то есть он допускает ложные попадания и поэтому их нужно
исключать дополнительно, сверяя результат с фактическими данными таблицы. (PostgreSQL дела-
ет это автоматически.) Индексы GiST являются неточными, так как все документы в них представ-
ляются сигнатурой фиксированной длины. Эта сигнатура создаётся в результате представления
присутствия каждого слова как одного бита в строке из n-бит, а затем логического объединения
этих битовых строк. Если двум словам будет соответствовать одна битовая позиция, попадание
оказывается ложным. Если для всех слов оказались установлены соответствующие биты (в случае
фактического или ложного попадания), для проверки правильности предположения о совпадении
слов необходимо прочитать строку таблицы.
Неточность индекса приводит к снижению производительности из-за дополнительных обращений
к записям таблицы, для которых предположение о совпадении оказывается ложным. Так как про-
извольный доступ к таблице обычно не бывает быстрым, это ограничивает применимость индексов
GiST. Вероятность ложных попаданий зависит от ряда факторов, например от количества уникаль-
ных слов, так что его рекомендуется сокращать, применяя словари.
Заметьте, что построение индекса GIN часто можно ускорить, увеличив maintenance_work_mem,
тогда как время построения индекса GiST не зависит от этого параметра.
Правильно используя индексы GIN и GiST и разделяя большие коллекции документов на секции,
можно реализовать очень быстрый поиск с возможностью обновления «на лету». Секционировать
данные можно как на уровне базы, с использованием наследования таблиц, так и распределив до-
кументы по разным серверам и затем собирая внешние результаты, например, средствами доступа
к сторонним данным. Последний вариант возможен благодаря тому, что функции ранжирования
используют только локальную информацию.
12.10. Поддержка psql
Информацию об объектах конфигурации текстового поиска можно получить в psql с помощью сле-
дующего набора команд:
\dF{d,p,t}[+] [ШАБЛОН]
Необязательный + в этих командах включает более подробный вывод.
В необязательном параметре ШАБЛОН может указываться имя объекта текстового поиска, возможно
дополненное именем схемы. Если ШАБЛОН не указан, выводится информация обо всех видимых объ-
ектах. ШАБЛОН может содержать регулярное выражение с разными масками для схемы и объекта.
Это иллюстрируют следующие примеры:
=&gt; \dF *fulltext*
403Полнотекстовый поиск
List of text search configurations
Schema | Name
| Description
--------+--------------+-------------
public | fulltext_cfg |
=&gt; \dF *.fulltext*
List of text search configurations
Schema
| Name
| Description
----------+----------------------------
fulltext | fulltext_cfg |
public
| fulltext_cfg |
Возможны следующие команды:
\dF[+] [ШАБЛОН]
Список конфигураций текстового поиска (добавьте + для дополнительных сведений).
=&gt; \dF russian
List of text search configurations
Schema
| Name
|
Description
------------+---------+------------------------------------
pg_catalog | russian | configuration for russian language
=&gt; \dF+ russian
Text search configuration "pg_catalog.russian"
Parser: "pg_catalog.default"
Token
| Dictionaries
-----------------+--------------
asciihword
| english_stem
asciiword
| english_stem
email
| simple
file
| simple
float
| simple
host
| simple
hword
| russian_stem
hword_asciipart | english_stem
hword_numpart
| simple
hword_part
| russian_stem
int
| simple
numhword
| simple
numword
| simple
sfloat
| simple
uint
| simple
url
| simple
url_path
| simple
version
| simple
word
| russian_stem
\dFd[+] [ШАБЛОН]
Список словарей текстового поиска (добавьте + для дополнительных сведений).
=&gt; \dFd
List of text search dictionaries
Schema
|
Name
|
Description
-----------+----------------+-------------------------------------------
pg_catalog | danish_stem
| snowball stemmer for danish language
pg_catalog | dutch_stem
| snowball stemmer for dutch language
pg_catalog | english_stem
| snowball stemmer for english language
pg_catalog | finnish_stem
| snowball stemmer for finnish language
404Полнотекстовый поиск
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
pg_catalog
|
|
|
|
|
|
|
|
|
|
|
|
french_stem
|
german_stem
|
hungarian_stem |
italian_stem
|
norwegian_stem |
portuguese_stem|
romanian_stem |
russian_stem
|
simple
|
spanish_stem
|
swedish_stem
|
turkish_stem
|
snowball stemmer for french language
snowball stemmer for german language
snowball stemmer for hungarian language
snowball stemmer for italian language
snowball stemmer for norwegian language
snowball stemmer for portuguese language
snowball stemmer for romanian language
snowball stemmer for russian language
simple dictionary: just lower case and ...
snowball stemmer for spanish language
snowball stemmer for swedish language
snowball stemmer for turkish language
\dFp[+] [ШАБЛОН]
Список анализаторов текстового поиска (добавьте + для дополнительных сведений).
=&gt; \dFp
List of text search parsers
Schema
| Name
|
Description
------------+---------+---------------------
pg_catalog | default | default word parser
=&gt; \dFp+
Text search parser "pg_catalog.default"
Method
|
Function
| Description
-----------------+----------------+-------------
Start parse
| prsd_start
|
Get next token | prsd_nexttoken |
End parse
| prsd_end
|
Get headline
| prsd_headline |
Get token types | prsd_lextype
|
Token types for parser "pg_catalog.default"
Token name
|
Description
-----------------+------------------------------------------
asciihword
| Hyphenated word, all ASCII
asciiword
| Word, all ASCII
blank
| Space symbols
email
| Email address
entity
| XML entity
file
| File or path name
float
| Decimal notation
host
| Host
hword
| Hyphenated word, all letters
hword_asciipart | Hyphenated word part, all ASCII
hword_numpart
| Hyphenated word part, letters and digits
hword_part
| Hyphenated word part, all letters
int
| Signed integer
numhword
| Hyphenated word, letters and digits
numword
| Word, letters and digits
protocol
| Protocol head
sfloat
| Scientific notation
tag
| XML tag
uint
| Unsigned integer
url
| URL
url_path
| URL path
version
| Version number
word
| Word, all letters
(23 rows)
405Полнотекстовый поиск
\dFt[+] [ШАБЛОН]
Список шаблонов текстового поиска (добавьте + для дополнительных сведений).
=&gt; \dFt
List of text search templates
Schema | Name
|
Description
----------+---------+----------------------------------------------------
pg_catalog|ispell
|ispell dictionary
pg_catalog|simple
|simple dictionary: just lower case and check for ...
pg_catalog|snowball |snowball stemmer
pg_catalog|synonym |synonym dictionary: replace word by its synonym
pg_catalog|thesaurus|thesaurus dictionary: phrase by phrase substitution
12.11. Ограничения
Текущая реализация текстового поиска в PostgreSQL имеет следующие ограничения:
•
•
•
•
•
•
•
Длина лексемы не может превышать 2 килобайта
Длина значения tsvector (лексемы и их позиции) не может превышать 1 мегабайт
64
Число лексем должно быть меньше 2
Значения позиций в tsvector должны быть от 0 до 16383
Расстояние в операторе <N> (ПРЕДШЕСТВУЕТ) типа tsquery не может быть больше 16384
Не больше 256 позиций для одной лексемы
Число узлов (лексемы + операторы) в значении tsquery должно быть меньше 32768
Для сравнения, документация PostgreSQL 8.1 содержала 335 420 слов, из них 10 441 уникальных, а
наиболее часто употребляющееся в ней слово «postgresql» встречается 6 127 раз в 655 документах.
Другой пример — архивы списков рассылки PostgreSQL содержали 910  989 уникальных слов в
57 491 343 лексемах в 461 020 сообщениях.
</N></N></query>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->



<div class="pagination">
  <ul class="inline-list">
    
    
      
        <li><a href="http://localhost:4000/page26/" class="btn">Previous</a></li>
      
    

    
    
      <li><a href="http://localhost:4000">1</a></li>
    

    
    
      
      
      <li>…</li>
    

    
    
    

    
      
        
        
        
        <li><a href="http://localhost:4000/page25/">25</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page26/">26</a></li>
      
    
      
        <li><strong class="current-page">27</strong></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page28/">28</a></li>
      
    
      
        
        
        
        <li><a href="http://localhost:4000/page29/">29</a></li>
      
    

    
    
      <li>…</li>
    

    
      <li><a href="http://localhost:4000/page40/">40</a></li>
    

    
    
      <li><a href="http://localhost:4000/page28/" class="btn">Next</a></li>
    
  </ul>
</div>

</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Sergey Khatsiola. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-130427752-1', 'auto');  
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>


          

</body>
</html>